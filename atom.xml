<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Funk Jungle</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-22T06:59:44.312Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>黄上</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>springboot-JPA</title>
    <link href="http://yoursite.com/2018/04/22/springboot-JPA/"/>
    <id>http://yoursite.com/2018/04/22/springboot-JPA/</id>
    <published>2018-04-22T06:14:04.000Z</published>
    <updated>2018-04-22T06:59:44.312Z</updated>
    
    <content type="html"><![CDATA[<p> spring-data-jpa<br>其实JPA本身并不是一种框架，是一种规范，其全称是Java Persistence API，是是Sun官方提出的Java持久化规范，而他的出现主要是为了简化现有的持久化开发工作和整合ORM技术，并且其是在充分吸收了现有Hibernate，TopLink，JDO等ORM框架的基础上发展而来的，具有易于使用，伸缩性强等优点。<br><a id="more"></a><br>而官网对spring data jpa是这么介绍的：Spring Data JPA是Spring Data系列的一部分，可以轻松实现基于JPA的存储库。该模块处理对基于JPA的数据访问层的增强的支持。这使得使用数据访问技术构建Spring供电的应用程序变得更加容易。</p><p>其本质就是像mybatis，hibernate那样与数据库进行交互的ORM技术，其原理就是整合了Hibernate的封装库，因为刚开始肯定要在网上找代码来看看具体逻辑到底是什么样的，这里我是以翟永超的springboot教程里面的整合spring-data-jpa这节来学习的，想学的朋友也可以直接到他的blog上去找项目来看，所有的项目的都在github上可以下载到。</p><p>教程链接：<a href="http://blog.didispace.com/springbootdata2/" target="_blank" rel="noopener">http://blog.didispace.com/springbootdata2/</a></p><p>首先我是先看完代码后想自己模仿着完成一个小案例，将数据存入数据库内，再把它取出来（这tm是最简单的操作了把），没想到这个框架极恶心，总之我是困在了NullPointerException上了。。。</p><p>我先从他的开源项目上去分析一下他的代码。</p><p>首先他是将依赖包导入到POM中，看看导入代码：</p><pre><code>&lt;!-- Mysql --&gt;&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;/groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;    &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt;&lt;!-- spring-data-jpa --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>以MySQL数据库为例，先引入MySQL连接的依赖包，然后直接在application.properties中配置数据源的参数信息。</p><pre><code>spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=dbuserspring.datasource.password=dbpassspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.jpa.properties.hibernate.hbm2ddl.auto=create</code></pre><p>spring.jpa.properties.hibernate.hbm2ddl.auto是hibernate的配置属性，其主要作用是：自动创建、更新、验证数据库表结构。该参数的几种配置如下：<br>-create：每次加载hibernate时都会删除上一次的生成的表，然后根据你的model类再重新来生成新表，哪怕两次没有任何改变也要这样执行，这就是导致数据库表数据丢失的一个重要原因。表示启动的时候先drop，再create.</p><p>-create-drop：每次加载hibernate时根据model类生成表，但是sessionFactory一关闭,表就自动删除。也表示创建，只不过再系统关闭前执行一下drop.</p><p>-update：最常用的属性，第一次加载hibernate时根据model类会自动建立起表的结构（前提是先建立好数据库），以后加载hibernate时根据model类自动更新表结构，即使表结构改变了但表中的行仍然存在不会删除以前的行。要注意的是当部署到服务器后，表结构是不会被马上建立起来的，是要等应用第一次运行起来后才会。这个操作启动的时候会去检查schema是否一致，如果不一致会做scheme更新.最常用的就是这个了。。。</p><p>-validate：每次加载hibernate时，验证创建数据库表结构，只会和数据库中的表进行比较，不会创建新表，但是会插入新值。 启动时验证现有schema与你配置的hibernate是否一致，如果不一致就抛出异常，并不做更新。</p><p>我在后面的时候要测试时发现数据在程序中已经执行成功存入数据库了，可是在查看数据库的时候却没有发现生成响应的表，我后来发现我用了create-drop这个参数，因为我用testNG测的，测试模块一结束，sessionFactory就关闭了，所以生成的表也就自动删除了，所以我这里改成create，这样数据导入的时候，我们可以在数据库里面看到相应的表生成。</p><p>如果是在本机上进行调试，则url可以写成jdbc:mysql:///test也可以。。。<br>注意test是你的数据库名字，如果没有这个数据库就会报mysql错误，我刚开始也是以为会自动建库，小失误。<br>事先要把这个test库给建立起来，mysql如何建库这个不说了吧。。</p><p>配置好后，这里先来看看一些jpa的基本注解，我们会用这些注解来写案例：<br>1.@Entity ：修饰实体类，指明该类将映射到指定的数据表，例如：Customer 类默认的数据表名为 customer</p><p>2.@Table ：当实体类与映射的数据库表名不同名时需要使用 @Table 注解，该注解与 @Entity 注解并列使用，使用其 name 属性指明数据库的表名<br>@Table(name = “JPA_CUSTOMER表名”)</p><p>3.@Id ：标识该属性为主键，一般标注在该属性的 getter 方法上</p><p>4.@GeneratedValue ：标注主键的生成策略，通过其 strategy 属性。通常与 @Id 注解一起使用。默认情况下 JPA 会自动选择一个最适合底层数据库的主键生成策略，MyS</p><p>5.默认为 AUTO，常用策略有：<br>–IDENTITY：采用数据库 ID自增长的方式来自增主键字段，Oracle 不支持这种方式；</p><p>–AUTO： JPA自动选择合适的策略，是默认选项；</p><p>–SEQUENCE：通过序列产生主键，通过 @SequenceGenerator 注解指定序列名，MySql 不支持这种方式</p><p>–TABLE：通过表产生主键，框架借由表模拟序列产生主键，使用该策略可以使应用更易于数据库移植</p><p>例：@GenerateValue（strategy=GenerationType.AUTO）,写在id属性的上面，主键策略。</p><p>6.@Basic ：用于没有任何标注的 getXxx() 方法，默认即为 @Basic,所以若一个 getter 方法无任何注解，可以使用 @Basic 注解，也可以不使用</p><p>7.@Column ：当实体的属性与其映射的数据表的列不同名时使用，一般用于 getter 方法上。其 name 属性用来指明此属性在数据表中对应的列名；unique 属性指明是否为唯一约束；nullable 属性用来指明是否可以为空，false 为不能为空；length 属性指明此列的长度。<br>通常写在普通属性上：@Column（name=”LAST_NAME”,length=50,nullable=false）<br>nullable表示不允许为空。</p><p>8.@Transient ：标注此注解后在创建数据表的时候将会忽略该属性  Customer 类并没有 info 这个属性，所以数据库中也不应该有 info 这个字段</p><p>9.@Temporal ：向数据库映射日期（Date）属性时用来调整映射的精度。Date 类型的数据有 DATE, TIME, 和 TIMESTAMP 三种精度(即单纯的日期,时间,或者两者兼备).</p><p>Birth 属性应该使用 DATE 类型(生日只具体到日即可，如：2015-10-22)，而 CreateTime 应该使用 TIMESTAMP 类型(创建时间应该具体到秒，如：2017-10-11 22:39:13)</p><p>注解讲完后，可以开始进入项目了，项目中我们需要建立实体类。（以User为例）<br>实体类需要建立@Entity注解以标记为实体类，映射到数据库中，自动生成的表名与这个实体类的类名一致<br>主键id需要加@Id和@GeneratedValue(strategy = GenerationType.IDENTITY)</p><p>原项目中的@GeneratedValue注解没有加后面的参数，所以为了保证不出错，加上参数，<br>JPA为开发人员提供了四种主键生成策略，被定义在枚举类GenerationType中，包含（TABLE , SEQUENCE , IDENTITY , AUTO）.<br>先介绍下这四种策略：</p><p>（1）GenerationType.TABLE</p><p>使用一个特定的数据库表格来保存主键，持久化引擎通过关系数据库的一张特定的表格来生成主键。</p><p>策略的优点：不依赖于外部环境和数据库的具体实现，在不同数据库间可以很容易的进行移植。</p><p>缺点：不能充分利用数据库的特性，一般不会优先使用。</p><p>（2）GenerationType.SEQUENCE</p><p>在某些数据库中，不支持主键自增长，比如Oracle，其提供了一种叫做”系列(sequence)”的机制生成主键。</p><p>该策略只要部分数据库（Oracle/PostgreSQL/DB2）支持序列对象，所以该策略一般不应用与其他数据库。</p><p>（3）GenerationType.IDENTITY</p><p>此种主键生成策略就是通常所说的主键自增长，数据库在插入数据时，会自动给主键赋值，比如Mysql可以在创建表时声明”auto_increment”来指定主键自增长。大部分数据库都提供了该支持。我使用了这种。。。</p><p>（4）GenerationType.AUTO</p><p>把主键生成策略交给持久化引擎，持久化引擎会根据数据库在以上三种主键生成策略中选择其中一种。因为这种策略比较常用，所以JPA默认的生成策略就是AUTO.这种方式如果数据库中不存在这张表的时候，用它来指定自增方式没有问题，但是如果数据库中已经存在这张表并设计了自动方式，那么插入数据的时候就会报错。</p><pre><code>@Entitypublic class User {    @Id    @GeneratedValue    private Long id;    @Column(nullable = false)    private String name;    @Column(nullable = false)    private Integer age;    public User(){}    public User(String name, Integer age) {        this.name = name;        this.age = age;    }    //省略get/set}</code></pre><p>接下来是DAO：<br>spring data jpa让我们解脱了DAO层的操作，基本上所有CRUD都可以依赖于它来实现，在里面就集成了一种方法就是自动编写SQL，但是如果我们要复杂SQL的时候，jpa也给我们提供了@Query用于我们自己编写sql语句，当然这是jpa特有的编写规范。<br>它们分别实现了按name查询User实体和按name和age查询User实体，可以看到我们这里没有任何类SQL语句就完成了两个条件查询方法。这就是Spring-data-jpa的一大特性：通过解析方法名创建查询。<br>除了通过解析方法名来创建查询外，它也提供通过使用@Query 注解来创建查询，您只需要编写JPQL语句，并通过类似“:name”来映射@Param指定的参数，就像例子中的第三个findUser函数一样。</p><pre><code>public interface UserRepository extends JpaRepository&lt;User, Long&gt; {   User findByName(String name);   User findByNameAndAge(String name, Integer age);   //：name是来映射@Param指定的参数，根据传递的参数来作为where查询的条件   //方法的参数个数必须和@Query里面需要的参数个数一致   //默认配置下， 使用了@Query注解后就不会再使用方法名解析的方式了   //这是命名化参数的形式，就是条件具体的指向参数，也可以用问号？索引方式来表达参数   @Query(&quot;from User u where u.name=:name&quot;)   User findUser1(@Param(&quot;name&quot;) String name);   //根据name和age的条件来查找数据，并返回User实例   @Query（value=&quot;select * from User u where u.name=?1 and u.age=?2&quot;,nativeQuery=true）   User findUser2(@Param(&quot;name&quot;)String name,@Param(&quot;age&quot;)Integer age);} </code></pre><p>JPQL主要用于JPA查询数据，和SQL语句的语法大同小异；<br>JPQL语言，即 Java Persistence Query Language 的简称。JPQL 是一种和 SQL 非常类似的中间性和对象化查询语言，它最终会被编译成针对不同底层数据库的 SQL 查询，从而屏蔽不同数据库的差异。 JPQL语言的语句可以是 select 语句、update 语句或delete语句，它们都通过 Query 接口封装执行。</p><p> Query注解自定义SQL查询 </p><p>1.我们可以直接使用@Query来使用这个类的方法。</p><p>默认配置下， 使用了@Query注解后就不会再使用方法名解析的方式了…注意</p><p>@Query有几大属性，分别是：<br>方法的参数个数必须和@Query里面需要的参数个数一致<br>value里面的参数也可以用SPEL表达式来写，也就是#{…}语句，用于更灵活的配置参数，不用把sql语句写死。</p><p>-String value() default “”;//默认是空，value=sql语句，<br>比如@Query(“from User u where u.name=:name”)就可以写成<br>@Query(value=”from User u where u.name=:name”)</p><p>-boolean nativeQuery() default false;//默认是false<br>代表原生sql，所谓本地查询，就是使用原生的sql语句（根据数据库的不同，在sql的语法或结构方面可能有所区别）进行查询数据库的操作。调用这个以后就可以针对不同的数据库做对应的sql语法了（就像oracle和mysql一样，虽然大体相同但是还是存在一些小地方的差别）</p><p>当不需要表中的全字段时，可自定义dto类来接受查询结果，这种方法要注意使用new + dto类全路径+ （别名.field1, 别名.field2, 别名.field3）, 且dto类中必须有对应参数结构的构造函数！别忘记加上无参的构造函数！</p><pre><code>@Query(&quot;select new com.user.domain.UserDto(a.userName, a.gender) from User a where userId = :userId&quot;)UserDto findByUserId(@Param(&quot;userId&quot;) userId);</code></pre><p>2.修改操作加上 @Modify注解</p><pre><code>@Query(value=&quot;update User set userId = :userId&quot;)@ModifyUser findByUserId(@Param(&quot;userId&quot;) userId);</code></pre><p>3.如果是like（模糊查询），后面的参数需要前面或者后面加”%”，比如下面都对：</p><pre><code>@Query(&quot;select o from UserModel o where o.name like ?1%&quot;)public List&lt;UserModel&gt; findByUuidOrAge(String name);@Query(&quot;select o from UserModel o where o.name like %?1&quot;)public List&lt;UserModel&gt; findByUuidOrAge(String name);@Query(&quot;select o from UserModel o where o.name like %?1%&quot;)public List&lt;UserModel&gt; findByUuidOrAge(String name);</code></pre><p>当然，这样在传递参数值的时候就可以不加’%’了，当然加了也不会错</p><p>4.还有个很有意思的，就是这个例子：</p><pre><code>@Query(value = &quot;select * from Book b where b.name=?1&quot;, nativeQuery = true)   List&lt;Book&gt; findByName(String name);//此方法sql将会报错(java.lang.IllegalArgumentException)，看出原因了吗,若没看出来，请看下一个例子  </code></pre><p>因为指定了nativeQuery = true，即使用原生的sql语句查询。使用java对象’Book’作为表名来查自然是不对的。只需将Book替换为表名book。因为若按数据库方法去查就找不到这张表了。</p><p>5.用SPEL表达式</p><pre><code>public interface BookQueryRepositoryExample extends Repository&lt;Book, Long&gt;{         @Query(value = &quot;select * from #{#entityName} b where b.name=?1&quot;, nativeQuery = true)         List&lt;Book&gt; findByName(String name);  }  先来说一说&apos;#{#entityName}&apos;到底是个啥。从字面来看，&apos;#{#entityName}&apos;不就是实体类的名称么，对，他就是。实体类Book,使用@Entity注解后，spring会将实体类Book纳入管理。默认&apos;#{#entityName}&apos;的值就是&apos;Book&apos;。&apos;#{#entityName}&apos;值为&apos;Book&apos;对象对应的数据表名称(book)。但是如果使用了@Entity(name = &quot;book&quot;)来注解实体类Book,此时&apos;#{#entityName}&apos;的值就变成了&apos;book&apos;。name值就是实体类对应的表名。。。到此，事情就明了了，只需要在用@Entity来注解实体类时指定name为此实体类对应的表名。在原生sql语句中，就可以把&apos;#{#entityName}&apos;来作为数据表名使用。</code></pre><p>@Query的方法都讲完了，仔细看看多做几个案例就可以完全熟悉这些操作。</p><p>接下来我们总结一下，如果不用@Query的话，jpa是怎么通过方法名来解析出对应sql的。</p><p> 预先生成方法（默认自带方法） </p><p>spring data jpa 默认预先生成了一些基本的CURD的方法，例如：增、删、改等等</p><p>1 继承JpaRepository</p><pre><code>public interface UserRepository extends JpaRepository&lt;User, Long&gt; {}</code></pre><p>既然是需要继承JpaRepository接口的话，那么自带封装的方法就是在这里面，<br>其实JpaRepository又继承于PagingAndSortingRepository，实现一组JPA规范相关的方法<br>PagingAndSortingRepository又继承于CrudRepository，实现了一组分页排序相关的方法<br>CrudRepository又继承于Repository，实现了一组CRUD相关的方法（主要是在这里）<br>Repository仅仅是一个标识，表明任何继承它的均为仓库接口类，方便Spring自动扫描识别。<br>JpaSpecificationExecutor： 比较特殊，不属于Repository体系，实现一组JPA Criteria查询相关的方法 </p><p>我们自己定义的XxxxRepository需要继承JpaRepository，这样我们的XxxxRepository接口就具备了通用的数据访问控制层的能力。 </p><p>-JpaRepository 所提供的基本功能 ：</p><p>  1.继承自CrudRepository&lt;T, ID extends Serializable&gt;</p><p>  这个接口提供了最基本的对实体类的添删改查操作<br>  T save(T entity);//保存单个实体<br>  Iterable<t> save(Iterable&lt;? extends T&gt; entities);//保存集合<br>  T findOne(ID id);//根据id查找实体<br>  boolean exists(ID id);//根据id判断实体是否存在<br>  Iterable<t> findAll();//查询所有实体,不用或慎用!<br>  long count();//查询实体数量<br>  void delete(ID id);//根据Id删除实体<br>  void delete(T entity);//删除一个实体<br>  void delete(Iterable&lt;? extends T&gt; entities);//删除一个实体的集合<br>  void deleteAll();//删除所有实体,不用或慎用! </t></t></p><p>  2.继承自PagingAndSortingRepository&lt;T, ID extends Serializable&gt;<br>  这个接口提供了分页与排序功能<br>  Iterable<t> findAll(Sort sort);//排序<br>  Page<t> findAll(Pageable pageable);//分页查询（含排序功能）</t></t></p><p>  3.本身JpaRepository&lt;T, ID extends Serializable&gt;<br>  这个接口提供了JPA的相关功能<br>  List<t> findAll();//查找所有实体<br>  List<t> findAll(Sort sort);//排序 查找所有实体<br>  List<t> save(Iterable&lt;? extends T&gt; entities);//保存集合<br>  void flush();//执行缓存与数据库同步，flush的字面意思是刷新的意思。<br>  T saveAndFlush(T entity);//强制执行持久化<br>  void deleteInBatch(Iterable<t> entities);//删除一个实体集合 </t></t></t></t></p><p>2 使用默认方法</p><pre><code>@Testpublic void testBaseQuery() throws Exception {    User user=new User();    userRepository.findAll();    userRepository.findOne(1l);    userRepository.save(user);    userRepository.delete(user);    userRepository.count();    userRepository.exists(1l);    // ...}</code></pre><p> 自定义简单查询 </p><p>自定义的简单查询就是根据方法名来自动生成SQL，主要的语法是findXXBy,readAXXBy,queryXXBy,countXXBy, getXXBy后面跟属性名称：</p><pre><code>User findByUserName(String userName);</code></pre><p>也使用一些加一些关键字And、 Or</p><pre><code>User findByUserNameOrEmail(String username, String email);</code></pre><p>修改、删除、统计也是类似语法</p><pre><code>Long deleteById(Long id);Long countByUserName(String userName)</code></pre><p>基本上SQL体系中的关键词都可以使用，例如：LIKE、 IgnoreCase、 OrderBy。</p><pre><code>List&lt;User&gt; findByEmailLike(String email);User findByUserNameIgnoreCase(String userName);List&lt;User&gt; findByUserNameOrderByEmailDesc(String email);</code></pre><p>具体的关键字，使用方法和生产成SQL如下表所示：</p><p><img src="/2018/04/22/springboot-JPA/main.png" alt="logo"></p><p> 复杂查询 </p><p>在实际的开发中我们需要用到分页、删选、连表等查询的时候就需要特殊的方法或者自定义SQL</p><p> 分页查询 </p><p>分页查询在实际使用中非常普遍了，spring data jpa已经帮我们实现了分页的功能，在查询的方法中，需要传入参数Pageable<br>,当查询中有多个参数的时候Pageable建议做为最后一个参数传入</p><pre><code>Page&lt;User&gt; findALL(Pageable pageable);Page&lt;User&gt; findByUserName(String userName,Pageable pageable);</code></pre><p>Pageable 是spring封装的分页实现类，使用的时候需要传入页数、每页条数和排序规则</p><pre><code>@Testpublic void testPageQuery() throws Exception {    int page=1,size=10;    Sort sort = new Sort(Direction.DESC, &quot;id&quot;);    Pageable pageable = new PageRequest(page, size, sort);    userRepository.findALL(pageable);    userRepository.findByUserName(&quot;testName&quot;, pageable);}</code></pre><p> 限制查询 </p><p>有时候我们只需要查询前N个元素，或者支取前一个实体。</p><pre><code>User findFirstByOrderByLastnameAsc();User findTopByOrderByAgeDesc();Page&lt;User&gt; queryFirst10ByLastname(String lastname, Pageable pageable);List&lt;User&gt; findFirst10ByLastname(String lastname, Sort sort);List&lt;User&gt; findTop10ByLastname(String lastname, Pageable pageable);</code></pre><p> 多表查询 </p><p>多表查询在spring data jpa中有两种实现方式，第一种是利用hibernate的级联查询来实现，第二种是创建一个结果集的接口来接收连表查询后的结果，这里主要第二种方式。</p><p>首先需要定义一个结果集的接口类。</p><pre><code>public interface HotelSummary {    City getCity();    String getName();    Double getAverageRating();    default Integer getAverageRatingRounded() {        return getAverageRating() == null ? null : (int) Math.round(getAverageRating());    }}</code></pre><p>查询的方法返回类型设置为新创建的接口</p><pre><code>@Query(&quot;select h.city as city, h.name as name, avg(r.rating) as averageRating &quot;        - &quot;from Hotel h left outer join h.reviews r where h.city = ?1 group by h&quot;)Page&lt;HotelSummary&gt; findByCity(City city, Pageable pageable);@Query(&quot;select h.name as name, avg(r.rating) as averageRating &quot;        - &quot;from Hotel h left outer join h.reviews r  group by h&quot;)Page&lt;HotelSummary&gt; findByCity(Pageable pageable);</code></pre><p>使用</p><pre><code>Page&lt;HotelSummary&gt; hotels = this.hotelRepository.findByCity(new PageRequest(0, 10, Direction.ASC, &quot;name&quot;));for(HotelSummary summay:hotels){        System.out.println(&quot;Name&quot; +summay.getName());}</code></pre><p>在运行中Spring会给接口（HotelSummary）自动生产一个代理类来接收返回的结果，代码汇总使用getXX的形式来获取。</p><p> 多数据源的支持 </p><p> 同源数据库的多源支持 </p><p>日常项目中因为使用的分布式开发模式，不同的服务有不同的数据源，常常需要在一个项目中使用多个数据源，因此需要配置sping data jpa对多数据源的使用，一般分一下为三步：</p><p>1 配置多数据源<br>2 不同源的实体类放入不同包路径<br>3 声明不同的包路径下使用不同的数据源、事务支持</p><p>参考文章：<a href="https://www.jianshu.com/p/34730e595a8c" target="_blank" rel="noopener">https://www.jianshu.com/p/34730e595a8c</a></p><p> 异构数据库多源支持 </p><p>比如我们的项目中，即需要对mysql的支持，也需要对mongodb的查询等。</p><p>实体类声明@Entity 关系型数据库支持类型、声明@Document 为mongodb支持类型，不同的数据源使用不同的实体就可以了</p><pre><code>interface PersonRepository extends Repository&lt;Person, Long&gt; { …}@Entitypublic class Person {  …}interface UserRepository extends Repository&lt;User, Long&gt; { …}@Documentpublic class User {  …}</code></pre><p>但是，如果User用户既使用mysql也使用mongodb呢，也可以做混合使用</p><pre><code>interface JpaPersonRepository extends Repository&lt;Person, Long&gt; { …}interface MongoDBPersonRepository extends Repository&lt;Person, Long&gt; { …}@Entity@Documentpublic class Person {  …}</code></pre><p>也可以通过对不同的包路径进行声明，比如A包路径下使用mysql,B包路径下使用mongoDB</p><p>@EnableJpaRepositories(basePackages = “com.neo.repositories.jpa”)<br>@EnableMongoRepositories(basePackages = “com.neo.repositories.mongo”)<br>interface Configuration { }</p><p> 其它 </p><p>使用枚举</p><p>使用枚举的时候，我们希望数据库中存储的是枚举对应的String类型，而不是枚举的索引值，需要在属性上面添加@Enumerated(EnumType.STRING) 注解</p><p>@Enumerated(EnumType.STRING)<br>@Column(nullable = true)<br>private UserType type;<br>不需要和数据库映射的属性</p><p>正常情况下我们在实体类上加入注解@Entity，就会让实体类和表相关连如果其中某个属性我们不需要和数据库来关联只是在展示的时候做计算，只需要加上@Transient属性既可。</p><p>@Transient<br>private String  userName;</p><p>参考项目：<a href="https://github.com/cloudfavorites/favorites-web" target="_blank" rel="noopener">https://github.com/cloudfavorites/favorites-web</a>  （用到所有标签和注解）<br>spring-data-jpa中文开发文档：<a href="https://legacy.gitbook.com/book/ityouknow/spring-data-jpa-reference-documentation/details" target="_blank" rel="noopener">https://legacy.gitbook.com/book/ityouknow/spring-data-jpa-reference-documentation/details</a></p><p>踩坑史：</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt; spring-data-jpa&lt;br&gt;其实JPA本身并不是一种框架，是一种规范，其全称是Java Persistence API，是是Sun官方提出的Java持久化规范，而他的出现主要是为了简化现有的持久化开发工作和整合ORM技术，并且其是在充分吸收了现有Hibernate，TopLink，JDO等ORM框架的基础上发展而来的，具有易于使用，伸缩性强等优点。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
      <category term="spring-data-jpa" scheme="http://yoursite.com/tags/spring-data-jpa/"/>
    
  </entry>
  
  <entry>
    <title>Springboot+Nginx实现负载均衡</title>
    <link href="http://yoursite.com/2018/04/19/springboot-nginx/"/>
    <id>http://yoursite.com/2018/04/19/springboot-nginx/</id>
    <published>2018-04-19T15:55:54.000Z</published>
    <updated>2018-04-21T15:42:55.517Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是-Nginx"><a href="#什么是-Nginx" class="headerlink" title="什么是 Nginx"></a>什么是 Nginx</h1><p>Nginx 是俄罗斯人编写的十分轻量级的 HTTP 服务器,Nginx，它的发音为“engine X”，是一个高性能的HTTP和反向代理服务器，同时也是一个 IMAP/POP3/SMTP 代理服务器。Nginx 是由俄罗斯人 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，它已经在该站点运行超过两年半了。Igor Sysoev 在建立的项目时,使用基于 BSD 许可。</p><p>官网：<a href="http://nginx.net" target="_blank" rel="noopener">http://nginx.net</a><br>Simplify your journey to microservices with the new NGINX Application Platform.<br><a id="more"></a><br>Nginx 以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。其拥有匹配 Lighttpd 的性能，同时还没有 Lighttpd 的内存泄漏问题，而且 Lighttpd 的 mod_proxy 也有一些问题并且很久没有更新。</p><p>现在，Igor 将源代码以类 BSD 许可证的形式发布。Nginx 因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名．业界一致认为它是 Apache2.2＋mod_proxy_balancer 的轻量级代替者，不仅是因为响应静态页面的速度非常快，而且它的模块数量达到 Apache 的近 2/3。对 proxy 和 rewrite 模块的支持很彻底，还支持 mod_fcgi、ssl、vhosts ，适合用来做 mongrel clusters 的前端 HTTP 响应。</p><p>Nginx在大型互联网站点中使用度很高，一台nginx服务器的处理性能基于服务器CPU，进程越高其nginx的质量越高。</p><p><img src="/2018/04/19/springboot-nginx/p1.png" alt="logo"><br>Nginx 在启动后，在 unix 系统中会以 daemon 的方式在后台运行，后台进程包含一个 master 进程和多个 worker 进程。我们也可以手动地关掉后台模式，让 Nginx 在前台运行，并且通过配置让 Nginx 取消 master 进程，从而可以使 Nginx 以单进程方式运行。很显然，生产环境下我们肯定不会这么做，所以关闭后台模式，一般是用来调试用的，在后面的章节里面，我们会详细地讲解如何调试 Nginx。</p><p>Nginx 最初是作为一个 Web 服务器创建的，用于解决 C10k 的问题。作为一个 Web 服务器，它可以以惊人的速度为您的数据服务。但 Nginx 不仅仅是一个 Web 服务器，你还可以将其用作反向代理，与较慢的上游服务器（如：Unicorn 或 Puma）轻松集成。你可以适当地分配流量（负载均衡器）、流媒体、动态调整图像大小、缓存内容等等。</p><p>基本的 nginx 体系结构由 master 进程和其 worker 进程组成。master 读取配置文件，并维护 worker 进程，而 worker 则会对请求进行实际处理。</p><p>Nginx的内部架构如图所示，当Nginx服务开启的时候，会启动一个master进程，及其多个worker（worker的多少与你搭建的服务器主机的性能有关，更多进程支持的强大CPU当然可以开启更多的worker），master 进程主要用来管理 worker 进程，包含：master接收来自外界的信号，向各 worker 进程发送信号，监控 worker 进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的 worker 进程。而基本的网络事件，则是放在 worker 进程中来处理了。多个 worker 进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。worker 进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与 Nginx 的进程模型以及事件处理模型是分不开的。</p><p>master 来管理 worker 进程，所以我们只需要与 master 进程通信就行了。master 进程会接收来自外界发来的信号，再根据信号做不同的事情。</p><p>例如：控制Nginx的一般命令有</p><p>-kill -HUP pid（这个命令现在较老，用处不大）：告诉 Nginx，从容地重启 Nginx，我们一般用这个信号来重启 Nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。master 进程在接收到 HUP 信号后是怎么做的呢？首先 master 进程在接到信号后，会先重新加载配置文件，然后再启动新的 worker 进程，并向所有老的 worker 进程发送信号，告诉他们可以光荣退休了。新的 worker 在启动后，就开始接收新的请求，而老的 worker 在收到来自 master 的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。</p><p>./nginx -s reload：重启 Nginx，新的 Nginx 进程在解析到 reload 参数后，就知道我们的目的是控制 Nginx 来重新加载配置文件了，它会向 master 进程发送信号，然后接下来的动作，就和我们直接向 master 进程发送信号一样了。<br>./nginx -s stop：停止 Nginx 的运行</p><p>我们知道了当我们在操作 Nginx 的时候，Nginx 内部做了些什么事情，那么，worker 进程又是如何处理请求的呢？我们前面有提到，worker 进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供 80 端口的 http 服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个 worker 进程都是从 master 进程 fork 过来，在 master 进程里面，先建立好需要 listen 的 socket（listenfd）之后，然后再 fork 出多个 worker 进程。所有 worker 进程的 listenfd 会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢 accept_mutex，抢到互斥锁的那个进程注册 listenfd 读事件，在读事件里调用 accept 接受该连接。当一个 worker 进程在 accept 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。</p><p>Nginx 采用这种进程模型有什么好处呢？当然，好处肯定会很多了。首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快启动新的 worker 进程。当然，worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。</p><p>为什么 Nginx 可以采用异步非阻塞的方式来处理呢，或者异步非阻塞到底是怎么回事呢？我们先回到原点，看看一个请求的完整过程。首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。阻塞调用会进入内核等待，cpu 就会让出去给别人用了，对单线程的 worker 来说，显然不合适，当网络事件越多时，大家都在等待呢，cpu 空闲下来没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。所以，在 Nginx 里面，最忌讳阻塞的系统调用了。不要阻塞，那就非阻塞喽。非阻塞就是，事件没有准备好，马上返回 EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。所以，才会有了异步非阻塞的事件处理机制，具体到系统调用就是像 select/poll/epoll/kqueue 这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制正好解决了我们上面的两个问题，拿 epoll 为例(在后面的例子中，我们多以 epoll 为例子，以代表这一类函数)，当事件没准备好时，放到 epoll 里面，事件准备好了，我们就去读写，当读写返回 EAGAIN 时，我们将它再次加入到 epoll 里面。这样，只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才在 epoll 里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 我之前有对连接数进行过测试，在 24G 内存的机器上，处理的并发请求数达到过 200 万。现在的网络服务器基本都采用这种方式，这也是nginx性能高效的主要原因。</p><p>我们之前说过，推荐设置 worker 的个数为 cpu 的核数，在这里就很容易理解了，更多的 worker 数，只会导致进程来竞争 cpu 资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，提供了 cpu 亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来 cache 的失效。像这种小的优化在 Nginx 中非常常见，同时也说明了 Nginx 作者的苦心孤诣。比如，Nginx 在做 4 个字节的字符串比较时，会将 4 个字符转换成一个 int 型，再作比较，以减少 cpu 的指令数等等。</p><p>现在，知道了 Nginx 为什么会选择这样的进程模型与事件模型了。对于一个基本的 Web 服务器来说，事件通常有三种类型，网络事件、信号、定时器。从上面的讲解中知道，网络事件通过异步非阻塞可以很好的解决掉。如何处理信号与定时器？</p><p>首先，信号的处理。对 Nginx 来说，有一些特定的信号，代表着特定的意义。信号会中断掉程序当前的运行，在改变状态后，继续执行。如果是系统调用，则可能会导致系统调用的失败，需要重入。关于信号的处理，大家可以学习一些专业书籍，这里不多说。对于 Nginx 来说，如果nginx正在等待事件（epoll_wait 时），如果程序收到信号，在信号处理函数处理完后，epoll_wait 会返回错误，然后程序可再次进入 epoll_wait 调用。</p><p>另外，再来看看定时器。由于 epoll_wait 等函数在调用的时候是可以设置一个超时时间的，所以 Nginx 借助这个超时时间来实现定时器。nginx里面的定时器事件是放在一颗维护定时器的红黑树里面，每次在进入 epoll_wait前，先从该红黑树里面拿到所有定时器事件的最小时间，在计算出 epoll_wait 的超时时间后进入 epoll_wait。所以，当没有事件产生，也没有中断信号时，epoll_wait 会超时，也就是说，定时器事件到了。这时，nginx会检查所有的超时事件，将他们的状态设置为超时，然后再去处理网络事件。由此可以看出，当我们写 Nginx 代码时，在处理网络事件的回调函数时，通常做的第一个事情就是判断超时，然后再去处理网络事件。</p><p>nginx应用场景：</p><p>1、反向代理<br>反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。</p><p>在物理层面上就是一般浏览器访问网站是对接到相应的真实服务器上，可能会存在多台服务器做集群来分布式处理，这时候我们若加上Nginx作为反向代理服务器（就是搭建一台主机给Nginx用），本来浏览器发送给真实服务器的请求就会先去到Nginx服务器上，再由Nginx分发请求给不同的真实服务器，这样做，一是为了减少服务端压力（统一处理），二是为了安全（浏览器访问到的服务器只是Nginx的地址而不是真实服务器）。</p><p>反向代理的定义：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。<br>反向代理的基本功能就是 隐藏原始服务器地址。其解决的是安全的问题。<br>但目前的主流反向代理服务器还同时兼职做负载均衡，静态文件缓存和动态请求分发，压缩文件，预防DDoS攻击等功能。这些功能都在一定程度上可以提升服务器负载。</p><p>2、http服务器。Nginx是一个http服务可以独立提供http服务及其动静分离。<br>Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器。</p><p>-静态资源储存</p><pre><code>server {    listen       80;                                                             server_name  localhost;                                                   client_max_body_size 1024M;    location / {           root   e:wwwroot;           index  index.html;       }}</code></pre><p>这样如果访问<a href="http://localhost" target="_blank" rel="noopener">http://localhost</a> 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。<br>就是指定url与本地静态资源的关系，当用户发起访问，直接就可以通过地址对应到Nginx服务器下的静态资源，我们可以将网站的静态资源全都放在Nginx服务器下的储存中，可以有效减免服务器压力。</p><p>-动静分离（动态页面的动静分离）</p><p>一般来说，现在的网站大多都具备交互性，就是动态网站，可以与后台交互，静态网站多数都是一些博客和资料，静态页面是不能随时改动的，静态是一次性写好放在服务器上进行浏览的，如果想改动，必须在页面上修改，然后再上传服务器覆盖原来的页面，这样才能更新信息，比较麻烦，使用者不能随时修改。 动态页面是可以随时改变内容的，有前后台之分，管理员可以在后台随时更新网站的内容，前台页面的内容也会随之更新，比较简单易学。</p><p>动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路：</p><pre><code>upstream test{     server localhost:8080;     server localhost:8081;  }   server {      listen       80;      server_name  localhost;      location / {          root   e:wwwroot;          index  index.html;      }      // 所有静态请求都由nginx处理，存放目录为html，静态资源和Nginx是同一台服务器，当然也可以不同      location ~ .(gif|jpg|jpeg|png|bmp|swf|css|js)$ {          root    e:wwwroot; //指的是e盘符下的wwwroot目录     }      // 所有动态请求都转发给tomcat处理，jsp动态网页和.do请求    location ~ .(jsp|do)$ {          proxy_pass  http://test;      }      //错误的页面也可以定义为静态资源页    error_page   500 502 503 504  /50x.html;      location = /50x.html {          root   e:wwwroot;      }  } </code></pre><p>这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活</p><p>3.负载均衡<br>负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。</p><p>（1）RR（默认）即Round-Robin,轮询调度<br>默认的负载均衡策略，当我们项目中的服务器有多台的时候，通过Nginx内部机制将这些请求进行随机分发而不是统统将所有的客户端请求都交给一台服务器去处理，这样也充当着一个请求管理者的作用，</p><p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p><p>简单配置：</p><pre><code>upstream test {       server localhost:8080;       server localhost:8081;   }   server {       listen       81;                                                                server_name  localhost;                                                      client_max_body_size 1024M;       location / {           proxy_pass http://test;           proxy_set_header Host $host:$server_port;       }   }</code></pre><p>负载均衡的核心代码为：</p><pre><code>upstream test {    server localhost:8080;    server localhost:8081;}</code></pre><p>端口8080和8081分别代表两台不同的服务器，但是我们访问<a href="http://localhost" target="_blank" rel="noopener">http://localhost</a> 的时候,也不会有问题，会默认跳转到<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a> 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。</p><p>（2）权重,基于RR<br>可以设置轮询哪个服务器的几率，weight和访问比率成正比，用于后端服务器性能不均的情况。<br>例如项目中使用的服务器集群中存在性能差异，为了避免性能分配不均和利用率，我们可以设置RR权重。</p><p>例如：</p><pre><code>upstream test {    server localhost:8080 weight=9;    server localhost:8081 weight=1;}</code></pre><p>那么10次一般只会有1次会访问到8081，而有9次会访问到8080</p><p>（3）ip_hash(见名知意，就是根据浏览器IP的Hash值)</p><p>上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p><p>如果利用Redis保存全局Session还会用到这个功能吗？</p><pre><code>upstream test {    ip_hash;    server localhost:8080;    server localhost:8081;}</code></pre><p>（4）fair（第三方）<br>按后端服务器的响应时间来分配请求，响应时间短的优先分配。（可以根据减少服务器不必要时间的浪费） </p><pre><code>upstream backend {     fair;     server localhost:8080;    server localhost:8081;} </code></pre><p>（5）url_hash（第三方）<br>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。</p><pre><code>upstream backend {     hash $request_uri;     hash_method crc32;     server localhost:8080;    server localhost:8081;} </code></pre><p>以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用。</p><p>4.正向代理</p><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。</p><pre><code>resolver 114.114.114.114 8.8.8.8;server {    resolver_timeout 5s;    listen 81;    access_log  e:wwwrootproxy.access.log;    error_log   e:wwwrootproxy.error.log;    location / {        proxy_pass http://$host$request_uri;    }}</code></pre><p>resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。</p><h1 id="Nginx支持热启动"><a href="#Nginx支持热启动" class="headerlink" title="Nginx支持热启动"></a>Nginx支持热启动</h1><p>Nginx是支持热启动的，也就是说当我们修改配置文件后，不用关闭Nginx，就可以实现让配置生效，当然我并不知道多少人知道这个，反正我一开始并不知道，导致经常杀死了Nginx线程再来启动。。。Nginx从新读取配置的命令是</p><p>即nginx -s reload </p><p>windows下面就是：nginx.exe -s reload  </p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是-Nginx&quot;&gt;&lt;a href=&quot;#什么是-Nginx&quot; class=&quot;headerlink&quot; title=&quot;什么是 Nginx&quot;&gt;&lt;/a&gt;什么是 Nginx&lt;/h1&gt;&lt;p&gt;Nginx 是俄罗斯人编写的十分轻量级的 HTTP 服务器,Nginx，它的发音为“engine X”，是一个高性能的HTTP和反向代理服务器，同时也是一个 IMAP/POP3/SMTP 代理服务器。Nginx 是由俄罗斯人 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，它已经在该站点运行超过两年半了。Igor Sysoev 在建立的项目时,使用基于 BSD 许可。&lt;/p&gt;
&lt;p&gt;官网：&lt;a href=&quot;http://nginx.net&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://nginx.net&lt;/a&gt;&lt;br&gt;Simplify your journey to microservices with the new NGINX Application Platform.&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
      <category term="nginx" scheme="http://yoursite.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>重返SpringBoot</title>
    <link href="http://yoursite.com/2018/04/19/return-springboot/"/>
    <id>http://yoursite.com/2018/04/19/return-springboot/</id>
    <published>2018-04-18T17:00:22.000Z</published>
    <updated>2018-04-18T17:31:19.353Z</updated>
    
    <content type="html"><![CDATA[<p>SpringBoot作为一些常用开发框架的集合（可以成为脚手架），其自身的自动化配置给我们的开发带来质的改变，不必去担心繁琐的XML配置（反正我到现在都没有去配什么XML文件），用一个application.properties文件就可以在日常开发中完全适用，我们通过各种功能性示例体验了Spring Boot的自动化配置给我们所带来的超便利的新开发方式。</p><p>但是SpringBoot的自动化配置也带入些许隐患(优&gt;&gt;&gt;弊)<br><a id="more"></a></p><h1 id="jar包冲突"><a href="#jar包冲突" class="headerlink" title="jar包冲突"></a>jar包冲突</h1><p>项目依赖复杂的情况下，由于依赖方的依赖组织不够严格，可能引入了一些实际我们不需要的依赖，从而导致我们的项目满足一些特定的自动化配置。（自动配置过剩问题，我遇到了很多这种问题，比如jpa与redis的冲突）<br>传统Spring项目转换为Spring Boot项目的过程中，由于不同的组织方式问题，引发自动化配置加载的错误，比如：通过xml手工组织的多数据源配置等。(升级框架时会遇到各种兼容问题，对升级框架不太友好)</p><p>上面这些原因都会导致不必要的自动化配置加载而导致应用无法启动或触发/health的健康检查不通过等问题。</p><p>若是遇到jar包兼容问题，则是通过外部依赖的修改来解决：通过与依赖方沟通，在对方提供的API依赖中去掉不必要的依赖<br>通过禁用指定的自动化配置来避免加载不必要的自动化配置，下面列举了禁用的方法：</p><p>-使用了@EnableAutoConfiguration<br>@EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class})<br>禁止了DataSource自动加载的类</p><p>-使用了@SpringBootApplication<br>@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})</p><p>-通过配置文件来设置<br>spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration</p><h2 id="日志框架冲突"><a href="#日志框架冲突" class="headerlink" title="日志框架冲突"></a>日志框架冲突</h2><p>jar包冲突中比较常见的是关于springboot本身的日志配置</p><p>Exception in thread “main” java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation </p><p>这个异常是由于打印日志的jar冲突导致，SpringBoot本身有打印日志的功能（springboot默认使用Commons Logging），如果跟本地的冲突，就需要去掉再调用其他的，如下</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;version&gt;1.3.3.RELEASE&lt;/version&gt;    &lt;exclusions&gt;        &lt;exclusion&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;        &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;</code></pre><h2 id="springboot版本不兼容问题"><a href="#springboot版本不兼容问题" class="headerlink" title="springboot版本不兼容问题"></a>springboot版本不兼容问题</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SpringBoot作为一些常用开发框架的集合（可以成为脚手架），其自身的自动化配置给我们的开发带来质的改变，不必去担心繁琐的XML配置（反正我到现在都没有去配什么XML文件），用一个application.properties文件就可以在日常开发中完全适用，我们通过各种功能性示例体验了Spring Boot的自动化配置给我们所带来的超便利的新开发方式。&lt;/p&gt;
&lt;p&gt;但是SpringBoot的自动化配置也带入些许隐患(优&amp;gt;&amp;gt;&amp;gt;弊)&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot+log4j日志管理</title>
    <link href="http://yoursite.com/2018/04/16/spring-logback/"/>
    <id>http://yoursite.com/2018/04/16/spring-logback/</id>
    <published>2018-04-16T06:11:56.000Z</published>
    <updated>2018-04-19T16:34:04.322Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于日志"><a href="#关于日志" class="headerlink" title="关于日志"></a>关于日志</h1><p>Spring Boot在所有内部日志中使用Commons Logging，但是默认配置也提供了对常用日志的支持，如：Java Util Logging，Log4J, Log4J2和Logback。每种Logger都可以通过配置使用控制台或者文件输出日志内容。Springboot帮我们整合了这些最常用的日志框架，只需要简单的按照约定配置即可在项目中很快的配置日志相关。</p><p>常用的日志框架(也称为日志门面库)有apache commons logging和slf4j，常用的日志系统(也称为日志实现库)有log4j,log4j2,JUL,logback等。<br>日志框作为门面，日志系统要搭配日志框架来使用，日志框架调用日志系统，在分布式中，还会有专门的分布式日志收集系统，在集群的多个分布式机器中将日志收集并整理的框架有：apache flume，facebook scribe等。<br><a id="more"></a><br>早期Java项目使用最多的日志门面是commons-logging，log4j是推荐的日志实现库，需要的jar包为commons-logging.jar、log4j.jar。</p><p>springboot中默认使用的也是commons logging+logback的组合，我们需要排除并且导入log4j的jar包</p><p>现今java项目推荐的日志门面是slf4j，log4j仍是推荐的日志实现库，需要的jar包为slf4j-api.jar、slf4j-log4j12.jar、log4j.jar，其中绑定包slf4j-log4j12.jar指定了要使用的实现库。</p><p>commons-logging存在osgi问题，但早期项目多使用其作为日志门面，为保证兼容仍使用其作为日志门面，但通过slf4j的静态绑定技术来加载具体的日志库log4j，需要的jar包为commons-logging.jar、jcl-over-slf4j.jar、slf4j-api.jar、slf4j-log4j12.jar、log4j.jar，其中jcl-over-slf4j.jar将日志的接口重定向到slf4j。</p><p>slf4j+log4j组合使用模式：</p><ol><li>slf4j-api-1.5.11.jar</li><li>slf4j-log4j12-1.5.11.jar</li><li>log4j-1.2.15.jar</li><li>log4j.properties(也可以是 log4j.xml)</li></ol><p>JCL+Log4J组合使用模式（即commons-logging+log4j）：</p><ol><li>commons-logging-1.1.jar</li><li>log4j-1.2.15.jar</li><li>log4j.properties</li></ol><p>不同的获取logger的方式</p><p>log4j：（单独使用）<br>import org.apache.log4j.Logger;<br>Logger logger= Logger.getLogger(xx.class);</p><p>slf4j+log4j：（借助LogFactory）<br>import  org.slf4j.Logger;<br>import  org.slf4j.LoggerFactory;<br>Logger logger = LoggerFactory.getLogger(xx.class);</p><p>jcl+log4j:（借助LogFactory）<br>import org.apache.commons.logging.Log;<br>import org.apache.commons.logging.LogFactory;<br>private static Log log = LogFactory.getLog(xx.class);</p><p>可以参考：<a href="https://blog.csdn.net/xydds/article/details/51606010" target="_blank" rel="noopener">https://blog.csdn.net/xydds/article/details/51606010</a>  根据使用场景的不同我们采用不同的日志框架+日志系统。</p><p>总的来说，slf4j与commons-logging只是一个日志门面，实际还是要依赖真正的日志库log4j，虽然slf4j和commons-loggins自带了日志库，但是毕竟log4j才是日志系统（主要功能）。</p><p>现今java项目推荐的日志门面是slf4j，log4j仍是推荐的日志实现库，需要的jar包为slf4j-api.jar、slf4j-log4j12.jar、log4j.jar，其中绑定包slf4j-log4j12.jar指定了要使用的实现库。<br>commons-logging存在osgi问题，但早期项目多使用其作为日志门面，为保证兼容仍使用其作为日志门面，但通过slf4j的静态绑定技术来加载具体的日志库log4j，需要的jar包为commons-logging.jar、jcl-over-slf4j.jar、slf4j-api.jar、slf4j-log4j12.jar、log4j.jar，其中jcl-over-slf4j.jar将日志的接口重定向到slf4j。</p><p>在日志系统中，主要分为三个配置，appenders，layouts和loggers，一般我们做项目时日志记录的历程是这样的，loggers负责记录事假，将事件记录到后转发给合适的appenders，然后appenders使用layouts将事件记录进行格式化，并将其发送给控制台，文件或其他目录位置。</p><p>在强调可重用组件开发的今天，除了自己从头到尾开发一个可重用的日志操作类外， Apache 为我们提供了一个强有力的日志操作包 -Log4j 。　　<br>Log4j 是 Apache 的一个开放源代码项目，通过使用 Log4j ，我们可以控制日志信息输送的目的地是控制台、文件、 GUI 组件、甚至是套接口(socket)服务器、 NT 的事件记录器、 UNIX Syslog 守护进程等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。最令人感兴趣的就 是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。　　<br>此外，通过 Log4j 其他语言接口，您可以在 C 、 C+ + 、 .Net 、 PL/SQL 程序中使用 Log4j ，其语法和用法与在 Java 程序中一样，使得多语言分布式系统得到一个统一一致的日志组件模块。而且，通 过使用各种第三方扩展，您可以很方便地将 Log4j 集成到 J2EE 、 JINI 甚至是 SNMP 应用中。</p><p><img src="/2018/04/16/spring-logback/main.png" alt="logo"></p><p>核心理解为：一个logger可以对应多个appender，一个appender只能对应一个layout。<br>因为logger捕抓到消息后，可以在各种地方输出（控制台，文件，硬盘甚至数据库），一个输出只能对应一种输出格式。</p><p>1.appenders负责输出到目标位置，日志输出目的地，负责日志的输出  （输出到什么 地方）<br>2.layouts负责日志信息的格式化，以什么形式展现<br>3.loggers负责捕抓事件给相应的appenders，如何处理日志</p><p>Log4j提供的layout有以下几种（一般在工作中常用）<br>org.apache.log4j.HTMLLayout（以HTML表格形式布局），<br>org.apache.log4j.PatternLayout（可以灵活地指定布局模式），<br>org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），<br>org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）</p><p>常用的集中appender有：（一般在工作中常用，也可以支持自定义appender）<br>org.apache.log4j.ConsoleAppender（控制台）<br>org.apache.log4j.FileAppender（文件）<br>org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）<br>org.apache.log4j.RollingFileAppender（（文件大小到达指定尺寸的时候产生一个新的文件）<br>org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）</p><p>例如：<br>默认的日志输出如下：<br>2016-04-13 08:23:50.120  INFO 37397 — [           main] org.hibernate.Version                    : HHH000412: Hibernate Core {4.3.11.Final}</p><p>输出内容元素具体如下：（包括这些）</p><p>时间日期 — 精确到毫秒<br>日志级别 — ERROR, WARN, INFO, DEBUG or TRACE<br>进程ID<br>分隔符 — — 标识实际日志的开始<br>线程名 — 方括号括起来（可能会截断控制台输出）<br>Logger名 — 通常使用源代码的类名<br>日志内容</p><h1 id="级别"><a href="#级别" class="headerlink" title="级别"></a>级别</h1><p>在Spring Boot中默认配置了ERROR、WARN和INFO级别的日志输出到控制台。</p><p>这里要说明一下日志的级别：（共分为5级），级别也就是反映出一种status的意思，我们根据关键字可以看出程序运行后记录的状态，看这个级别参数，知道是错误，警告还是正确运行。</p><p>level为logger服务，用来定义日志的级别，他的值可以是： OFF（关闭）FATAL（致命的） ERROR（错误）WARN（警告） INFO（信息）DEBUG （调试） ALL（所有），输出日志的策略由此Level决定，例如：如果logger的Level设置为INFO，那么系统只输出INFO以及以上（WARN、ERROR、FATAL）信息。如果当前logger没有设定Level，那么它在输出日志时采用的策略是：它会使用它继承的Logger的Level作为它自己的Level来处理。如果它的上级也没有设置Level，那么就找上上级，几次类推，直到root为止，（root的Level是不能设为空的，所以最终一定会找到一个Level）。默认root的Level是INFO，其他logger的Level默认都是null，需要手动指定。</p><pre><code>【level】日志输出级别（由小到大，级别最高为DEBUG）    FATAL 0     ERROR 3 严重错误    WARN  4 一般警告    INFO  6 一般显示信息    DEBUG 7 程序调试信息</code></pre><p>可以设置级别： debug&gt;info&gt;error<br>debug ：显示 debug 、 info 、 error<br>info ：显示 info 、 error<br>error ：只 error<br>也就是说只显示比大于等于当前级别的信息</p><p>如果我们不指定appenders输出到哪个文件，那么springboot是默认将信息输入到控制台的，ERROR是产生严重错误的级别，这个在我们产生错误导致程序不运行时显示的，WARN则是警告的情况，INFO则是正常信息的输出，程序正常运行。<br>我们可以通过两种方式切换至DEBUG级别：</p><p>在运行命令后加入–debug标志，如：$ java -jar myapp.jar –debug<br>在application.properties中配置debug=true，该属性置为true的时候，核心Logger（包含嵌入式容器、hibernate、spring）会输出更多内容，但是你自己应用的日志并不会输出为DEBUG级别。</p><p>这是springboot启动的三种方式：<br>第一种是cmd到项目目录然后命令行mvn spring-boot:run启动项目，</p><p>第二种是运行Application.java入口类方法，</p><p>第三种是使用mvn install 生成jar后运行，先到项目根目录<br>mvn install<br>cd target<br>java -jar   xxxx.jar</p><p>上诉改debug也是通过在项目目录下输入指令来设置debug开启。。。</p><p>在Spring Boot中只需要在application.properties文件中进行配置完成日志记录的级别控制。<br>配置格式：logging.level.<em>=LEVEL<br>logging.level：日志级别控制前缀，</em>为包名或Logger名<br>LEVEL：选项TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF</p><p>举例：<br>logging.level.com.didispace=DEBUG：com.didispace包下所有class以DEBUG级别输出<br>logging.level.root=WARN：root日志以WARN级别输出</p><p>其中， level 是日志记录的优先级，分为 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 ALL 或者您定义的级别。 Log4j 建议只使用四个级别 ，优先级从高到低分别是 ERROR 、 WARN 、 INFO 、 DEBUG 。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定 义了 INFO 级别，则应用程序中所有 DEBUG 级别的日志信息将不被打印出来 。</p><h1 id="控制台输出"><a href="#控制台输出" class="headerlink" title="控制台输出"></a>控制台输出</h1><p>控制台选项<br>Threshold=DEBUG:指定日志消息的输出最低层次。<br>ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。<br>Target=System.err：默认情况下是：System.out,指定输出控制台<br>FileAppender 选项<br>Threshold=DEBUF:指定日志消息的输出最低层次。<br>ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。<br>File=mylog.txt:指定消息输出到mylog.txt文件。<br>Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。<br>RollingFileAppender 选项<br>Threshold=DEBUG:指定日志消息的输出最低层次。<br>ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。<br>File=mylog.txt:指定消息输出到mylog.txt文件。<br>Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。<br>MaxFileSize=100KB: 后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。<br>MaxBackupIndex=2:指定可以产生的滚动文件的最大数。</p><h1 id="文件输出"><a href="#文件输出" class="headerlink" title="文件输出"></a>文件输出</h1><p>我们日常工作中经常要进行日志记录，并输出到响应位置的文件夹，甚至是mongoDB数据库（文件储存数据库）中，用于存放数据，我们要怎么用springboot内集成的框架来完成日志记录呢？</p><p>Spring Boot默认配置只会输出到控制台，并不会记录到文件中，但是我们通常生产环境使用时都需要以文件方式记录。</p><p>若要增加文件输出，需要在application.properties中配置logging.file或logging.path属性。</p><p>logging.file，设置文件，可以是绝对路径，也可以是相对路径。如：logging.file=my.log<br>logging.path，设置目录，会在该目录下创建spring.log文件，并写入日志内容，如：logging.path=/var/log</p><p>日志文件会在10Mb大小的时候被截断，产生新的日志文件，默认级别为：ERROR、WARN、INFO<br>也就是说每产生一个10mb大小的日志就会新建一个新的日志用于记录。</p><h1 id="自定义输出日志的格式"><a href="#自定义输出日志的格式" class="headerlink" title="自定义输出日志的格式"></a>自定义输出日志的格式</h1><p>在Spring Boot中可以通过在application.properties配置如下参数控制输出格式：</p><p>logging.pattern.console：定义输出到控制台的样式（不支持JDK Logger）<br>logging.pattern.file：定义输出到文件的样式（不支持JDK Logger）</p><p>一般来说是在日志的自定义文件中配置的：</p><p>如果使用pattern布局就要指定的打印信息的具体格式ConversionPattern，打印参数如下：<br>日志信息格式中几个符号所代表的含义：<br>-X号: X信息输出时左对齐；<br>%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,<br>%d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921<br>%r: 输出自应用启动到输出该log信息耗费的毫秒数<br>%c: 输出日志信息所属的类目，通常就是所在类的全名<br>%t: 输出产生该日志事件的线程名<br>%l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main (TestLog4.Java:10)<br>%x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像Java servlets这样的多客户多线程的应用中。<br>%%: 输出一个”%”字符<br>%F: 输出日志消息产生时所在的文件名称<br>%L: 输出代码中的行号<br>%m: 输出代码中指定的消息,产生的日志具体信息<br>%n: 输出一个回车换行符，Windows平台为”\r\n”，Unix平台为”\n”输出日志信息换行<br>可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如：<br>1)%20c：指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐。<br>2)%-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，”-“号指定左对齐。<br>3)%.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格。<br>4)%20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边较远输出的字符截掉。</p><p>比如：%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L - %m%n 的格式意思就是说：</p><p>时间{指定时间格式} （%p就是表INFO） 所在类（%c{1}只表示类名不是全限定名）：显示调用logger的代码行 - 指定消息及回车（一般最后都会加一个%n）</p><p>具体规范参考：<a href="https://blog.csdn.net/reserved_person/article/details/52849505" target="_blank" rel="noopener">https://blog.csdn.net/reserved_person/article/details/52849505</a><br>             <a href="http://logging.apache.org/" target="_blank" rel="noopener">http://logging.apache.org/</a></p><h1 id="自定义日志文件配置"><a href="#自定义日志文件配置" class="headerlink" title="自定义日志文件配置"></a>自定义日志文件配置</h1><p>由于日志服务一般都在ApplicationContext创建前就初始化了，它并不是必须通过Spring的配置文件控制。因此通过系统属性和传统的Spring Boot外部配置文件依然可以很好的支持日志控制和管理。</p><p>根据不同的日志系统，你可以按如下规则组织配置文件名，就能被正确加载：</p><p>Logback：logback-spring.xml, logback-spring.groovy, logback.xml, logback.groovy<br>Log4j：log4j-spring.properties, log4j-spring.xml, log4j.properties, log4j.xml<br>Log4j2：log4j2-spring.xml, log4j2.xml<br>JUL (Java Util Logging)：logging.properties</p><p>Spring Boot官方推荐优先使用带有-spring的文件名作为你的日志配置（如使用logback-spring.xml，而不是logback.xml）</p><h1 id="讲讲springboot-log4j"><a href="#讲讲springboot-log4j" class="headerlink" title="讲讲springboot+log4j"></a>讲讲springboot+log4j</h1><p>在POM中引入：</p><pre><code>&lt;!-- 如果要使用Log4j来记录，要先把springboot默认的logback给排除掉本身 spring-boot-starter就是包含在spring-boot-starter-web中的，我们要把它重新声明出来去排除spring-boot-starter-logging（默认的Commons Logging日志框架）改用SLF4j日志框架来记录--&gt; &lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;    &lt;exclusions&gt;        &lt;exclusion&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;        &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 引入log4j的相关jar包 --&gt;&lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-log4j&lt;/artifactId&gt;      &lt;version&gt;1.3.8.RELEASE&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>新建log4j.properties文件，是log4j的自定义配置文件</p><pre><code>例：//root是控制整个工程的日志，rootLogger就是根记录器级别，配置根Logger// 此句为将等级为INFO的日志信息输出到stdout和file这两个目的地，// console和file的定义在下面的代码，可以任意起名。// 等级可分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL，// 如果配置OFF则不打出任何信息，如果配置为INFO这样只显示INFO, WARN, ERROR的log信息，// 而DEBUG信息不会被显示，具体讲解可参照第三部分定义配置文件中的logger。// 弃用：log4j.rootCategory=[level],appenderName1,appenderName2...// 改用：log4j.rootLogger = [ level ] , appenderName1 , appenderName2 , …// 级别后面写的就是各appender的名称// 需要分别配置//但是根据最新版本的lig4j来看，log4j.rootCategory仿佛已经被弃用了，取而代之的是rootLogger//这个类拓展了Category这个类，即生成Category对象时同样也生成一个LOgger，所以，建议用rootLogger//log4j.rootCategory=INFO, console, filelog4j.rootLogger=INFO, console, file// 控制台输出log4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L - %m%n// root日志输出// 输出到logs/all.log文件中log4j.appender.file=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.file.file=D:\\logs\\all.loglog4j.appender.file.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L - %m%n// 出来上述的全局输出以外，还有工作中常用的分类输出// 即可以定义一个具体的包的日志输出// 假设在com.mybatis包下设置日志输出//如果是rootCategory，则是控制整个工程log4j.category.com.mybatis=DEBUG,didifilelog4j.appender.didifile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.didifile.file=D:\\logs\\my.loglog4j.appender.didifile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.didifile.layout=org.apache.log4j.PatternLayoutlog4j.appender.didifile.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L ---- %m%n// 除了对包分类，还可以针对级别进行分类// 比如发生了ERROR或者WARN可以输出到不同的文件中//这个算是专门输出异常的文件log4j.logger.error=errorfile// error日志输出log4j.appender.errorfile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.errorfile.file=D:\\logs\\error.loglog4j.appender.errorfile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.errorfile.Threshold = ERROR  ## 输出ERROR级别以上的日志！！log4j.appender.errorfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.errorfile.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L - %m%n</code></pre><p>下面是一段log4j官方对于logger与category的区别：<br>原话是：<br>public class Categoryextends java.lang.Objectimplements AppenderAttachableThis class has been deprecated and replaced by the Logger subclass. It will be kept around to preserve backward compatibility until mid 2003.<br>Logger is a subclass of Category, i.e. it extends Category. In other words, a logger is a category. Thus, all operations that can be performed on a category can be performed on a logger. Internally, whenever log4j is asked to produce a Category object, it will instead produce a Logger object. Log4j 1.2 will never produce Category objects but only Logger instances. In order to preserve backward compatibility, methods that previously accepted category objects still continue to accept category objects.<br>For example, the following are all legal and will work as expected.<br>// Deprecated form:       Category cat = Category.getInstance(“foo.bar”)       // Preferred form for retrieving loggers:       Logger logger = Logger.getLogger(“foo.bar”)   The first form is deprecated and should be avoided.<br>There is absolutely no need for new client code to use or refer to the Category class. Whenever possible, please avoid referring to it or using it.<br>See the short manual for an introduction on this class.<br>See the document entitled preparing for log4j 1.3 for a more detailed discussion.</p><p>Author:<br>Ceki Gülcü, Anders Kristensen</p><p>足以解释这个问题了，logger代替了category这个类的功能，并且比其更加强大和好用。<br> //弃用形式：Category cat = Category.getInstance（“foo.bar”）//用于检索记录器的首选表单：Logger logger = Logger.getLogger（“foo.bar”）第一种形式已被弃用，应该避免。<br>绝对不需要新的客户端代码来使用或引用Category类。只要有可能，请避免提及或使用它。</p><p>下面我们再举一个LOG4J日志配置的例子，将这个日志同时在控制台，文件，回滚文件，发送日志邮件，输出到数据库日志表并且自定义标签等全套功能配置：</p><p> LOG4J 的配置之简单使它遍及于越来越多的应用中了： Log4J 配置文件实现了输出到控制台、文件、回滚文件、发送日志邮件、输出到数据库日志表、自定义标签等全套功能。择其一二使用就够用了，</p><p> //设置级别和多个目的地<br> log4j.rootLogger=DEBUG,CONSOLE,A1,im<br> log4j.addivity.org.apache=true</p><p> //应用于控制台</p><p> log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender<br> log4j.appender.Threshold=DEBUG<br> log4j.appender.CONSOLE.Target=System.out<br> log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout<br> log4j.appender.CONSOLE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n<br> //log4j.appender.CONSOLE.layout.ConversionPattern=[start]%d{DATE}[DATE]%n%p[PRIORITY]%n%x[NDC]%n%t//[THREAD] n%c[CATEGORY]%n%m[MESSAGE]%n%n</p><p> // 应用于文件</p><p> log4j.appender.FILE=org.apache.log4j.FileAppender<br> log4j.appender.FILE.File=file.log<br> log4j.appender.FILE.Append=false<br> log4j.appender.FILE.layout=org.apache.log4j.PatternLayout<br> log4j.appender.FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n<br> // Use this layout for LogFactor 5 analysis</p><p> // 应用于文件回滚</p><p> log4j.appender.ROLLING_FILE=org.apache.log4j.RollingFileAppender<br> log4j.appender.ROLLING_FILE.Threshold=ERROR<br> log4j.appender.ROLLING_FILE.File=rolling.log  // 文件位置 , 也可以用变量 ${java.home} 、 rolling.log<br> log4j.appender.ROLLING_FILE.Append=true       //true: 添加   false: 覆盖<br> log4j.appender.ROLLING_FILE.MaxFileSize=10KB   // 文件最大尺寸<br> log4j.appender.ROLLING_FILE.MaxBackupIndex=1  // 备份数<br> log4j.appender.ROLLING_FILE.layout=org.apache.log4j.PatternLayout<br> log4j.appender.ROLLING_FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n<br> // 应用于 socket<br> log4j.appender.SOCKET=org.apache.log4j.RollingFileAppender<br> log4j.appender.SOCKET.RemoteHost=localhost<br> log4j.appender.SOCKET.Port=5001<br> log4j.appender.SOCKET.LocationInfo=true</p><p> // Set up for Log Facter 5<br> log4j.appender.SOCKET.layout=org.apache.log4j.PatternLayout<br> log4j.appender.SOCET.layout.ConversionPattern=[start]%d{DATE}[DATE]%n%p[PRIORITY]%n%x[NDC]%n%t[THREAD]%n%c[CATEGORY]%n%m[MESSAGE]%n%n </p><p> // Log Factor 5 Appender<br> log4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appender<br> log4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000</p><p> // 发送日志给邮件</p><p> log4j.appender.MAIL=org.apache.log4j.net.SMTPAppender<br> log4j.appender.MAIL.Threshold=FATAL<br> log4j.appender.MAIL.BufferSize=10<br> <a href="http://www.wuset.com" target="_blank" rel="noopener">www.wuset.com</a> “&gt;<a href="mailto:log4j.appender.MAIL.From=web@www.wuset.com" target="_blank" rel="noopener">log4j.appender.MAIL.From=web@www.wuset.com</a><br> log4j.appender.MAIL.SMTPHost=<a href="http://www.wusetu.com" target="_blank" rel="noopener">www.wusetu.com</a><br> log4j.appender.MAIL.Subject=Log4J Message<br> <a href="http://www.wusetu.com" target="_blank" rel="noopener">www.wusetu.com</a> “&gt;<a href="mailto:log4j.appender.MAIL.To=web@www.wusetu.com" target="_blank" rel="noopener">log4j.appender.MAIL.To=web@www.wusetu.com</a><br> log4j.appender.MAIL.layout=org.apache.log4j.PatternLayout<br> log4j.appender.MAIL.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n</p><p> // 用于数据库<br> log4j.appender.DATABASE=org.apache.log4j.jdbc.JDBCAppender<br> log4j.appender.DATABASE.URL=jdbc:mysql://localhost:3306/test<br> log4j.appender.DATABASE.driver=com.mysql.jdbc.Driver<br> log4j.appender.DATABASE.user=root<br> log4j.appender.DATABASE.password=294823013<br> log4j.appender.DATABASE.sql=INSERT INTO LOG4J (Message) VALUES (‘[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n’)<br> log4j.appender.DATABASE.layout=org.apache.log4j.PatternLayout<br> log4j.appender.DATABASE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n</p><p> log4j.appender.A1=org.apache.log4j.DailyRollingFileAppender<br> log4j.appender.A1.File=SampleMessages.log4j<br> log4j.appender.A1.DatePattern=yyyyMMdd-HH’.log4j’<br> log4j.appender.A1.layout=org.apache.log4j.xml.XMLLayout</p><p> // 自定义 Appender</p><p> log4j.appender.im = net.cybercorlin.util.logger.appender.IMAppender</p><p> log4j.appender.im.host = mail.cybercorlin.net<br> log4j.appender.im.username = username<br> log4j.appender.im.password = password<br> log4j.appender.im.recipient = <a href="mailto:corlin@cybercorlin.net" target="_blank" rel="noopener">corlin@cybercorlin.net</a></p><p> log4j.appender.im.layout=org.apache.log4j.PatternLayout<br> log4j.appender.im.layout.ConversionPattern =[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n</p><h1 id="在代码中使用Logger"><a href="#在代码中使用Logger" class="headerlink" title="在代码中使用Logger"></a>在代码中使用Logger</h1><p>以上说了那么多的日志配置，那么当我们配置好后，如何去使用呢？</p><ol><li>得到记录器<br>使用 Log4j ，第一步就是获取日志记录器，这个记录器将负责控制日志信息。其语法为：<br>public static Logger getLogger( String name)<br>通过指定的名字获得记录器，如果必要的话，则为这个名字创建一个新的记录器。 Name 一般取本类的名字，比如：<br>static Logger logger = Logger.getLogger ( ServerWithLog4j.class.getName () ) </li></ol><p>这里注意，看你需要的日志框架是什么来确定你获取Logger对象的方式：</p><pre><code>// slf4j接口使用// getLogger内调用slf4j-log4j.jar的StaticLoggerBinder类的getLogger，获取对应的log4jprivate static final Logger logger = LoggerFactory.getLogger(LogTest.class);// commons-logging接口使用// 与slf4j基本一样，一个用Logger，一个用Logprivate static final Log logger = LoggerFactory.getLogger(LogTest.class);</code></pre><p>　　 </p><ol><li>读取配置文件<br>当获得了日志记录器之后，第二步将配置 Log4j 环境，其语法为：<br>BasicConfigurator.configure () ： 自动快速地使用缺省 Log4j 环境。<br>PropertyConfigurator.configure ( String configFilename) ：读取使用 Java 的特性文件编写的配置文件。<br>DOMConfigurator.configure ( String filename ) ：读取 XML 形式的配置文件。 　 　 </li><li>插入记录信息（格式化日志信息）<br>当上两个必要步骤执行完毕，您就可以轻松地使用不同优先级别的日志记录语句插入到您想记录日志的任何地方，其语法如下：<br>Logger.debug ( Object message ) ;<br>Logger.info ( Object message ) ;<br>Logger.warn ( Object message ) ;<br>Logger.error ( Object message ) ;  </li></ol><p>例如：</p><pre><code>//可以作为基类logger，需要的类可以直接继承//似乎只需要声明其Logger对象就可以使用了。。。public abstract class HelloDao {      private static Logger logger = Logger.getLogger(HelloDao.class);       public static void main(String[] args) {          // 记录debug级别的信息          logger.debug(&quot;This is debug message from Dao.&quot;);          // 记录info级别的信息          logger.info(&quot;This is info message from Dao.&quot;);          // 记录error级别的信息          logger.error(&quot;This is error message from Dao.&quot;);      }  }</code></pre><p>如果这个类作为基类，如J2EE中的BaseDao、BaseAction、BaseService等等，则我们可以将各层的日志信息分类输出到各个文件。</p><p>为了提高效率，我们可以在写日志前增加判断：</p><pre><code>// 记录debug级别的信息  if (logger.isDebugEnabled()) {      logger.debug(&quot;This is debug message from Dao.&quot;);  }    // 记录info级别的信息  if (logger.isInfoEnabled()) {      logger.info(&quot;This is info message from Dao.&quot;);  }  // 记录error级别的信息  logger.error(&quot;This is error message from Dao.&quot;);  </code></pre><p>具体完整的配置可以参考：<a href="https://blog.csdn.net/anlina_1984/article/details/5313023" target="_blank" rel="noopener">https://blog.csdn.net/anlina_1984/article/details/5313023</a><br>                      <a href="http://www.iteye.com/topic/378077" target="_blank" rel="noopener">http://www.iteye.com/topic/378077</a></p><h1 id="Spring-Boot中对log4j进行多环境不同日志级别的控制"><a href="#Spring-Boot中对log4j进行多环境不同日志级别的控制" class="headerlink" title="Spring Boot中对log4j进行多环境不同日志级别的控制"></a>Spring Boot中对log4j进行多环境不同日志级别的控制</h1><p>根据开发-测试-生产阶段的多环境log配置，SpringBoot也为此量身打造了基于多环境的级别控制</p><p>开发-测试-生产环境的级别控制</p><p>创建多环境配置文件<br>application-dev.properties：开发环境<br>application-test.properties：测试环境<br>application-prod.properties：生产环境<br>application.properties中添加属性：spring.profiles.active=dev（默认激活application-dev.properties配置）<br>application-dev.properties和application-test.properties配置文件中添加日志级别定义：logging.level.com.didispace=DEBUG<br>application-prod.properties配置文件中添加日志级别定义：logging.level.com.didispace=INFO</p><p>通过上面的定义，根据logging.level.com.didispace在不同环境的配置文件中定义了不同的级别，但是我们已经把日志交给了log4j管理，看看我们log4j.properties中对com.didispace包下的日志定义是这样的，固定定义了DEBUG级别，并输出到名为didifile定义的appender中。</p><pre><code>// LOG4J配置log4j.category.com.didispace=DEBUG, didifile   </code></pre><p>那么，要如何动态的改变这个DEBUG级别呢？用到参数调用，用SPEL表达式来实现动态替换</p><pre><code>// 动态LOG4J配置log4j.category.com.didispace=${logging.level.com.didispace}, didifile </code></pre><p>对于不同环境的使用人员也不需要改变代码或打包文件，只需要通过执行命令中参加参数即可，比如我想采用生产环境的级别，那么我可以这样运行应用：更改对应环境配置文件即可，而不是去大费周章的修改代码了。</p><pre><code>java -jar xxx.jar --spring.profiles.active=prod</code></pre><h1 id="Springboot使用slf4j-logback"><a href="#Springboot使用slf4j-logback" class="headerlink" title="Springboot使用slf4j+logback"></a>Springboot使用slf4j+logback</h1><p>我们添加spring-boot-starter-web这个包后，spring-boot-starter-web依赖spring-boot-starter，而spring-boot-starter其内部有一个jar包是spring-boot-starter-logging包含的就是slf4j-api.jar和logback-core.jar。</p><p>所以说我们若决定用slf4j+logback的组合，那么就添加这个spring-boot-starter-web包即可。</p><p><img src="/2018/04/16/spring-logback/p1.png" alt="logo"></p><p>我们在日志冲突中若决定使用其他日志框架或其他日志系统的时候，只需要更改jar包即可，若是我们想采用log4j的话，那我们就需要把这个spring-boot-starter-logging给exclusion掉才能使用。<br>比如我们要使用slf4j+log4j的组合的话，那么要去掉spring-boot-starter-logging，添加spring-boot-starter-log4j，里面包含了slf4j-api+log4j的相关jar包。</p><p>无论从设计上还是实现上，Logback相对log4j而言有了相对多的改进。不过尽管难以一一细数，这里还是列举部分理由为什么选择logback而不是log4j。牢记logback与log4j在概念上面是很相似的，它们都是有同一群开发者建立。所以如果你已经对log4j很熟悉，你也可以很快上手logback。如果你喜欢使用log4j,你也许会迷上使用logback。</p><p>基于我们先前在log4j上的工作，logback 重写了内部的实现，在某些特定的场景上面，甚至可以比之前的速度快上10倍。在保证logback的组件更加快速的同时，同时所需的内存更加少。</p><p>Logback 历经了几年，数不清小时数的测试。尽管log4j也是测试过的，但是Logback的测试更加充分，跟log4j不在同一个级别。我们认为，这正是人们选择Logback而不是log4j的最重要的原因。人们都希望即使在恶劣的条件下，你的日记框架依然稳定而可靠。</p><p>所以这才是我们考虑用springboot原生集成的WEB开发包spring-boot-starter-web，里面就天然集成了slf4j+logback</p><p>日志记录相关依赖，首选Spring-Boot”原生态”的logback，也就是说我们在实际开发中，现在直接使用spring-boot-starter-web自带的slf4j+logback即可。</p><p>Logback是由 log4j创始人设计的又一个开源日志组件</p><p>logback当前分成三个模块：<br>logback-core<br>logback- classic<br>logback-access</p><p>logback-core是其它两个模块的基础模块</p><p>logback-classic 非常自然的实现了SLF4J，logback-classic 包下包括了logback-core+slf4j，我们不用额外导入。</p><p>logback-classic中的登陆类自然的实现了SLF4J。当你使用 logback-classic作为底层实现时，涉及到LF4J日记系统的问题你完全不需要考虑。更进一步来说，由于 logback-classic强烈建议使用SLF4J作为客户端日记系统实现，如果需要切换到log4j或者其他，你只需要替换一个jar包即可，不需要去改变那些通过SLF4J API 实现的代码。这可以大大减少更换日记系统的工作量。</p><h2 id="关于logback的配置"><a href="#关于logback的配置" class="headerlink" title="关于logback的配置"></a>关于logback的配置</h2><p>使用XML配置文件或者Groovy（Gradle区别于maven所建工程，Gradle基于Groovy语言，而maven基于xml）</p><p>配置logback的传统方法是通过XML文件。在文档中，大部分例子都是是用XML语法。但是，对于logback版本0.9.22，通过Groovy编写的配置文件也得到支持。相比于XML，Groovy风格的配置文件更加直观，连贯和简短的语法。</p><p>现在， 已经有一个工具自动把logback.xml文件迁移至logback.groovy。</p><p>若是我们要使用groovy构造工程的话，要在eclipse对应版本上安装groovy的集成开发环境，以为这是和maven类似的第三方集成库工程系统。</p><p>这些就不明说了，关于如何构建groovy工程，在专门的文章中有阐述。</p><p>不过这里不能像log4j那样直接使用properties文件来配置，我觉得有点麻烦。。。</p><p>先来看看logback中的日志配置与log4j又有那些不一样</p><p>如果配置文件 logback-test.xml 和 logback.xml 都不存在，那么 logback 默认地会调用BasicConfigurator ，创建一个最小化配置。最小化配置由一个关联到根 logger 的ConsoleAppender 组成。输出用模式为%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n 的 PatternLayoutEncoder 进行格式化。root logger 默认级别是 DEBUG。</p><p>在springboot中默认查找logback.xml和logback-spring.xml文件。</p><p>logback.xml配置如下：</p><pre><code>&lt;configuration&gt;          &lt;!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,%i索引【从数字0开始递增】,,, --&gt;          &lt;!-- appender是configuration的子节点，是负责写日志的组件。 --&gt;      &lt;!-- ConsoleAppender：把日志输出到控制台 --&gt;      &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;              &lt;encoder&gt;                  &lt;pattern&gt;%d %p (%file:%line\)- %m%n&lt;/pattern&gt;                &lt;!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 --&gt;              &lt;charset&gt;UTF-8&lt;/charset&gt;             &lt;/encoder&gt;          &lt;/appender&gt;          &lt;!-- RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 --&gt;      &lt;!-- 以下的大概意思是：1.先按日期存日志，日期变了，将前一天的日志文件名重命名为XXX%日期%索引，新的日志仍然是sys.log --&gt;      &lt;!--             2.如果日期没有发生变化，但是当前日志的文件大小超过1KB时，对当前日志进行分割 重命名--&gt;      &lt;appender name=&quot;syslog&quot;              class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;              &lt;File&gt;log/sys.log&lt;/File&gt;              &lt;!-- rollingPolicy:当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。 --&gt;          &lt;!-- TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动 --&gt;          &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;                  &lt;!-- 活动文件的名字会根据fileNamePattern的值，每隔一段时间改变一次 --&gt;              &lt;!-- 文件名：log/sys.2017-12-05.0.log --&gt;              &lt;fileNamePattern&gt;log/sys.%d.%i.log&lt;/fileNamePattern&gt;               &lt;!-- 每产生一个日志文件，该日志文件的保存期限为30天 --&gt;               &lt;maxHistory&gt;30&lt;/maxHistory&gt;                 &lt;timeBasedFileNamingAndTriggeringPolicy  class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;                      &lt;!-- maxFileSize:这是活动文件的大小，默认值是10MB,本篇设置为1KB，只是为了演示 --&gt;                    &lt;maxFileSize&gt;1KB&lt;/maxFileSize&gt;                  &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;              &lt;/rollingPolicy&gt;              &lt;encoder&gt;                  &lt;!-- pattern节点，用来设置日志的输入格式 --&gt;              &lt;pattern&gt;                      %d %p (%file:%line\)- %m%n                &lt;/pattern&gt;                  &lt;!-- 记录日志的编码 --&gt;              &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt;             &lt;/encoder&gt;          &lt;/appender&gt;          &lt;!-- 控制台输出日志级别 --&gt;      &lt;root level=&quot;info&quot;&gt;              &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;          &lt;/root&gt;          &lt;!-- 指定项目中某个包，当有日志操作行为时的日志记录级别 --&gt;      &lt;!-- com.appley为根包，也就是只要是发生在这个根包下面的所有日志操作行为的权限都是DEBUG --&gt;      &lt;!-- 级别依次为【从高到低】：FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE  --&gt;      &lt;logger name=&quot;com.appleyk&quot; level=&quot;DEBUG&quot;&gt;              &lt;appender-ref ref=&quot;syslog&quot; /&gt;          &lt;/logger&gt;      &lt;/configuration&gt; </code></pre><p>可以看出，logback在configuration标签中进行配置，包含3个最主要的子标签appender，logger和root<br>可以这样描述配置文件的基本结构：以<configuration>开头，后面有零个或多个<appender>元素，有零个或多个<logger>元素，有最多一个<root>元素。</root></logger></appender></configuration></p><p>1.根节点<configuration>，包含下面三个属性：<br>-scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。<br>-scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。<br>-debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。</configuration></p><p>例如：</p><pre><code>&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; 　　&lt;!--其他配置省略--&gt; &lt;/configuration&gt;</code></pre><p>2.子节点</p><p>-<contextname>：用来设置上下文名称，每个logger都关联到logger上下文，默认上下文名称为default。但可以使用<contextname>设置成其他名字，用于区分不同应用程序的记录。一旦设置，不能修改。<br>其实就是用于标记这个logback配置文件，作为一个全局名称来使用</contextname></contextname></p><contextname>myAppName</contextname> <p>-子节点<property>：用来定义变量值，它有两个属性name和value，通过<property>定义的值会被插入到logger上下文中，可以使“${}”来使用变量。<br>就是自定义配置参数的意思，用户可以通过这个xml文件来修改参数。<br>name: 变量的名称<br>value: 的值时变量定义的值</property></property></p><p>例如：</p><pre><code>&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; 　&lt;property name=&quot;APP_Name&quot; value=&quot;myAppName&quot; /&gt; 　&lt;contextName&gt;${APP_Name}&lt;/contextName&gt; 　&lt;!--其他配置省略--&gt; &lt;/configuration&gt;</code></pre><p>-子节点<timestamp>：获取时间戳字符串，他有两个属性key和datePattern<br>key: 标识此<timestamp> 的名字；<br>datePattern: 设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循java.txt.SimpleDateFormat的格式。<br>例如：</timestamp></timestamp></p><pre><code>&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; 　&lt;timestamp key=&quot;bySecond&quot; datePattern=&quot;yyyyMMdd&apos;T&apos;HHmmss&quot;/&gt; 　&lt;contextName&gt;${bySecond}&lt;/contextName&gt; 　&lt;!-- 其他配置省略--&gt; &lt;/configuration&gt;</code></pre><p>-主要子节点<appender>：负责写日志的组件，它有两个必要属性name和class。name指定appender名称，class指定appender的全限定名</appender></p><p>（1）ConsoleAppender 把日志输出到控制台，有以下子节点：</p><p><encoder>：对日志进行格式化。（具体参数稍后讲解 ）</encoder></p><p><target>：字符串System.out(默认)或者System.err（区别不多说了）</target></p><pre><code>　&lt;configuration&gt; 　　　　　　&lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; 　　　　　　&lt;encoder&gt; 　　　　　　　　&lt;pattern&gt;%-4relative [%thread] %-5level %logger{35} - %msg %n&lt;/pattern&gt; 　　　　　　&lt;/encoder&gt; 　　　　　　&lt;/appender&gt; &lt;!--root用于指定级别 ref指向对应的appender的name属性值--&gt;　　　　　　&lt;root level=&quot;DEBUG&quot;&gt; 　　　　　　　　&lt;appender-ref ref=&quot;STDOUT&quot; /&gt; 　　　　　　&lt;/root&gt; 　&lt;/configuration&gt;</code></pre><p>上述配置表示把&gt;=DEBUG级别的日志都输出到控制台</p><p>（2）FileAppender：把日志添加到文件，有以下子节点：<br>　<file>：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。<br>　　　　　　<append>：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。<br>　　　　　　<encoder>：对记录事件进行格式化。（具体参数稍后讲解 ）<br>　　　　　　<prudent>：如果是 true，日志会被安全的写入文件，即使其他的FileAppender也在向此文件做写入操作，效率低，默认是 false。<br>例如：</prudent></encoder></append></file></p><pre><code>&lt;configuration&gt; 　　&lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; 　　　　　&lt;file&gt;testFile.log&lt;/file&gt; 　　　　　&lt;append&gt;true&lt;/append&gt; 　　　　　&lt;encoder&gt; 　　　　　　　&lt;pattern&gt;%-4relative [%thread] %-5level %logger{35} - %msg%n&lt;/pattern&gt; 　　　　　&lt;/encoder&gt; 　　&lt;/appender&gt;     &lt;!-- DEBUG以上的级别都会被输出 ref指向对应的appender的name属性值--&gt;　　&lt;root level=&quot;DEBUG&quot;&gt; 　　　　  &lt;appender-ref ref=&quot;FILE&quot; /&gt; 　　&lt;/root&gt; &lt;/configuration&gt;</code></pre><p>上述配置表示把&gt;=DEBUG级别的日志都输出到testFile.log</p><p>（3）RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。有以下子节点：</p><p><file>：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。</file></p><p><append>：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。    </append></p><rollingpolicy>:当发生滚动时，决定RollingFileAppender的行为，涉及文件移动和重命名。属性class定义具体的滚动策略类<br>class=”ch.qos.logback.core.rolling.TimeBasedRollingPolicy”： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。有以下子节点：<br><filenamepattern>：必要节点，包含文件名及“%d”转换符，“%d”可以包含一个java.text.SimpleDateFormat指定的时间格式，如：%d{yyyy-MM}。<br>如果直接使用 %d，默认格式是 yyyy-MM-dd。RollingFileAppender的file字节点可有可无，通过设置file，可以为活动文件和归档文件指定不同位置，当前日志总是记录到file指定的文件（活动文件），活动文件的名字不会改变；<br>如果没设置file，活动文件的名字会根据fileNamePattern 的值，每隔一段时间改变一次。“/”或者“\”会被当做目录分隔符。<br><maxhistory>:<br>可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且<maxhistory>是6，则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。<br><br>class=”ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy”： 查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动。只有一个节点:<br><maxfilesize>:这是活动文件的大小，默认值是10MB。<br><prudent>：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。<br><br><triggeringpolicy>: 告知 RollingFileAppender 合适激活滚动。<br>class=”ch.qos.logback.core.rolling.FixedWindowRollingPolicy” 根据固定窗口算法重命名文件的滚动策略。有以下子节点：<br><minindex>:窗口索引最小值<br><maxindex>:窗口索引最大值，当用户指定的窗口过大时，会自动将窗口设置为12。<br><filenamepattern>:必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为 mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz 或者 没有log%i.log.zip<br><br>例如：<br><br>    <configuration><br>    　　<appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"><br>    　　　　　<rollingpolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"><br>    　　　　　　　<filenamepattern>logFile.%d{yyyy-MM-dd}.log</filenamepattern><br>    　　　　　　　<maxhistory>30</maxhistory><br>    　　　　　</rollingpolicy><br>    　　　　　<encoder><br>    　　　　　　　<pattern>%-4relative [%thread] %-5level %logger{35} - %msg%n</pattern><br>    　　　　　</encoder><br>    　　</appender><br><br>    　　<root level="DEBUG"><br>    　　　　　<appender-ref ref="FILE"><br>    　　</appender-ref></root><br>    </configuration><br><br>上述配置表示每天生成一个日志文件，保存30天的日志文件。<br>　　　　　　　　<br>    <configuration><br>    　　<appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"><br>    　　　　　<file>test.log</file><br>             <rollingpolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy"><br>    　　　　　　　<filenamepattern>tests.%i.log.zip</filenamepattern><br>    　　　　　　　<minindex>1</minindex><br>    　　　　　　　<maxindex>3</maxindex><br>    　　　　　</rollingpolicy> <pre><code>　　　　　&lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; 　　　　　　　&lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt; 　　　　　&lt;/triggeringPolicy&gt; 　　　　　&lt;encoder&gt; 　　　　　　　&lt;pattern&gt;%-4relative [%thread] %-5level %logger{35} - %msg%n&lt;/pattern&gt; 　　　　　&lt;/encoder&gt; 　　&lt;/appender&gt; 　　&lt;root level=&quot;DEBUG&quot;&gt; 　　　　　&lt;appender-ref ref=&quot;FILE&quot; /&gt; 　　&lt;/root&gt; &lt;/configuration&gt;</code></pre><p>上述配置表示按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。</p><p>　　　　　　<encoder>：对记录事件进行格式化。负责两件事，一是把日志信息转换成字节数组，二是把字节数组写入到输出流。<br>PatternLayoutEncoder 是唯一有用的且默认的encoder ，有一个<pattern>节点，用来设置日志的输入格式。使用“%”加“转换符”方式，如果要输出“%”，则必须用“\”对“\%”进行转义。</pattern></encoder></p><p>(4) 还有SocketAppender、SMTPAppender、DBAppender、SyslogAppender、SiftingAppender，并不常用，这里就不详解了。<br>大家可以参考官方文档（<a href="http://logback.qos.ch/documentation.html），还可以编写自己的Appender。" target="_blank" rel="noopener">http://logback.qos.ch/documentation.html），还可以编写自己的Appender。</a></p><p>-子节点<loger>：用来设置某一个包或具体的某一个类的日志打印级别、以及指定<appender>。<loger>仅有一个name属性，一个可选的level和一个可选的addtivity属性。</loger></appender></loger></p><p>可以包含零个或多个<appender-ref>元素，标识这个appender将会添加到这个loger<br>name: 用来指定受此loger约束的某一个包或者具体的某一个类。<br>level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前loger将会继承上级的级别。<br>addtivity: 是否向上级loger传递打印信息。默认是true。同<loger>一样，可以包含零个或多个<appender-ref>元素，标识这个appender将会添加到这个loger。</appender-ref></loger></appender-ref></p><p>常用loger配置有：</p><pre><code>&lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt;&lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicBinder&quot; level=&quot;TRACE&quot; /&gt;&lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicExtractor&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.SQL&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.engine.QueryParameters&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.engine.query.HQLQueryPlan&quot; level=&quot;DEBUG&quot; /&gt;&lt;!--myibatis log configure--&gt;&lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;&lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;DEBUG&quot;/&gt;</code></pre><p>-子节点<root>:它也是<loger>元素，但是它是根loger,是所有<loger>的上级。只有一个level属性，因为name已经被命名为”root”,且已经是最上级了。<br>level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，不能设置为INHERITED或者同义词NULL。 默认是DEBUG。</loger></loger></root></p><p>基本上常用的子节点已经介绍完了，再给个常用的DEMO吧：</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;false&quot;&gt;&lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt;&lt;property name=&quot;LOG_HOME&quot; value=&quot;/home&quot; /&gt;&lt;!-- 控制台输出 --&gt;&lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;&lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;/appender&gt;&lt;!-- 按照每天生成日志文件 --&gt;&lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;&lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;&lt;!--日志文件输出的文件名--&gt;&lt;FileNamePattern&gt;${LOG_HOME}/TestWeb.log.%d{yyyy-MM-dd}.log&lt;/FileNamePattern&gt;&lt;!--日志文件保留天数--&gt;&lt;MaxHistory&gt;30&lt;/MaxHistory&gt;&lt;/rollingPolicy&gt;&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;&lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;!--日志文件最大的大小--&gt;&lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt;&lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt;&lt;/triggeringPolicy&gt;&lt;/appender&gt;&lt;!-- 日志输出级别 --&gt;&lt;root level=&quot;INFO&quot;&gt;&lt;appender-ref ref=&quot;STDOUT&quot; /&gt;&lt;/root&gt;&lt;/configuration&gt;</code></pre><p>对应的JAVA代码应该怎么记录呢？</p><pre><code>import org.slf4j.Logger;  import org.slf4j.LoggerFactory;public class App {　　private final static Logger logger = LoggerFactory.getLogger(App.class);　　　　public static void main(String[] args) {　　　　　　logger.info(&quot;logback-info 成功了&quot;);　　　　　　logger.error(&quot;logback-error 成功了&quot;);　　　　　　logger.debug(&quot;logback-debug 成功了&quot;);　　　　}}</code></pre><p>与Log4j的不同，是用LoggerFactory的getLogger(getClass())来获取Logger对象的，这里要注意，若是用logback则用这种方式。</p><p>参考: <a href="https://blog.csdn.net/haidage/article/details/6794509/" target="_blank" rel="noopener">https://blog.csdn.net/haidage/article/details/6794509/</a><br>      <a href="https://www.cnblogs.com/warking/p/5710303.html" target="_blank" rel="noopener">https://www.cnblogs.com/warking/p/5710303.html</a><br>      <a href="https://blog.csdn.net/liuweixiao520/article/details/78900779" target="_blank" rel="noopener">https://blog.csdn.net/liuweixiao520/article/details/78900779</a></p><h1 id="springboot整合slf4j-log4j2"><a href="#springboot整合slf4j-log4j2" class="headerlink" title="springboot整合slf4j+log4j2"></a>springboot整合slf4j+log4j2</h1><p>相当于又把logback的缺点重新改进，过程可以说是很有意思的，又log4j在性能上的缺失–》演变到使用性能更好的logback–》又演变到更好的log4j2框架上，可以说，选择很多种。。。</p><p>Log4j 升级Log4j 2 后的性能简单比较：</p><p><img src="/2018/04/16/spring-logback/p2.png" alt="logo"></p><p>可见在同步日志模式下, Logback的性能是最糟糕的.<br>而log4j2的性能无论在同步日志模式还是异步日志模式下都是最佳的.</p><p>其根本原因在于log4j2使用了LMAX, 一个无锁的线程间通信库代替了, logback和log4j之前的队列. 并发性能大大提升。关于LMAX，可以单独总结。</p><h2 id="关于log4j2的新特性"><a href="#关于log4j2的新特性" class="headerlink" title="关于log4j2的新特性"></a>关于log4j2的新特性</h2><p>-丢数据这种情况少，可以用来做审计功能。而且自身内部报的exception会被发现，但是logback和log4j不会。<br>-log4j2使用了disruptor技术，在多线程环境下，性能高于logback等10倍以上。<br>-(garbage free）之前的版本会产生非常多的临时对象，会造成GC频繁，log4j2则在这方面上做了优化，减少产生临时对象。尽可能少的GC<br>-利用插件系统，使得扩展新的appender,filter,layout等变得容易，log4j不可以扩展 插件？？？？<br>-因为插件系统的简单性，所以在配置的时候，可以不用具体指定所要处理的类型。class<br>-可以自定义level<br>-Java 8 lambda support for lazy logging<br>-Support for Message objects<br>-对filter的功能支持的更强大<br>-系统日志(Syslog)协议supports both TCP and UDP<br>-利用jdk1.5并发的特性，减少了死锁的发生。<br>-Socket LogEvent SerializedLayout<br>-支持kafka queue</p><p>第一步：按照上面所说的，springboot本身默认集成的是logback，我们若是想用其他的，需要修改pom</p><p>去掉spring-boot-starter-logging</p><pre><code>&lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;&lt;/dependency&gt;</code></pre><p>添加Log4j2</p><pre><code>&lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>第二步：由于本身的properties默认配置对log4j不太友好，所以依然采用XML的外部文件配置形式<br>然后需要在resource下面添加log4j2.xml配置文件，当然了如果你不添加，springboo会提示你没有对应文件，并使用默认的配置文件，这个时候级别可以在application.properties中配置。</p><p>logging.level.root=error </p><p>当然了，使用配置文件，配置可以多样化,下面是默认的log4j2配置,log4j2支持xml、json、yml格式的配置<br><img src="/2018/04/16/spring-logback/p3.png" alt="logo"></p><p>例如：</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;  &lt;configuration status=&quot;OFF&quot;&gt;    &lt;appenders&gt;      &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;        &lt;PatternLayout pattern=&quot;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n&quot;/&gt;      &lt;/Console&gt;    &lt;/appenders&gt;    &lt;loggers&gt;      &lt;root level=&quot;error&quot;&gt;        &lt;appender-ref ref=&quot;Console&quot;/&gt;      &lt;/root&gt;    &lt;/loggers&gt;  &lt;/configuration&gt;</code></pre><p>大体上与log4j没什么区别。</p><p>appenders里设置日志的输出方式、级别和格式<br>loggers里设置全局的级别和绑定appenders里的name</p><p>File 日志输出到文件，可配置覆盖还是追加<br>RollingFile “滚动文件”可作为按日输出日志的方式<br>Console 控制台日志</p><p>PatternLayout 格式化输出日志</p><p>ThresholdFilter“阈值筛选器” 可单独设置appender的输出级别</p><p>loggers里需要匹配每个appender的名称 name</p><p>我的服务一般放在linux服务器上跑，可能要实时查看日志，现有这个需求“我要打印到控制台的日志级别为Error，日志文件里保存的是INFO级别的日志”这样在产生错误的时候，就不会被大量无用的代码干扰。<br>要使用ThresholdFilter，配置如下：</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;OFF&quot;&gt;    &lt;Appenders&gt;        &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）--&gt;            &lt;ThresholdFilter level=&quot;ERROR&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt;            &lt;PatternLayout pattern=&quot;%d{yyyy.MM.dd &apos;at&apos; HH:mm:ss z} %-5level %class{36} %M() @%L - %msg%n&quot;/&gt;        &lt;/Console&gt;        &lt;File name=&quot;ERROR&quot; fileName=&quot;logs/error.log&quot; append=&quot;false&quot;&gt;            &lt;ThresholdFilter level=&quot;error&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt;            &lt;PatternLayout pattern=&quot;%d{yyyy.MM.dd &apos;at&apos; HH:mm:ss z} %-5level %class{36} %M() @%L - %msg%n&quot;/&gt;        &lt;/File&gt;        &lt;!--这个会打印出所有的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档--&gt;        &lt;RollingFile name=&quot;RollingFile&quot; fileName=&quot;logs/app.log&quot;                     filePattern=&quot;log/$${date:yyyy-MM}/app-%d{MM-dd-yyyy}-%i.log.gz&quot;&gt;            &lt;PatternLayout pattern=&quot;%d{yyyy.MM.dd &apos;at&apos; HH:mm:ss z} %-5level %class{36} %M() @%L - %msg%n&quot;/&gt;            &lt;SizeBasedTriggeringPolicy size=&quot;5MB&quot;/&gt;        &lt;/RollingFile&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;INFO&quot;&gt;            &lt;appender-ref ref=&quot;ERROR&quot; /&gt;            &lt;appender-ref ref=&quot;RollingFile&quot;/&gt;            &lt;appender-ref ref=&quot;Console&quot;/&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt; </code></pre><p>三个appender：Console、File、RollingFile </p><ul><li>Console 通过ThresholdFilter过滤规则只输出ERROR级别的错误(onMatch=”ACCEPT” onMismatch=”DENY” 匹配到的接受，没有匹配的走人) </li><li>File 也通过ThresholdFilter的方式输出到日志，当然了append=”false” 会在服务每次启动的时候清空日志(覆盖) </li><li>RollingFile 因为日志全局设置的为INFO，所以不需要ThresholdFilter,这里只需要指定filePattern和SizeBasedTriggeringPolicy就行了</li></ul><h2 id="多环境分别使用不同的log4j2的配置文件"><a href="#多环境分别使用不同的log4j2的配置文件" class="headerlink" title="多环境分别使用不同的log4j2的配置文件"></a>多环境分别使用不同的log4j2的配置文件</h2><p>在多环境中（开发-测试-生产），有不同的properties文件，每个文件对应的日志配置不一样，那么我们如何均衡这种关系。<br><img src="/2018/04/16/spring-logback/p4.png" alt="logo"></p><p>主properties配置文件中激活指定的properties配置文件，如激活 dev的properties文件只需添加“spring.profiles.active=dev ”即可，这是进入”application-dev.properties”配置文件，在该文件中添加“logging.config=classpath:log4j2-dev.xml”，这时候dev开发环境将使用“log4j2-dev.xml”配置信息来输出日志。<br>这样就对应了每个环境下的配置文件能够对应不同的日志系统</p><p>参考：<a href="https://www.oschina.net/translate/reasons-to-prefer-logbak-over-log4j" target="_blank" rel="noopener">https://www.oschina.net/translate/reasons-to-prefer-logbak-over-log4j</a><br>      <a href="https://blog.csdn.net/liuweixiao520/article/details/78900779" target="_blank" rel="noopener">https://blog.csdn.net/liuweixiao520/article/details/78900779</a><br>      <a href="https://logging.apache.org/log4j/2.x/manual/configuration.html#AutomaticConfiguration" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/manual/configuration.html#AutomaticConfiguration</a>           </p></appender></configuration></filenamepattern></maxindex></minindex></triggeringpolicy></prudent></maxfilesize></maxhistory></maxhistory></filenamepattern></rollingpolicy>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;关于日志&quot;&gt;&lt;a href=&quot;#关于日志&quot; class=&quot;headerlink&quot; title=&quot;关于日志&quot;&gt;&lt;/a&gt;关于日志&lt;/h1&gt;&lt;p&gt;Spring Boot在所有内部日志中使用Commons Logging，但是默认配置也提供了对常用日志的支持，如：Java Util Logging，Log4J, Log4J2和Logback。每种Logger都可以通过配置使用控制台或者文件输出日志内容。Springboot帮我们整合了这些最常用的日志框架，只需要简单的按照约定配置即可在项目中很快的配置日志相关。&lt;/p&gt;
&lt;p&gt;常用的日志框架(也称为日志门面库)有apache commons logging和slf4j，常用的日志系统(也称为日志实现库)有log4j,log4j2,JUL,logback等。&lt;br&gt;日志框作为门面，日志系统要搭配日志框架来使用，日志框架调用日志系统，在分布式中，还会有专门的分布式日志收集系统，在集群的多个分布式机器中将日志收集并整理的框架有：apache flume，facebook scribe等。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
      <category term="logback" scheme="http://yoursite.com/tags/logback/"/>
    
  </entry>
  
  <entry>
    <title>LDAP服务器结合Springboot</title>
    <link href="http://yoursite.com/2018/04/15/LDAP/"/>
    <id>http://yoursite.com/2018/04/15/LDAP/</id>
    <published>2018-04-15T05:07:42.000Z</published>
    <updated>2018-04-15T05:51:12.984Z</updated>
    
    <content type="html"><![CDATA[<p>LDAP（轻量级目录访问协议，Lightweight Directory Access Protocol)是实现提供被称为目录服务的信息服务。目录服务是一种特殊的数据库系统，其专门针对读取，浏览和搜索操作进行了特定的优化。目录一般用来包含描述性的，基于属性的信息并支持精细复杂的过滤能力。目录一般不支持通用数据库针对大量更新操作操作需要的复杂的事务管理或回卷策略。就是说LDAP精于读取和查询，在写入功能上表现较差，不支持事务和回滚操作，而目录服务的更新则一般都非常简单。这种目录可以存储包括个人信息、web链结、jpeg图像等各种信息。为了访问存储在目录中的信息，就需要使用运行在TCP/IP 之上的访问协议—LDAP。<br><a id="more"></a></p><p>目录简单来说就是一种树状结构的数据库。</p><p>而目录服务是一种以树状结构的目录数据库为基础，外加各种访问协议的信息查询服务。</p><p>顾名思义，目录天生就是用来查询的。</p><p>目录服务是由目录数据库和一套访问协议组成的系统。类似以下的信息适合储存在目录中：</p><p>企业员工信息，如姓名、电话、邮箱等；<br>公用证书和安全密钥；<br>公司的物理设备信息，如服务器，它的IP地址、存放位置、厂商、购买时间等；<br>LDAP是轻量目录访问协议(Lightweight Directory Access Protocol)的缩写，LDAP是从X.500目录访问协议的基础上发展过来的，目前的版本是v3.0。与LDAP一样提供类似的目录服务软件还有ApacheDS、Active Directory、Red Hat Directory Service 。</p><h1 id="LDAP特点"><a href="#LDAP特点" class="headerlink" title="LDAP特点"></a>LDAP特点</h1><p>LDAP的结构用树来表示，而不是用表格。正因为这样，就不能用SQL语句了<br>LDAP可以很快地得到查询结果，不过在写方面，就慢得多<br>LDAP提供了静态数据的快速查询方式<br>Client/server模型，Server 用于存储数据，Client提供操作目录信息树的工具<br>这些工具可以将数据库的内容以文本格式（LDAP 数据交换格式，LDIF）呈现在您的面前<br>LDAP是一种开放Internet标准，LDAP协议是跨平台的Interent协议</p><h1 id="LDAP组织数据的方式"><a href="#LDAP组织数据的方式" class="headerlink" title="LDAP组织数据的方式"></a>LDAP组织数据的方式</h1><p><img src="/2018/04/15/LDAP/p1.png" alt="logo"></p><h2 id="Entry"><a href="#Entry" class="headerlink" title="Entry"></a>Entry</h2><p>条目，也叫记录项，是LDAP中最基本的颗粒，就像字典中的词条，或者是数据库中的记录。通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的。</p><p>dn：每一个条目都有一个唯一的标识名（distinguished Name ，DN），如上图中一个 dn：”cn=baby,ou=marketing,ou=people,dc=mydomain,dc=org” 。通过DN的层次型语法结构，可以方便地表示出条目在LDAP树中的位置，通常用于检索。</p><p>rdn：一般指dn逗号最左边的部分，如cn=baby。它与RootDN不同，RootDN通常与RootPW同时出现，特指管理LDAP中信息的最高权限用户。</p><p>Base DN：LDAP目录树的最顶部就是根，也就是所谓的“Base DN”，如”dc=mydomain,dc=org”。</p><h2 id="Attribute"><a href="#Attribute" class="headerlink" title="Attribute"></a>Attribute</h2><p>每个条目都可以有很多属性（Attribute），比如常见的人都有姓名、地址、电话等属性。每个属性都有名称及对应的值，属性值可以有单个、多个，比如你有多个邮箱。</p><p>属性不是随便定义的，需要符合一定的规则，而这个规则可以通过schema制定。比如，如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson，那么就不能为它指定employeeNumber属性，因为employeeNumber是在inetOrgPerson中定义的。</p><p>LDAP为人员组织机构中常见的对象都设计了属性(比如commonName，surname)。下面有一些常用的别名：<br><img src="/2018/04/15/LDAP/p2.png" alt="logo"></p><h2 id="ObjectClass"><a href="#ObjectClass" class="headerlink" title="ObjectClass"></a>ObjectClass</h2><p>对象类是属性的集合，LDAP预想了很多人员组织机构中常见的对象，并将其封装成对象类。比如人员（person）含有姓（sn）、名（cn）、电话(telephoneNumber)、密码(userPassword)等属性，单位职工(organizationalPerson)是人员(person)的继承类，除了上述属性之外还含有职务（title）、邮政编码（postalCode）、通信地址(postalAddress)等属性。</p><p>通过对象类可以方便的定义条目类型。每个条目可以直接继承多个对象类，这样就继承了各种属性。如果2个对象类中有相同的属性，则条目继承后只会保留1个属性。对象类同时也规定了哪些属性是基本信息，必须含有(Must或Required，必要属性)：哪些属性是扩展信息，可以含有（May或Optional，可选属性）。</p><p>对象类有三种类型：结构类型（Structural）、抽象类型(Abstract)和辅助类型（Auxiliary）。结构类型是最基本的类型，它规定了对象实体的基本属性，每个条目属于且仅属于一个结构型对象类。抽象类型可以是结构类型或其他抽象类型父类，它将对象属性中共性的部分组织在一起，称为其他类的模板，条目不能直接集成抽象型对象类。辅助类型规定了对象实体的扩展属性。每个条目至少有一个结构性对象类。</p><p>对象类本身是可以相互继承的，所以对象类的根类是top抽象型对象类。以常用的人员类型为例，他们的继承关系：</p><p><img src="/2018/04/15/LDAP/p3.png" alt="logo"></p><p>下面是inetOrgPerson对象类的在schema中的定义，可以清楚的看到它的父类SUB和可选属性MAY、必要属性MUST(继承自organizationalPerson)，关于各属性的语法则在schema中的attributetype定义。</p><pre><code>`# inetOrgPerson``# The inetOrgPerson represents people who are associated with an``# organization in some way.  It is a structural class and is derived``# from the organizationalPerson which is defined in X.521 [X521].`objectclass     ( 2.16.840.1.113730.3.2.2NAME &apos;inetOrgPerson&apos;    DESC &apos;RFC2798: Internet Organizational Person&apos;SUP organizationalPersonSTRUCTURAL    MAY (            audio $ businessCategory $ carLicense $ departmentNumber $            displayName $ employeeNumber $ employeeType $ givenName $            homePhone $ homePostalAddress $ initials $ jpegPhoto $            labeledURI $ mail $ manager $ mobile $ o $ pager $            photo $ roomNumber $ secretary $ uid $ userCertificate $            x500uniqueIdentifier $ preferredLanguage $            userSMIMECertificate $ userPKCS12 )    )</code></pre><h2 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h2><p>对象类（ObjectClass）、属性类型（AttributeType）、语法（Syntax）分别约定了条目、属性、值，他们之间的关系如下图所示。所以这些构成了模式(Schema)——对象类的集合。条目数据在导入时通常需要接受模式检查，它确保了目录中所有的条目数据结构都是一致的。</p><p><img src="/2018/04/15/LDAP/p4.png" alt="logo"></p><p>schema（一般在/etc/ldap/schema/目录）在导入时要注意前后顺序。</p><h2 id="backend-amp-database"><a href="#backend-amp-database" class="headerlink" title="backend &amp; database"></a>backend &amp; database</h2><p>ldap的后台进程slapd接收、响应请求，但实际存储数据、获取数据的操作是由Backends做的，而数据是存放在database中，所以你可以看到往往你可以看到backend和database指令是一样的值如 bdb 。一个 backend 可以有多个 database instance，但每个 database 的 suffix 和 rootdn 不一样。openldap 2.4版本的模块是动态加载的，所以在使用backend时需要moduleload back_bdb指令。</p><p>bdb是一个高性能的支持事务和故障恢复的数据库后端，可以满足绝大部分需求。许多旧文档里（包括官方）说建议将bdb作为首选后端服务（primary backend），但2.4版文档明确说hdb才是被首先推荐使用的，这从 2.4.40 版默认安装后的配置文件里也可以看出。hdb是基于bdb的，但是它通过扩展的索引和缓存技术可以加快数据访问，修改entries会更有效率，有兴趣可以访问上的链接或slapd.backends。</p><p>另外config是特殊的backend，用来在运行时管理slapd的配置，它只能有一个实例，甚至无需显式在slapd.conf中配置。</p><h2 id="TLS-amp-SASL"><a href="#TLS-amp-SASL" class="headerlink" title="TLS &amp; SASL"></a>TLS &amp; SASL</h2><p>分布式LDAP 是以明文的格式通过网络来发送信息的，包括client访问ldap的密码（当然一般密码已然是二进制的），SSL/TLS 的加密协议就是来保证数据传送的保密性和完整性。</p><p>SASL （Simple Authenticaion and Security Layer）简单身份验证安全框架，它能够实现openldap客户端到服务端的用户验证，也是ldapsearch、ldapmodify这些标准客户端工具默认尝试与LDAP服务端认证用户的方式（前提是已经安装好 Cyrus SASL）。SASL有几大工业实现标准：Kerveros V5、DIGEST-MD5、EXTERNAL、PLAIN、LOGIN。</p><p>Kerveros V5是里面最复杂的一种，使用GSSAPI机制，必须配置完整的Kerberos V5安全系统，密码不再存放在目录服务器中，每一个dn与Kerberos数据库的主体对应。DIGEST-MD5稍微简单一点，密码通过saslpasswd2生成放在sasldb数据库中，或者将明文hash存到LDAP dn的userPassword中，每一个authid映射成目录服务器的dn，常和SSL配合使用。参考 <a href="https://docs.oracle.com/cd/E19957-01/820-0293/6nc1tbp0h/index.html" target="_blank" rel="noopener">https://docs.oracle.com/cd/E19957-01/820-0293/6nc1tbp0h/index.html</a></p><p>EXTERNAL一般用于初始化添加schema时使用，如ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/core.ldif。</p><h2 id="LDIF"><a href="#LDIF" class="headerlink" title="LDIF"></a>LDIF</h2><p>LDIF 是一种普遍使用的文件格式，用来描述目录信息或可对目录执行的修改操作。<br>LDIF（LDAP Data Interchange Format，数据交换格式）是LDAP数据库信息的一种文本格式，用于数据的导入导出，每行都是“属性: 值”对。</p><p>结构参考：<a href="https://blog.csdn.net/daily11/article/details/51030464" target="_blank" rel="noopener">https://blog.csdn.net/daily11/article/details/51030464</a><br><a href="https://zhuanlan.zhihu.com/p/32732045" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32732045</a></p><p>openLDAP服务器安装参考：<a href="http://seanlook.com/2015/01/21/openldap-install-guide-ssl/" target="_blank" rel="noopener">http://seanlook.com/2015/01/21/openldap-install-guide-ssl/</a></p><h2 id="SpringBoot整合LDAP"><a href="#SpringBoot整合LDAP" class="headerlink" title="SpringBoot整合LDAP"></a>SpringBoot整合LDAP</h2><p>很多时候，我们在构建系统的时候都会自己创建用户管理体系，这对于开发人员来说并不是什么难事，但是当我们需要维护多个不同系统并且相同用户跨系统使用的情况下，如果每个系统维护自己的用户信息，那么此时用户信息的同步就会变的比较麻烦，对于用户自身来说也会非常困扰，很容易出现不同系统密码不一致啊等情况出现。如果此时我们引入LDAP来集中存储用户的基本信息并提供统一的读写接口和校验机制，那么这样的问题就比较容易解决了。下面就来说说当我们使用Spring Boot开发的时候，如何来访问LDAP服务端。</p><p>LDAP目录中的信息是是按照树型结构组织，具体信息存储在条目(entry)的数据结构中。条目相当于关系数据库中表的记录；条目是具有区别名DN （Distinguished Name）的属性（Attribute），DN是用来引用条目的，DN相当于关系数据库表中的关键字（Primary Key）。属性由类型（Type）和一个或多个值（Values）组成，相当于关系数据库中的字段（Field）由字段名和数据类型组成，只是为了方便检索的需要，LDAP中的Type可以有多个Value，而不是关系数据库中为降低数据的冗余性要求实现的各个域必须是不相关的。LDAP中条目的组织一般按照地理位置和组织关系进行组织，非常的直观。LDAP把数据存放在文件中，为提高效率可以使用基于索引的文件数据库，而不是关系数据库。类型的一个例子就是mail，其值将是一个电子邮件地址。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LDAP（轻量级目录访问协议，Lightweight Directory Access Protocol)是实现提供被称为目录服务的信息服务。目录服务是一种特殊的数据库系统，其专门针对读取，浏览和搜索操作进行了特定的优化。目录一般用来包含描述性的，基于属性的信息并支持精细复杂的过滤能力。目录一般不支持通用数据库针对大量更新操作操作需要的复杂的事务管理或回卷策略。就是说LDAP精于读取和查询，在写入功能上表现较差，不支持事务和回滚操作，而目录服务的更新则一般都非常简单。这种目录可以存储包括个人信息、web链结、jpeg图像等各种信息。为了访问存储在目录中的信息，就需要使用运行在TCP/IP 之上的访问协议—LDAP。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>数据分析与挖掘--POWER BI</title>
    <link href="http://yoursite.com/2018/04/14/power-bi/"/>
    <id>http://yoursite.com/2018/04/14/power-bi/</id>
    <published>2018-04-14T02:25:47.000Z</published>
    <updated>2018-04-14T02:33:06.159Z</updated>
    
    <content type="html"><![CDATA[<p>大数据已经成为互联网时代的进程之一，海量数据的处理可以通过hadoop+spark和分布式架构系统进行实现，所有数据的可视化需求显得更加迫切，如何将大数据更加直观的展现给非技术人员去理解，这就是power BI。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大数据已经成为互联网时代的进程之一，海量数据的处理可以通过hadoop+spark和分布式架构系统进行实现，所有数据的可视化需求显得更加迫切，如何将大数据更加直观的展现给非技术人员去理解，这就是power BI。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具类" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7%E7%B1%BB/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="powerbi" scheme="http://yoursite.com/tags/powerbi/"/>
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="生产工具" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>ORM框架--Hibernate</title>
    <link href="http://yoursite.com/2018/04/09/hibernate/"/>
    <id>http://yoursite.com/2018/04/09/hibernate/</id>
    <published>2018-04-09T11:48:37.000Z</published>
    <updated>2018-04-14T02:24:29.621Z</updated>
    
    <content type="html"><![CDATA[<p>Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
      <category term="mybatis" scheme="http://yoursite.com/tags/mybatis/"/>
    
  </entry>
  
  <entry>
    <title>Mybatis在spring和springboot框架中的操作总结</title>
    <link href="http://yoursite.com/2018/04/08/mybatis/"/>
    <id>http://yoursite.com/2018/04/08/mybatis/</id>
    <published>2018-04-08T15:53:43.000Z</published>
    <updated>2018-04-14T16:12:09.343Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis在我上个项目中结合spring+springMVC框架的SSM架构中有用到，Mybatis作为一个半自动化的ORM框架，在编程的难度对比上我觉得比Hibernate的性能要好，对简单数据做操作时当然是Hibernate更为方便因为不用写SQL语句，但是在操作的自由性和性能的比较上我觉得mybatis要更好些，但是我最近又系统学习了spring-data-jpa框架，我觉得这个框架用来写数据交互真的要比Mybatis或者Hibernate爽太多了。。。（个人意见，可能有一部分是因为结合了Springboot）<br><a id="more"></a></p><p>mybatis是一个半自动化的orm框架，所谓半自动化就是mybaitis只支持数据库查出的数据映射到pojo类上，而实体到数据库的映射需要自己编写sql语句实现，相较于hibernate这种完全自动化的框架我更喜欢mybatis，mybatis非常灵活，可以随心所欲的编写自己的sql语句来实现复杂的数据库操作，还会有一种畅酣淋漓的编写sql语句的潇洒感，但是以前的mybaits需要一大堆的配置文件，以及各种mapper和dao和实体的关联，导致使用mybatis还是不够简洁，后来mybatis也发现了这个弊端，开发了mybatis generator工具来自动化生成实体类、mapper配置文件、dao层代码来减轻开发工作量，在后期也是实现了抛弃mapper配置文件基于注解的开发模式，直到现在，mybatis看spring boot这么火热，也开发了一套基于spring boot的模式：<strong>mybatis-spring-boot-starter</strong>。<br>spring boot简约轻巧的风格正在逐渐被越来越多的厂商及开发者所认可，包括阿里的开源RPC框架dubbo也准备开发一套对spring boot应用的支持（dubbo-spring-boot-starter启动配置模块）</p><p>在springboot框架下开发项目很爽，因为需要集成的基本单元已经帮你集成好了，因为使用了java配置的原因，所以零XML配置使得整个开发过程很放松，让工程师能够更好的将精力集中在编写实际的业务逻辑上。</p><p>Mybatis+Spring+SpringMVC的SSM架构使用mybatis generator工具来简化开发。<br>Mybatis+Springboot+SpringMVC的新架构就采用mybatis-spring-boot-starter。</p><h1 id="spring-mybatis"><a href="#spring-mybatis" class="headerlink" title="spring+mybatis"></a>spring+mybatis</h1><p>我这里从最传统的spring+Mybatis项目开始讲起，因为要产生对比才能更好的理解新架构对开发的改变！</p><h2 id="传统模式"><a href="#传统模式" class="headerlink" title="传统模式"></a>传统模式</h2><p>在原先的项目中简单分析下mybatis与数据库在DAO层进行交互的一般流程：</p><p>第一步：首先先编写实体类，满足javaBean规范（有包，实现序列化接口，有无参数构造器，各个属性有相应的get/set方法），实体类对应数据库中的表，这里我用的是mysql数据库来做项目。</p><p>第二步：编写DAO接口，里面有一些对这个表所做的操作，具体的实现在mapper文件中写sql语句。</p><p>第三步：写mapper.xml映射文件，主要是映射实体类，和实现DAO接口的逻辑<br>并且在配置文件中要进行org.mybatis.spring.SqlSessionFactoryBean的配置，指定所有mapper文件所存在的包名<br>mapper文件的xml头格式也有要求：<br>&lt;?xml version=”1.0” encoding=”UTF-8” ?&gt;<br>&lt;!DOCTYPE mapper PUBLIC “-//ibatis.apache.org//DTD Mapper 3.0//EN”<br> “<a href="http://ibatis.apache.org/dtd/ibatis-3-mapper.dtd&quot;&gt;" target="_blank" rel="noopener">http://ibatis.apache.org/dtd/ibatis-3-mapper.dtd&quot;&gt;</a><br>…</p><p>这是传统的模式与数据库进行交互，因为要编写大量的实体类entity，Dao接口，mapper文件，很难管理且开发太过恶心。</p><p>后来出现了mybatis generator工具来自动来自动生成这些东西，居然还有基于注解的去mapper化开发模式，这也是我今天总结的时候才发现的，这不是学jpa吗？</p><p>先来看看这个mybatis generator工具到底是啥玩意。。</p><h2 id="mybatis-generator工具模式-’"><a href="#mybatis-generator工具模式-’" class="headerlink" title="mybatis generator工具模式 ##’"></a>mybatis generator工具模式 ##’</h2><p>mybatis generator工具官网:<a href="http://mbg.cndocs.ml/" target="_blank" rel="noopener">http://mbg.cndocs.ml/</a><br>mybatis-generator 是一个代码自动生成工具，手动写入一个个实体类和mapper还有xml配置文件感觉会很麻烦，使用mybatis generator只需要简单的配置就能完成我们的工作，这里简述一下开发步骤。</p><p>MyBatis Generator (MBG) 是一个Mybatis的代码生成器 MyBatis 和 iBATIS. 他可以生成Mybatis各个版本的代码，和iBATIS 2.2.0版本以后的代码。 他可以内省数据库的表（或多个表）然后生成可以用来访问（多个）表的基础对象。 这样和数据库表进行交互时不需要创建对象和配置文件。 MBG的解决了对数据库操作有最大影响的一些简单的CRUD（插入，查询，更新，删除）操作。 您仍然需要对联合查询和存储过程手写SQL和对象。</p><p>mybatis generator的原理就是根据你数据库中已有的表自动生成对应的实体类，mapper以及DAO接口，我们先来操作一下(表已经事先在数据库中创建好了)</p><p>第一步：导入相关的jar包</p><pre><code>&lt;properties&gt;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;  &lt;/properties&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;javax.servlet&lt;/groupId&gt;      &lt;artifactId&gt;jstl&lt;/artifactId&gt;      &lt;version&gt;1.2&lt;/version&gt;      &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt;      &lt;artifactId&gt;jsp-api&lt;/artifactId&gt;      &lt;version&gt;2.1&lt;/version&gt;      &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.glassfish&lt;/groupId&gt;      &lt;artifactId&gt;javax.annotation&lt;/artifactId&gt;      &lt;version&gt;3.0.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.glassfish&lt;/groupId&gt;      &lt;artifactId&gt;javax.ejb&lt;/artifactId&gt;      &lt;version&gt;3.0.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.jboss.weld&lt;/groupId&gt;      &lt;artifactId&gt;weld-osgi-bundle&lt;/artifactId&gt;      &lt;version&gt;1.0.1-SP3&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.glassfish&lt;/groupId&gt;      &lt;artifactId&gt;javax.servlet&lt;/artifactId&gt;      &lt;version&gt;3.0.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--测试框架  --&gt;    &lt;dependency&gt;      &lt;groupId&gt;junit&lt;/groupId&gt;      &lt;artifactId&gt;junit&lt;/artifactId&gt;      &lt;version&gt;4.12&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- Mysql --&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.mybatis&lt;/groupId&gt;      &lt;artifactId&gt;mybatis&lt;/artifactId&gt;      &lt;version&gt;3.2.7&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- Mysql 依赖 --&gt;    &lt;dependency&gt;      &lt;groupId&gt;mysql&lt;/groupId&gt;      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;      &lt;version&gt;5.1.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--生成代码插件--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt;        &lt;version&gt;1.3.2&lt;/version&gt;        &lt;type&gt;jar&lt;/type&gt;    &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;    &lt;plugins&gt;      &lt;plugin&gt;        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;      &lt;/plugin&gt;      &lt;plugin&gt;        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;        &lt;configuration&gt;          &lt;source&gt;1.6&lt;/source&gt;          &lt;target&gt;1.6&lt;/target&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;    &lt;/plugins&gt;  &lt;/build&gt;</code></pre><p>第二步:新建生成代码的配置文件mybatis-generator-config.xml<br>具体更详细的各参数配置在这里：<a href="https://www.jianshu.com/p/e09d2370b796" target="_blank" rel="noopener">https://www.jianshu.com/p/e09d2370b796</a><br>注意这个文件是最坑的，一定不要设置错了，不然很尴尬。。。自动生成虽然好用，但是也要多做才能完全掌握其中奥义。</p><pre><code>&lt;generatorConfiguration&gt;    &lt;context id=&quot;prod&quot;&gt;        &lt;!-- RowBounds pagination --&gt;        &lt;plugin type=&quot;org.mybatis.generator.plugins.RowBoundsPlugin&quot; /&gt;        &lt;plugin type=&quot;org.mybatis.generator.plugins.CaseInsensitiveLikePlugin&quot; /&gt;        &lt;plugin type=&quot;org.mybatis.generator.plugins.SerializablePlugin&quot; /&gt;        &lt;commentGenerator&gt;            &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot; /&gt;            &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt;        &lt;/commentGenerator&gt;        &lt;!-- jdbc连接 --&gt;        &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot;                        connectionURL=&quot;jdbc:mysql:///test&quot;                         userId=&quot;root&quot;                        password=&quot;294823013&quot; /&gt;        &lt;!-- 在javaModelGenerator标签下配置你需要生成的数据库实体的地址  --&gt;        &lt;javaModelGenerator targetPackage=&quot;com.mybatis.entity&quot;            targetProject=&quot;src/main/java&quot;&gt;            &lt;!-- 是否针对string类型的字段在set的时候进行trim调用 --&gt;            &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot; /&gt;        &lt;/javaModelGenerator&gt;        &lt;!-- 在sqlMapGenerator标签下配置mysql的xml配置文件 --&gt;        &lt;sqlMapGenerator targetPackage=&quot;mappers&quot; targetProject=&quot;src/main/java&quot; /&gt;        &lt;!-- 在javaClientGenerator标签下配置mapper方法，相当于DAO接口，业务层调用里面的方法对数据库进行操作  --&gt;        &lt;javaClientGenerator targetPackage=&quot;com.mybatis.mapper&quot;            targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot; /&gt;        &lt;!-- 在table标签下配置数据库的表名和生成实体的表名，表名是koro_table，所生成的实体类是KoroTable --&gt;        &lt;table tableName=&quot;koro_table&quot; domainObjectName=&quot;KoroTable&quot;&gt;        &lt;/table&gt;    &lt;/context&gt;&lt;/generatorConfiguration&gt;</code></pre><p>第三步：新建批处理类main方法<br>利用mybatis generator来进行自动生成，编写</p><pre><code>public class App {    public static void main(String[] args) {        args = new String[] { &quot;-configfile&quot;, &quot;src\\main\\resources\\mybatis-generator-config.xml&quot;, &quot;-overwrite&quot; };        ShellRunner.main(args);    }}</code></pre><p>执行这个类就可以自动生成了，生成后的目录结构是这样的：<br><img src="/2018/04/08/mybatis/p1.png" alt="logo"></p><p>我们会发现我们生成了两个实体对象，一个是数据库映射对象，一个是Example对象。Example对象就是为了方便我们执行sql操作的类，可以使用Example类进行数据库的条件查询。同时mybatis-generator还帮助我们生成了sql的CRUD等操作。<br>com.mybatis.mapper下的KoroTableMapper.java就是DAO接口，里面是一些crud操作</p><pre><code>public interface KoroTableMapper {    int countByExample(KoroTableExample example);    int deleteByExample(KoroTableExample example);    int deleteByPrimaryKey(Integer id);    int insert(KoroTable record);    int insertSelective(KoroTable record);    List&lt;KoroTable&gt; selectByExampleWithRowbounds(KoroTableExample example, RowBounds rowBounds);    List&lt;KoroTable&gt; selectByExample(KoroTableExample example);    KoroTable selectByPrimaryKey(Integer id);    int updateByExampleSelective(@Param(&quot;record&quot;) KoroTable record, @Param(&quot;example&quot;) KoroTableExample example);    int updateByExample(@Param(&quot;record&quot;) KoroTable record, @Param(&quot;example&quot;) KoroTableExample example);    int updateByPrimaryKeySelective(KoroTable record);    int updateByPrimaryKey(KoroTable record);}</code></pre><p>mappers目录下的是自动生成的mapper.xml文件，对应DAO接口的各个方法的实现</p><pre><code>&lt;mapper namespace=&quot;com.mybatis.mapper.KoroTableMapper&quot; &gt;  &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.mybatis.entity.KoroTable&quot; &gt;    &lt;id column=&quot;id&quot; property=&quot;id&quot; jdbcType=&quot;INTEGER&quot; /&gt;    &lt;result column=&quot;NAME&quot; property=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; /&gt;    &lt;result column=&quot;age&quot; property=&quot;age&quot; jdbcType=&quot;INTEGER&quot; /&gt;  &lt;/resultMap&gt;  &lt;sql id=&quot;Example_Where_Clause&quot; &gt;    &lt;where &gt;      &lt;foreach collection=&quot;oredCriteria&quot; item=&quot;criteria&quot; separator=&quot;or&quot; &gt;        &lt;if test=&quot;criteria.valid&quot; &gt;          &lt;trim prefix=&quot;(&quot; suffix=&quot;)&quot; prefixOverrides=&quot;and&quot; &gt;            &lt;foreach collection=&quot;criteria.criteria&quot; item=&quot;criterion&quot; &gt;              &lt;choose &gt;                &lt;when test=&quot;criterion.noValue&quot; &gt;                  and ${criterion.condition}                &lt;/when&gt;                &lt;when test=&quot;criterion.singleValue&quot; &gt;                  and ${criterion.condition} #{criterion.value}                &lt;/when&gt;                &lt;when test=&quot;criterion.betweenValue&quot; &gt;                  and ${criterion.condition} #{criterion.value} and #{criterion.secondValue}                &lt;/when&gt;                &lt;when test=&quot;criterion.listValue&quot; &gt;                  and ${criterion.condition}                  &lt;foreach collection=&quot;criterion.value&quot; item=&quot;listItem&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot; &gt;                    `#{listItem}`                  &lt;/foreach&gt;                &lt;/when&gt;              &lt;/choose&gt;            &lt;/foreach&gt;          &lt;/trim&gt;        &lt;/if&gt;      &lt;/foreach&gt;    &lt;/where&gt;  &lt;/sql&gt;  &lt;sql id=&quot;Update_By_Example_Where_Clause&quot; &gt;    &lt;where &gt;      &lt;foreach collection=&quot;example.oredCriteria&quot; item=&quot;criteria&quot; separator=&quot;or&quot; &gt;        &lt;if test=&quot;criteria.valid&quot; &gt;          &lt;trim prefix=&quot;(&quot; suffix=&quot;)&quot; prefixOverrides=&quot;and&quot; &gt;            &lt;foreach collection=&quot;criteria.criteria&quot; item=&quot;criterion&quot; &gt;              &lt;choose &gt;                &lt;when test=&quot;criterion.noValue&quot; &gt;                  and ${criterion.condition}                &lt;/when&gt;                &lt;when test=&quot;criterion.singleValue&quot; &gt;                  and ${criterion.condition} #{criterion.value}                &lt;/when&gt;                &lt;when test=&quot;criterion.betweenValue&quot; &gt;                  and ${criterion.condition} #{criterion.value} and #{criterion.secondValue}                &lt;/when&gt;                &lt;when test=&quot;criterion.listValue&quot; &gt;                  and ${criterion.condition}                  &lt;foreach collection=&quot;criterion.value&quot; item=&quot;listItem&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot; &gt;                    `#{listItem}`                  &lt;/foreach&gt;                &lt;/when&gt;              &lt;/choose&gt;            &lt;/foreach&gt;          &lt;/trim&gt;        &lt;/if&gt;      &lt;/foreach&gt;    &lt;/where&gt;  &lt;/sql&gt;  &lt;sql id=&quot;Base_Column_List&quot; &gt;    id, NAME, age  &lt;/sql&gt;  &lt;select id=&quot;selectByExample&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;com.mybatis.entity.KoroTableExample&quot; &gt;    select    &lt;if test=&quot;distinct&quot; &gt;      distinct    &lt;/if&gt;    &lt;include refid=&quot;Base_Column_List&quot; /&gt;    from koro_table    &lt;if test=&quot;_parameter != null&quot; &gt;      &lt;include refid=&quot;Example_Where_Clause&quot; /&gt;    &lt;/if&gt;    &lt;if test=&quot;orderByClause != null&quot; &gt;      order by ${orderByClause}    &lt;/if&gt;  &lt;/select&gt;  &lt;select id=&quot;selectByPrimaryKey&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.lang.Integer&quot; &gt;    select     &lt;include refid=&quot;Base_Column_List&quot; /&gt;    from koro_table    where id = #{id,jdbcType=INTEGER}  &lt;/select&gt;  &lt;delete id=&quot;deleteByPrimaryKey&quot; parameterType=&quot;java.lang.Integer&quot; &gt;    delete from koro_table    where id = #{id,jdbcType=INTEGER}  &lt;/delete&gt;  &lt;delete id=&quot;deleteByExample&quot; parameterType=&quot;com.mybatis.entity.KoroTableExample&quot; &gt;    delete from koro_table    &lt;if test=&quot;_parameter != null&quot; &gt;      &lt;include refid=&quot;Example_Where_Clause&quot; /&gt;    &lt;/if&gt;  &lt;/delete&gt;  &lt;insert id=&quot;insert&quot; parameterType=&quot;com.mybatis.entity.KoroTable&quot; &gt;    insert into koro_table (id, NAME, age      )    values (#{id,jdbcType=INTEGER}, #{name,jdbcType=VARCHAR}, #{age,jdbcType=INTEGER}      )  &lt;/insert&gt;  &lt;insert id=&quot;insertSelective&quot; parameterType=&quot;com.mybatis.entity.KoroTable&quot; &gt;    insert into koro_table    &lt;trim prefix=&quot;(&quot; suffix=&quot;)&quot; suffixOverrides=&quot;,&quot; &gt;      &lt;if test=&quot;id != null&quot; &gt;        id,      &lt;/if&gt;      &lt;if test=&quot;name != null&quot; &gt;        NAME,      &lt;/if&gt;      &lt;if test=&quot;age != null&quot; &gt;        age,      &lt;/if&gt;    &lt;/trim&gt;    &lt;trim prefix=&quot;values (&quot; suffix=&quot;)&quot; suffixOverrides=&quot;,&quot; &gt;      &lt;if test=&quot;id != null&quot; &gt;        `#{id,jdbcType=INTEGER},`      &lt;/if&gt;      &lt;if test=&quot;name != null&quot; &gt;        `#{name,jdbcType=VARCHAR},`      &lt;/if&gt;      &lt;if test=&quot;age != null&quot; &gt;        `#{age,jdbcType=INTEGER},`      &lt;/if&gt;    &lt;/trim&gt;  &lt;/insert&gt;  &lt;select id=&quot;countByExample&quot; parameterType=&quot;com.mybatis.entity.KoroTableExample&quot; resultType=&quot;java.lang.Integer&quot; &gt;    select count(*) from koro_table    &lt;if test=&quot;_parameter != null&quot; &gt;      &lt;include refid=&quot;Example_Where_Clause&quot; /&gt;    &lt;/if&gt;  &lt;/select&gt;  &lt;update id=&quot;updateByExampleSelective&quot; parameterType=&quot;map&quot; &gt;    update koro_table    &lt;set &gt;      &lt;if test=&quot;record.id != null&quot; &gt;        id = #{record.id,jdbcType=INTEGER},      &lt;/if&gt;      &lt;if test=&quot;record.name != null&quot; &gt;        NAME = #{record.name,jdbcType=VARCHAR},      &lt;/if&gt;      &lt;if test=&quot;record.age != null&quot; &gt;        age = #{record.age,jdbcType=INTEGER},      &lt;/if&gt;    &lt;/set&gt;    &lt;if test=&quot;_parameter != null&quot; &gt;      &lt;include refid=&quot;Update_By_Example_Where_Clause&quot; /&gt;    &lt;/if&gt;  &lt;/update&gt;  &lt;update id=&quot;updateByExample&quot; parameterType=&quot;map&quot; &gt;    update koro_table    set id = #{record.id,jdbcType=INTEGER},      NAME = #{record.name,jdbcType=VARCHAR},      age = #{record.age,jdbcType=INTEGER}    &lt;if test=&quot;_parameter != null&quot; &gt;      &lt;include refid=&quot;Update_By_Example_Where_Clause&quot; /&gt;    &lt;/if&gt;  &lt;/update&gt;  &lt;update id=&quot;updateByPrimaryKeySelective&quot; parameterType=&quot;com.mybatis.entity.KoroTable&quot; &gt;    update koro_table    &lt;set &gt;      &lt;if test=&quot;name != null&quot; &gt;        NAME = #{name,jdbcType=VARCHAR},      &lt;/if&gt;      &lt;if test=&quot;age != null&quot; &gt;        age = #{age,jdbcType=INTEGER},      &lt;/if&gt;    &lt;/set&gt;    where id = #{id,jdbcType=INTEGER}  &lt;/update&gt;  &lt;update id=&quot;updateByPrimaryKey&quot; parameterType=&quot;com.mybatis.entity.KoroTable&quot; &gt;    update koro_table    set NAME = #{name,jdbcType=VARCHAR},      age = #{age,jdbcType=INTEGER}    where id = #{id,jdbcType=INTEGER}  &lt;/update&gt;  &lt;select resultMap=&quot;BaseResultMap&quot; parameterType=&quot;com.mybatis.entity.KoroTableExample&quot; id=&quot;selectByExampleWithRowbounds&quot; &gt;    select    &lt;if test=&quot;distinct&quot; &gt;      distinct    &lt;/if&gt;    &lt;include refid=&quot;Base_Column_List&quot; /&gt;    from koro_table    &lt;if test=&quot;_parameter != null&quot; &gt;      &lt;include refid=&quot;Example_Where_Clause&quot; /&gt;    &lt;/if&gt;    &lt;if test=&quot;orderByClause != null&quot; &gt;      order by ${orderByClause}    &lt;/if&gt;  &lt;/select&gt;&lt;/mapper&gt;</code></pre><p><resultmap>标签中是对应数据库表的所有字段的映射等等，mybatis-generator为我们全自动化的根据数据库表结构生成实体类，DAO接口以及mapper映射，可以说是很方便。</resultmap></p><h2 id="springboot与mybatis整合"><a href="#springboot与mybatis整合" class="headerlink" title="springboot与mybatis整合"></a>springboot与mybatis整合</h2><p>第一步：springboot与mybatis整合的导包：mysql连接与mybatis-spring-boot-starter即可</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;/groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>第二步：在application.properties文件中配置mybatis的相关项</p><p>#mybatis.config-location=classpath:mybatis-config.xml</p><p>#mybatis mapper文件的位置<br>mybatis.mapper-locations=classpath<em>:mapper/</em>.xml</p><p>#扫描pojo类的位置,在此处指明扫描实体类的包，在mapper中就可以不用写pojo类的全路径名了<br>mybatis.type-aliases-package=com.domain</p><p>jdbc.type=mysql<br>spring.datasource.url=jdbc:mysql://localhost:3306/test<br>spring.datasource.username=root<br>spring.datasource.password=294823013<br>spring.datasource.driver-class-name=com.mysql.jdbc.Driver</p><p>第三步：在数据库中建立表meaage并给些数据（准备好数据库）</p><p>第四步：编写实体类Message，名称与表名对应</p><pre><code>public class Message {    private int id;    private String content;    private String name;//省略get/set方法//添加无参构造器}</code></pre><p>第五步：编写Dao接口</p><pre><code>//加上该注解才能使用@MapperScan扫描到@Mapperpublic interface MessageDao {    Message findById(@Param(&quot;id&quot;)int id);}</code></pre><p>第六步：编写Dao对应的mapper文件</p><pre><code>&lt;mapper namespace=&quot;com.mybatis.domain.MessageDao&quot;&gt;&lt;select id=&quot;findById&quot; parameterType=&quot;int&quot;    resultType=&quot;com.mybatis.domain.Message&quot;&gt;   SELECT * FROM message WHERE id=#{id}&lt;/select&gt;&lt;/mapper&gt;</code></pre><p>第七步：启动类</p><pre><code>@SpringBootApplication@MapperScan(&quot;mapper&quot;)public class Application {    public static void main(String[] args) {        SpringApplication.run(Application.class, args);    }}</code></pre><p>添加@MapperScan(“mapper”)，以扫描mapper文件夹下的那些mapper文件</p><p>第八步：添加Controller类来简单测试</p><pre><code>@RestControllerpublic class MessageController {    @Autowired    private MessageDao messageDao;    @RequestMapping(&quot;/msg&quot;)    public Message msg(){        Message msg=messageDao.findById(1);        System.out.println(msg);        return msg;    }}</code></pre><p>第九步：测试，浏览器输入：<a href="http://localhost:8088/msg" target="_blank" rel="noopener">http://localhost:8088/msg</a></p><p>得到结果：{“id”:1,”content”:”aaaaaaaaaa”,”name”:”o1”}</p><p>测试成功！！</p><p>springboot+mybatis的操作就是这些。。。（总之我觉得改变的话就是springboot将一对的xml配置信息全部简化放在application.properties中去进行配置，我们只需要去完成逻辑即可）</p><p>当我们需要一个很简单的DML功能时，如果去创建mapper文件并编写一堆语句的时候也许会显得很麻烦，这个时候就可以通过注解的方式简化配置，新建一个UserAnnotationDao通过注解的方式来实现增删改查:</p><p>接下来介绍不需要mapper文件来对应Dao接口的方法（其实本质就是用java配置取代xml配置的意思）</p><p>新建MessageAnnotationDao，但是这次不用mapper文件来实现Dao中的方法，用@Select和@Results注解来配置<br>在使用简单的DML操作时，为了不用mapper那么麻烦，我们可以采用注解方式直接配置。<br>控制层直接调用即可。</p><pre><code>@Mapperpublic interface MessageAnnotationDao {    @Select(&quot;SELECT * FROM message where id=#{id}&quot;)    @Results({        @Result(property=&quot;id&quot;,column=&quot;id&quot;),        @Result(property=&quot;content&quot;,column=&quot;content&quot;),        @Result(property=&quot;name&quot;,column=&quot;name&quot;)    })    public Message findById(int id);}</code></pre><p>使用注解自后就不需要mapper文件了，分别测试这几个方法均能正确执行，使用注解和使用xml的方式都差不多，通常情况下，如果没有复杂的连接查询，我们可以使用注解的方式，当设计到复杂的sql还是使用xml的方式更好掌控一些，所以通常情况下两种方式都会使用，根据sql的复杂程度选择不同的方式来提高开发效率。</p><p>关于不用mapper文件配置sql语句的注解有哪些？<br>1.传参方式<br>下面通过几种不同传参方式来实现前文中实现的插入操作。</p><p>-使用@Param<br>这个注解在控制层也会用到，用于声明html文件中form表单提交时的key与传参的参数名对应，这样就可以更加保险的传递参数。</p><p>Insert(“INSERT INTO USER(NAME, AGE) VALUES(#{name}, #{age})”)<br>int insert(@Param(“name”) String name, @Param(“age”) Integer age);</p><p>这种方式很好理解，@Param中定义的name对应了SQL中的#{name}，age对应了SQL中的#{age}。</p><p>-使用Map<br>如下代码，通过Map对象来作为传递参数的容器：</p><p>@Insert(“INSERT INTO USER(NAME, AGE) VALUES(#{name,jdbcType=VARCHAR}, #{age,jdbcType=INTEGER})”)<br>int insertByMap(Map&lt;String, Object&gt; map);</p><p>对于Insert语句中需要的参数，我们只需要在map中填入同名的内容即可，具体如下面代码所示：</p><p>Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();<br>map.put(“name”, “CCC”);<br>map.put(“age”, 40);<br>userMapper.insertByMap(map);</p><p>系统会自动识别，从map中找相同的key</p><p>-使用对象<br>除了Map对象，我们也可直接使用普通的Java对象来作为查询条件的传参，比如我们可以直接使用User对象:</p><p>@Insert(“INSERT INTO USER(NAME, AGE) VALUES(#{name}, #{age})”)<br>int insertByUser(User user);</p><p>这样语句中的#{name}、#{age}就分别对应了User对象中的name和age属性。</p><p>2.增删改查（CRUD）<br>MyBatis针对不同的数据库操作分别提供了不同的注解来进行配置，在之前的示例中演示了@Insert，下面针对User表做一组最基本的增删改查作为示例：</p><pre><code>public interface UserMapper {    @Select(&quot;SELECT * FROM user WHERE name = #{name}&quot;)    User findByName(@Param(&quot;name&quot;) String name);    @Insert(&quot;INSERT INTO user(name, age) VALUES(#{name}, #{age})&quot;)    int insert(@Param(&quot;name&quot;) String name, @Param(&quot;age&quot;) Integer age);    @Update(&quot;UPDATE user SET age=#{age} WHERE name=#{name}&quot;)    void update(User user);    @Delete(&quot;DELETE FROM user WHERE id =#{id}&quot;)    void delete(Long id);}</code></pre><p>在完成了一套增删改查后，不妨我们试试下面的单元测试来验证上面操作的正确性：</p><pre><code>@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = Application.class)@Transactionalpublic class ApplicationTests {    @Autowired    private UserMapper userMapper;    @Test    @Rollback    public void testUserMapper() throws Exception {        // insert一条数据，并select出来验证        userMapper.insert(&quot;AAA&quot;, 20);        User u = userMapper.findByName(&quot;AAA&quot;);        Assert.assertEquals(20, u.getAge().intValue());        // update一条数据，并select出来验证        u.setAge(30);        userMapper.update(u);        u = userMapper.findByName(&quot;AAA&quot;);        Assert.assertEquals(30, u.getAge().intValue());        // 删除这条数据，并select验证        userMapper.delete(u.getId());        u = userMapper.findByName(&quot;AAA&quot;);        Assert.assertEquals(null, u);    }}</code></pre><p>3.返回结果的绑定</p><p>对于增、删、改操作相对变化较小。而对于“查”操作，我们往往需要进行多表关联，汇总计算等操作，那么对于查询的结果往往就不再是简单的实体对象了，往往需要返回一个与数据库实体不同的包装类，那么对于这类情况，就可以通过@Results和@Result注解来进行绑定，具体如下：</p><pre><code>@Results({    @Result(property = &quot;name&quot;, column = &quot;name&quot;),    @Result(property = &quot;age&quot;, column = &quot;age&quot;)})@Select(&quot;SELECT name, age FROM user&quot;)List&lt;User&gt; findAll();</code></pre><p>在上面代码中，@Result中的property属性对应User对象中的成员名，column对应SELECT出的字段名。在该配置中故意没有查出id属性，只对User对应中的name和age对象做了映射配置，这样可以通过下面的单元测试来验证查出的id为null，而其他属性不为null：</p><pre><code>@Test@Rollbackpublic void testUserMapper() throws Exception {    List&lt;User&gt; userList = userMapper.findAll();    for(User user : userList) {        Assert.assertEquals(null, user.getId());        Assert.assertNotEquals(null, user.getName());    }}</code></pre><p>具体的更多注解配置在mybatis开发文档中：<a href="http://www.mybatis.org/mybatis-3/zh/java-api.html" target="_blank" rel="noopener">http://www.mybatis.org/mybatis-3/zh/java-api.html</a></p><h2 id="springboot-mybatis结合mybatis-generator工具"><a href="#springboot-mybatis结合mybatis-generator工具" class="headerlink" title="springboot+mybatis结合mybatis-generator工具"></a>springboot+mybatis结合mybatis-generator工具</h2><p>为了能最大程度的简化开发，我们如果在项目中使用springboot+mybatis的组合，那么在生成对应的文件上可以采用mybatis-generator工具。</p><p>在前言中说到，mybatis也发现了我们需要重复的去创建pojo类、mapper文件以及dao类并且需要配置它们之间的依赖关系可能会很麻烦，所以mybtis提供了一个mybatis generator工具来帮我们自动创建pojo类、mapper文件以及dao类并且会帮我们配置好它们的依赖关系，而我们只需要关系我们的业务逻辑直接使用就行了。<br>要使用mybatis generator工具需要在pom.xml文件中添加一个generator的maven工具：</p><p>接下来就以一个项目来讲，这个generatorConfig的xml文件是最容易出错的，但是只要自己独立完成了以后就可以完美掌握了，挽歌互勉。。。</p><p>参考文章：<a href="https://blog.csdn.net/pucao_cug/article/details/64499355" target="_blank" rel="noopener">https://blog.csdn.net/pucao_cug/article/details/64499355</a> （这篇是配置maven generator插件的，很有借鉴意义）<br><a href="https://blog.csdn.net/w410589502/article/details/70756764" target="_blank" rel="noopener">https://blog.csdn.net/w410589502/article/details/70756764</a></p><p>第一步：我还是先把自己的POM包给你们看下</p><pre><code>  &lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;  &lt;/parent&gt;  &lt;groupId&gt;myself.my&lt;/groupId&gt;  &lt;artifactId&gt;spring-annotation&lt;/artifactId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;  &lt;packaging&gt;war&lt;/packaging&gt;  &lt;properties&gt;        &lt;tomcat.version&gt;7.0.69&lt;/tomcat.version&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;  &lt;dependencies&gt;    &lt;!-- springBoot的web支持 --&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;    &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;    &lt;artifactId&gt;tomcat-embed-logging-juli&lt;/artifactId&gt;    &lt;version&gt;8.0.23&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;1.3.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;     &lt;dependency&gt;        &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt;        &lt;version&gt;1.3.2&lt;/version&gt;     &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;    &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt;    &lt;!-- plugin配置用于指定使用插件 --&gt;    &lt;plugins&gt;     &lt;!-- 这个plugin里面又使用dependencies引入了mysql 的驱动和mybatis的相关jar包，     这个不能省略。 --&gt;     &lt;plugin&gt;           &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;           &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;           &lt;version&gt;1.3.2&lt;/version&gt;           &lt;executions&gt;              &lt;execution&gt;                 &lt;id&gt;Generate MyBatis Files&lt;/id&gt;                 &lt;goals&gt;                    &lt;goal&gt;generate&lt;/goal&gt;                 &lt;/goals&gt;                 &lt;phase&gt;generate&lt;/phase&gt;                 &lt;configuration&gt;                    &lt;verbose&gt;true&lt;/verbose&gt;                    &lt;overwrite&gt;true&lt;/overwrite&gt;                 &lt;/configuration&gt;              &lt;/execution&gt;           &lt;/executions&gt;           &lt;dependencies&gt;              &lt;dependency&gt;                 &lt;groupId&gt;mysql&lt;/groupId&gt;                 &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;                 &lt;version&gt;5.1.38&lt;/version&gt;              &lt;/dependency&gt;              &lt;dependency&gt;                 &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;                  &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt;                  &lt;version&gt;1.3.5&lt;/version&gt;              &lt;/dependency&gt;              &lt;dependency&gt;                 &lt;groupId&gt;org.mybatis&lt;/groupId&gt;                 &lt;artifactId&gt;mybatis&lt;/artifactId&gt;                 &lt;version&gt;3.4.2&lt;/version&gt;              &lt;/dependency&gt;           &lt;/dependencies&gt;        &lt;/plugin&gt;      &lt;!-- 资源文件拷贝插件 --&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;        &lt;configuration&gt;          &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;      &lt;!-- java编译插件 --&gt;      &lt;plugin&gt;       &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;       &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;       &lt;configuration&gt;        &lt;source&gt;1.7&lt;/source&gt;        &lt;target&gt;1.7&lt;/target&gt;        &lt;encoding&gt;UTF-8&lt;/encoding&gt;       &lt;/configuration&gt;      &lt;/plugin&gt;      &lt;!-- spring-boot-maven-plugin插件 在SpringBoot项目中开启的方式有两种      一种是run java.application 还有一种就是这个插件开启--&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;      &lt;/plugin&gt;    &lt;/plugins&gt;    &lt;!-- 用于在子Pom中使用,继承中使用 --&gt;    &lt;pluginManagement&gt;      &lt;plugins&gt;        &lt;!-- Tomcat配置 用于远程部署java web项目--&gt;        &lt;plugin&gt;          &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;          &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;          &lt;version&gt;2.2&lt;/version&gt;        &lt;/plugin&gt;      &lt;/plugins&gt;    &lt;/pluginManagement&gt;  &lt;/build&gt;&lt;/project&gt;</code></pre><p>首先注意的:<br>这里用到spring-boot-starter基础和spring-boot-starter-test用来做单元测试验证数据访问<br>引入连接mysql的必要依赖mysql-connector-java<br>引入整合MyBatis的核心依赖mybatis-spring-boot-starter<br>这里不引入spring-boot-starter-jdbc依赖，是由于mybatis-spring-boot-starter中已经包含了此依赖</p><p>这是application.properties文件中的配置参数</p><pre><code>`#Mybatis Generator configuration``#dao类和实体类的位置`project =src/main/java`#mapper文件的位置`resources=src/main/java`#根据数据库中的表生成对应的pojo类、dao、mapper`jdbc_driver =com.mysql.jdbc.Driverjdbc_url=jdbc:mysql:///testjdbc_user=rootjdbc_password=294823013</code></pre><p>注意这个配置文件，跟之前的generator配置是一样的，格式千万注意，project是注明实体类生成的位置，resource是注明mapper文件生成的位置。</p><p>最容易出错的地方就在于配置这个generator的文件时，数据的格式不要写错！！！</p><pre><code>&lt;!-- 配置生成器 --&gt;&lt;generatorConfiguration&gt;    &lt;!--执行generator插件生成文件的命令： call mvn mybatis-generator:generate -e --&gt;    &lt;!-- 引入配置文件 --&gt;    &lt;properties resource=&quot;application.properties&quot;/&gt;    &lt;!--classPathEntry:数据库的JDBC驱动,换成你自己的驱动位置 可选 --&gt;    &lt;!-- 一个数据库一个context --&gt;    &lt;!--defaultModelType=&quot;flat&quot; 大数据字段，不分表 --&gt;    &lt;context id=&quot;MysqlTables&quot; targetRuntime=&quot;MyBatis3Simple&quot; defaultModelType=&quot;flat&quot;&gt;        &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表；        一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt;        &lt;property name=&quot;autoDelimitKeywords&quot; value=&quot;true&quot; /&gt;        &lt;!-- 生成的Java文件的编码 --&gt;        &lt;property name=&quot;javaFileEncoding&quot; value=&quot;utf-8&quot; /&gt;        &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt;        &lt;property name=&quot;beginningDelimiter&quot; value=&quot;`&quot; /&gt;        &lt;property name=&quot;endingDelimiter&quot; value=&quot;`&quot; /&gt;        &lt;!-- 格式化java代码 --&gt;        &lt;property name=&quot;javaFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultJavaFormatter&quot;/&gt;        &lt;!-- 格式化XML代码 --&gt;        &lt;property name=&quot;xmlFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultXmlFormatter&quot;/&gt;        &lt;plugin type=&quot;org.mybatis.generator.plugins.SerializablePlugin&quot; /&gt;        &lt;plugin type=&quot;org.mybatis.generator.plugins.ToStringPlugin&quot; /&gt;        &lt;!-- 注释 --&gt;        &lt;commentGenerator &gt;            &lt;property name=&quot;suppressAllComments&quot; value=&quot;false&quot;/&gt;&lt;!-- 是否取消注释 --&gt;            &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot; /&gt; &lt;!-- 是否生成注释代时间戳--&gt;        &lt;/commentGenerator&gt;        &lt;!-- jdbc连接参数，用application.properties文件的参数，SPEL表达式取值即可         因为这用到了mybatis generator技术来将数据库中的表自动生成mapper文件和实体类，所以直接用参数         配置数据库连接就不起作用了，必须要在这里手动配置 --&gt;        &lt;jdbcConnection driverClass=&quot;${jdbc_driver}&quot; connectionURL=&quot;${jdbc_url}&quot; userId=&quot;${jdbc_user}&quot; password=&quot;${jdbc_password}&quot; /&gt;        &lt;!-- 类型转换 --&gt;        &lt;javaTypeResolver&gt;            &lt;!-- 是否使用bigDecimal， false可自动转化以下类型（Long, Integer, Short, etc.） --&gt;            &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt;        &lt;/javaTypeResolver&gt;        &lt;!-- 最主要的4个generator配置，这很容易写错 --&gt;        &lt;!-- 生成实体类地址 --&gt;        &lt;javaModelGenerator targetPackage=&quot;com.mybatis.domain&quot; targetProject=&quot;${project}&quot; &gt;            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt;            &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt;        &lt;/javaModelGenerator&gt;        &lt;!-- 生成mapxml文件 --&gt;        &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;${resources}&quot; &gt;            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;        &lt;/sqlMapGenerator&gt;        &lt;!-- 生成mapxml对应client，也就是接口dao --&gt;        &lt;javaClientGenerator targetPackage=&quot;com.mybatis.domain&quot; targetProject=&quot;${project}&quot; type=&quot;XMLMAPPER&quot; &gt;            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;        &lt;/javaClientGenerator&gt;        &lt;!-- table可以有多个,每个数据库中的表都可以写一个table，tableName表示要匹配的数据库表,也可以在tableName属性中通过使用%通配符来匹配所有数据库表,只有匹配的表才会自动生成文件 --&gt;        &lt;table tableName=&quot;user&quot; enableCountByExample=&quot;true&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;true&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;true&quot;&gt;            &lt;property name=&quot;useActualColumnNames&quot; value=&quot;false&quot; /&gt;            &lt;!-- 数据库表主键 --&gt;            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;Mysql&quot; identity=&quot;true&quot; /&gt;        &lt;/table&gt;    &lt;/context&gt;&lt;/generatorConfiguration&gt;</code></pre><p>这些都配置完后，我们要用插件启动测试能否自动生成</p><p>如何使用插件呢？</p><p>我们配置好POM中的插件后，在项目上右键–》run as–》run configrations<br><img src="/2018/04/08/mybatis/p2.png" alt="logo"></p><p>在点击Run Configurations以后，会弹出对话框，在对话框上找到Maven Build，然后右键并且点击new，如下图:<br><img src="/2018/04/08/mybatis/p3.png" alt="logo"></p><p> 在新出现的界面上填写Name，Base directory，Goals这三个地方，其中Name可以随便写，Base directory是你的工程的路径，例如我的是E:\eclipse_workspace_2015\springmybatis，Goals这个地方不用变，照着图写，这个是maven插件的命令。至于Maven  Runtime下拉框可以不选，也可以选择自己安装在eclipse外面的那个。<br><img src="/2018/04/08/mybatis/p4.png" alt="logo"></p><p>执行mybatis-generator:generate命令</p><p>点击Apply,在点击 Run，稍等一会，你可以看到generator执行成功了，如图：<br><img src="/2018/04/08/mybatis/p5.png" alt="logo"></p><p>生成文件：<br><img src="/2018/04/08/mybatis/p6.png" alt="logo"></p><p>注意配置不要错了即可，这就是spring或者springboot环境下与mybatis的整合。。。</p><h1 id="使用数据库版本控制器"><a href="#使用数据库版本控制器" class="headerlink" title="使用数据库版本控制器"></a>使用数据库版本控制器</h1><p>创建表的过程我们在实际开发系统的时候会经常使用，但是一直有一个问题存在，由于一个系统的程序版本通过git得到了很好的版本控制，而数据库结构并没有，即使我们通过Git进行了语句的版本化，那么在各个环境的数据库中如何做好版本管理呢？下面我们就通过本文来学习一下在Spring Boot中如何使用Flyway来管理数据库的版本。</p><p>Flyway简介</p><p>Flyway是一个简单开源数据库版本控制器（约定大于配置），主要提供migrate、clean、info、validate、baseline、repair等命令。它支持SQL（PL/SQL、T-SQL）方式和Java方式，支持命令行客户端等，还提供一系列的插件支持（Maven、Gradle、SBT、ANT等）。</p><p>Flyway是一款开源的数据库版本管理工具，它更倾向于规约优于配置的方式。Flyway可以独立于应用实现管理并跟踪数据库变更，支持数据库版本自动升级，并且有一套默认的规约，不需要复杂的配置，Migrations可以写成SQL脚本，也可以写在Java代码中，不仅支持Command Line和Java API，还支持Build构建工具和Spring Boot等，同时在分布式环境下能够安全可靠地升级数据库，同时也支持失败恢复等。</p><p>避免不正当的操作损坏数据库的结构导致严重事故，目前支持的数据库主要有：Oracle, SQL Server, SQL Azure, DB2, DB2 z/OS, MySQL(including Amazon RDS), MariaDB, Google Cloud SQL, PostgreSQL(including Amazon RDS and Heroku), Redshift, Vertica, H2, Hsql, Derby, SQLite, SAP HANA, solidDB, Sybase ASE and Phoenix.</p><h2 id="为什么使用Flyway"><a href="#为什么使用Flyway" class="headerlink" title="为什么使用Flyway?"></a>为什么使用Flyway?</h2><p>通常在项目开始时会针对数据库进行全局设计，但在开发产品新特性过程中，难免会遇到需要更新数据库Schema的情况，比如：添加新表，添加新字段和约束等，这种情况在实际项目中也经常发生。那么，当开发人员完成了对数据库更的SQL脚本后，如何快速地在其他开发者机器上同步？并且如何在测试服务器上快速同步？以及如何保证集成测试能够顺利执行并通过呢？<br>假设以Spring Boot技术栈项目为例，可能有人会说，本地使用Hibernate自动更新数据库Schema模式，然后让QA或DEV到测试服务器上手动执行SQL脚本，同时可以写一个Gradle任务自动执行更新。<br>个人觉得，对于Hibernate自动更新数据库，感觉不靠谱，不透明，控制自由度不高，而且有时很容易就会犯错，比如：用SQL创建的某个字段为VARCHAR类型，而在Entity中配置的为CHAR类型，那么在运行集成测试时，自动创建的数据库表中的字段为CHAR类型，而实际SQL脚本期望的是VARCHAR类型，虽然测试通过了，但不是期望的行为，并且在本地bootRun或服务器上运行Service时都会失败。另外，到各测试服务器上手动执行SQL脚本费时费神费力的，干嘛不自动化呢，当然，对于高级别和PROD环境，还是需要DBA手动执行的。最后，写一段自动化程序来自动执行更新，想法是很好的，那如果已经有了一些插件或库可以帮助你更好地实现这样的功能，为何不好好利用一下呢，当然，如果是为了学习目的，重复造轮子是无可厚非的。<br>其实，以上问题可以通过Flyway工具来解决，Flyway可以实现自动化的数据库版本管理，并且能够记录数据库版本更新记录，Flyway官网对Why database migrations结合示例进行了详细的阐述，有兴趣可以参阅一下。</p><p><a href="https://flywaydb.org/" target="_blank" rel="noopener">https://flywaydb.org/</a> （官方网站）</p><p>第一步：首先先加入依赖</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.flywaydb&lt;/groupId&gt;    &lt;artifactId&gt;flyway-core&lt;/artifactId&gt;    &lt;version&gt;5.0.3&lt;/version&gt;&lt;/dependency&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Mybatis在我上个项目中结合spring+springMVC框架的SSM架构中有用到，Mybatis作为一个半自动化的ORM框架，在编程的难度对比上我觉得比Hibernate的性能要好，对简单数据做操作时当然是Hibernate更为方便因为不用写SQL语句，但是在操作的自由性和性能的比较上我觉得mybatis要更好些，但是我最近又系统学习了spring-data-jpa框架，我觉得这个框架用来写数据交互真的要比Mybatis或者Hibernate爽太多了。。。（个人意见，可能有一部分是因为结合了Springboot）&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
      <category term="mybatis" scheme="http://yoursite.com/tags/mybatis/"/>
    
  </entry>
  
  <entry>
    <title>JAVA新测试框架--testng和mockito</title>
    <link href="http://yoursite.com/2018/04/05/java-%E6%96%B0%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/"/>
    <id>http://yoursite.com/2018/04/05/java-新测试框架/</id>
    <published>2018-04-05T12:59:13.000Z</published>
    <updated>2018-04-05T16:14:25.535Z</updated>
    
    <content type="html"><![CDATA[<p>测试是检查应用程序的功能的过程是否按要求工作，在开发人员层面进行单元测试，在采取适当措施来测试每一个实体（类或方法）以确保最终产品符合要求。单元测试是非常必要的，这是软件公司向他们的客户提供高质量的软件产品必要前提。</p><p>较常用的测试框架是Junit4，这个是老框架，现在的互联网开发公司常用的新框架有testng和mockito两种。<br>单元测试用例是代码的一部分从而确保代码（方法）的另一部分工作正常。要快速实现这些理想的效果，测试框架是必需的。JUnit对于Java编程语言是完美的单元测试框架。<br><a id="more"></a><br>单元测试可以通过两种方式来完成：</p><p><strong>手动测试：</strong></p><p>手动执行测试用例，没有任何工具支持称为手动测试。<br>费时和乏味：由于测试案例是由人力的，所以它是非常缓慢而乏味的执行。<br>巨大的人力资源的投入：作为测试用例需要手动执行，所以更多的测试都需要手动测试。<br>较不可靠：手动测试是为测试可能不会被精确地每次执行，因为人为错误导致不可靠。<br>非可编程：无需编程就可以做，获取信息隐藏复杂的测试</p><p><strong>自动测试：</strong></p><p>以工具支持，并通过使用自动化工具则称为自动化测试执行测试用例。<br>快速自动化运行测试用例比人力显著更快。<br>人力资源的投入较少：测试用例是通过使用自动化工具，所以较少测试者都需要在自动化测试执行。<br>更可靠：自动化测试在每次运行的时间进行精确的相同操作。<br>可编程：测试人员可以编写复杂的测试，以带出隐藏的信息。</p><p>JUnit是一个Java编程语言编写的单元测试框架。 重要的是在测试驱动开发中，并且是一个家族的统称为xUnit单元测试框架中的一个。</p><p>JUnit促进“先测试再编码”，它强调建立测试数据的一段代码可以被测试，先测试再编码实现的想法。这种做法就像是“试了一下，码了一点，测试了一下，代码一点点……”这增加了程序员的工作效率和程序代码的稳定性，减少程序员的压力和花在调试的时间。</p><p>而TestNG和mockito是全新的测试体系，在junit4的基础上，很多更加简便的测试框架被开发出来，为什么介绍这两种框架，因为现在的软件开放公司都是利用junit+TestNG+mockito的方式，运用大家的优点来搭建总体的测试体系。不过似乎在功能方面，TestNG可以完全替代Junit的功能，不过Junit作为传统的xunit测试体系，在新出的Junit5测试框架也有很强的性能（在下面会做分析）。</p><h1 id="Testng"><a href="#Testng" class="headerlink" title="Testng"></a>Testng</h1><p>JUnit让开发人员了解测试的实用性，尤其是在单元测试这一模块上比任何其他测试框架都要简单明了。凭借一个相当简单，务实，严谨的架构，JUnit已经能够“感染”了一大批开发人员。</p><p>JUnit缺点：<br>1.最初的设计，使用于单元测试，现在只用于各种测试。<br>2.不能依赖测试<br>3.配置控制欠佳(安装/拆卸)<br>4.侵入性(强制扩展类，并以某种方式命名方法)<br>5.静态编程模型(不必要的重新编译)<br>6.不适合管理复杂项目应用，JUnit复杂项目中测试非常棘手。</p><h2 id="而TetsNG是什么样的框架？"><a href="#而TetsNG是什么样的框架？" class="headerlink" title="而TetsNG是什么样的框架？"></a>而TetsNG是什么样的框架？</h2><p>TestNG是一个测试框架，其灵感来自JUnit和NUnit（也就是xUnit家族的产品），但引入了一些新的功能，使其功能更强大，使用更方便。</p><p>TestNG是一个开源自动化测试框架;TestNG表示下一代(Next Generation的首字母)。 TestNG类似于JUnit(特别是JUnit 4)，但它不是JUnit框架的扩展。它的灵感来源于JUnit。它的目的是优于JUnit，尤其是在用于测试集成多类时。 TestNG的创始人是Cedric Beust(塞德里克·博伊斯特)。</p><p>TestNG消除了大部分的旧框架的限制，使开发人员能够编写更加灵活和强大的测试。 因为它在<strong>很大程度上借鉴了Java注解</strong>(JDK5.0引入的)来定义测试，它也可以显示如何使用这个新功能在真实的Java语言生产环境中。</p><p>TestNG的特点：</p><p>1.注解<br>2.TestNG使用Java和面向对象的功能<br>3.支持综合类测试(例如，默认情况下，不用创建一个新的测试每个测试方法的类的实例)<br>4.独立的编译时测试代码和运行时配置/数据信息<br>5.灵活的运行时配置<br>6.主要介绍“测试组”。当编译测试，只要要求TestNG运行所有的“前端”的测试，或“快”，“慢”，“数据库”等<br>7.支持依赖测试方法，并行测试，负载测试，局部故障<br>8.灵活的插件API<br>9.支持多线程测试</p><p>TestNG(Next Generation)是一个测试框架，它受到JUnit和NUnit的启发，而引入了许多新的创新功能，如依赖测试，分组概念，使测试更强大，更容易做到。 它旨在涵盖所有类别的测试：单元，功能，端到端，集成等…</p><h2 id="如何使用TestNG？"><a href="#如何使用TestNG？" class="headerlink" title="如何使用TestNG？"></a>如何使用TestNG？</h2><p>展示如何开始使用TestNG单元测试框架，使用的开发环境依然是Eclipse m.3+maven3+JDK1.8<br>这里选用TestNG的版本为TestNG 6.10版本</p><p>第一步：先去官网或者是ali的maven库中去复制TestNG 6.10的版本，然后将其放在pom中的dependencies标签下。</p><p>第二步：安装Eclipse的插件支持，在Eclipse Market中搜索“TestNG for Eclipse”，然后install，重启Eclipse。</p><p>第三步：查看是否安装成功，在eclipse的工具栏中，点击file-》new-》other，看到TestNG文件夹，即表示安装插件成功。</p><p>第四步：这就可以使用TestNG用于测试组件或者单元了，在想要测试的项目的src/test/java下新建“TestNG class”，这个类就相当于Junit的测试类，在这个类中，去写测试代码，然后右键run as–》选择“TestNG test”就可以测试了。(其实测试方法有两种，接下来就讲)</p><h3 id="TestNG的测试方式"><a href="#TestNG的测试方式" class="headerlink" title="TestNG的测试方式"></a>TestNG的测试方式</h3><p>第一种直接执行：右键要执行的方法，　　点Run As -&gt;TestNG Test</p><p>第二种:  通过testng.xml文件来执行. 把要执行的case, 放入testng.xml文件中。 右键点击testng.xml,   点Run As<br>这个xml文件放在src/test/java里即可</p><p>在testng.xml中，可以控制测试用例按顺序执行。  当preserve-order=”true”是，可以保证节点下面的方法是按顺序执行的</p><h3 id="断言（ASSERT-的用法"><a href="#断言（ASSERT-的用法" class="headerlink" title="断言（ASSERT)的用法"></a>断言（ASSERT)的用法</h3><p>这里介绍一下载TestNG中同样也支持断言Assert，在实际开发中用于检测错误。<br>如何用断言Assert，断言里面又有什么方法？那个方法较为常用呢？</p><p>在经过对其进行一定了解之后，对其作用及用法有了一定的了解，assert()的用法像是一种“契约式编程”，在我的理解中，其表达的意思就是，程序在我的假设条件下，能够正常良好的运作，其实就相当于一个if语句：其本质就是代替if-else，因为如果要用if-else来测的话，整个测试结构就会变得很复杂，可读性也不好，程序结构比较臃肿，用了Assert就好多了。</p><pre><code>if(假设成立){     程序正常运行；}else{      报错&amp;&amp;终止程序！（避免由程序运行引起更大的错误）  }</code></pre><p>如果断言的条件错误，则直接程序报错，可以说是一种保障正确的一种方式，org.testng.Assert 用来校验接口测试的结果，那么它提供哪些方法呢?</p><p>提供了以下这些方法：（根据实际情况需要而去测试）</p><p>assertTrue 判断是否为true。<br>assertFalse 判断是否为false。<br>assertSame 判断引用地址是否相等。<br>assertNotSame 判断引用地址是否不相等。<br>assertNull 判断是否为null<br>assertNotNull 判断是否不为null<br>assertEquals 判断是否相等，Object类型的对象需要实现hashCode及equals方法，集合类型Collection/Set/Map 中的对象也需要实现hashCode及equals方法，3个double参数时比较好玩，前两个double相等，或者前两个double的差值小于传入的第三个double值，即偏移量小于多少时，认为相等。<br>assertNotEquals 判断是否不相等<br>assertEqualsNoOrder 判断忽略顺序是否相等</p><p>例子：</p><p>StringGenerator类<br>    public class StringGenerator {</p><pre><code>    public String generate(){        return &quot;testng demo!&quot;;    }}</code></pre><p>Test类</p><pre><code>public class TestNgDemo {  @Test  public void test1() {      StringGenerator sg=new StringGenerator();      String content=sg.generate();      /*       * testng框架中的Assert断言的作用       *        */      Assert.assertNotNull(content);//判断是否为空      Assert.assertEquals(content, &quot;testng demo!&quot;);//判断内容是否相等  }}</code></pre><p>控制台输出内容的部分：</p><pre><code>[RemoteTestNG] detected TestNG version 6.10.0[TestNG] Running:  C:\Users\Administrator\AppData\Local\Temp\testng-eclipse--46238976\testng-customsuite.xmlPASSED: test1===============================================    Default test    Tests run: 1, Failures: 0, Skips: 0==============================================================================================Default suiteTotal tests run: 1, Failures: 0, Skips: 0===============================================</code></pre><p>这样就是TestNG测试框架的使用，当然这个测试框架还可以应用在很多方面，比如：<br>TestNG预期异常测试<br>TestNG忽略测试<br>TestNG超时测试<br>TestNG分组测试<br>TestNG套件测试<br>TestNG依赖测试<br>TestNG参数化测试<br>TestNG参数测试实例<br>TestNG + Selenium负载测试<br>TestNG + Spring集成测试</p><h3 id="介绍TestNG的各种测试案例"><a href="#介绍TestNG的各种测试案例" class="headerlink" title="介绍TestNG的各种测试案例"></a>介绍TestNG的各种测试案例</h3><h3 id="TestNG和Junit4相对比："><a href="#TestNG和Junit4相对比：" class="headerlink" title="TestNG和Junit4相对比："></a>TestNG和Junit4相对比：</h3><p>JUnit 4和TestNG都是Java中非常受欢迎的单元测试框架。两种框架在功能上看起来非常相似。 哪一个更好？ 在Java项目中应该使用哪个单元测试框架？</p><p>下面表中概括了JUnit 4和TestNG之间的功能比较。如下图所示 -</p><p><img src="/2018/04/05/java-新测试框架/p1.png" alt="logo"></p><h3 id="注释支持"><a href="#注释支持" class="headerlink" title="注释支持"></a>注释支持</h3><p>注释/注解支持在JUnit 4和TestNG中是非常类似的。<br><img src="/2018/04/05/java-新测试框架/p2.png" alt="logo"></p><p>JUnit4和TestNG之间的主要注释差异是：</p><p>在JUnit 4中，我们必须声明“@BeforeClass”和“@AfterClass”方法作为静态方法。 TestNG在方法声明中更灵活，它没有这个约束。</p><p>3个额外的setUp / tearDown级别：suite和group(@Before / AfterSuite，@Before / After Test，@Before / After Group)。</p><pre><code>JUnit 4@BeforeClasspublic static void oneTimeSetUp() {    // one-time initialization code    System.out.println(&quot;@BeforeClass - oneTimeSetUp&quot;);}TestNG@BeforeClasspublic void oneTimeSetUp() {        // one-time initialization code        System.out.println(&quot;@BeforeClass - oneTimeSetUp&quot;);}</code></pre><p>在JUnit 4中，注释命名约定有点混乱，例如“Before”，“After”和“Expected”，我们并不真正了解“Before”和“After”之前的内容，以及要测试中的“预期” 方法。TestiNG更容易理解，它使用类似“BeforeMethod”，“AfterMethod”和“ExpectedException”就很明了。</p><p><strong>异常测试</strong></p><p>“异常测试”是指从单元测试中抛出的异常，此功能在JUnit 4和TestNG中都可实现。</p><pre><code>JUnit 4@Test(expected = ArithmeticException.class)public void divisionWithException() {  int i = 1/0;}TestNG@Test(expectedExceptions = ArithmeticException.class)public void divisionWithException() {  int i = 1/0;}</code></pre><p><strong>忽略测试</strong></p><p>“忽略”表示是否应该忽略单元测试，该功能在JUnit 4和TestNG中均可实现。</p><pre><code>JUnit 4@Ignore(&quot;Not Ready to Run&quot;)@Testpublic void divisionWithException() {  System.out.println(&quot;Method is not ready yet&quot;);}TestNG@Test(enabled=false)public void divisionWithException() {  System.out.println(&quot;Method is not ready yet&quot;);}</code></pre><p><strong>时间测试</strong></p><p>“时间测试”表示如果单元测试所花费的时间超过指定的毫秒数，则测试将会终止，并将其标记为失败，此功能在JUnit 4和TestNG中均可实现。</p><pre><code>JUnit 4@Test(timeout = 1000)public void infinity() {    while (true);}TestNG@Test(timeOut = 1000)public void infinity() {    while (true);}</code></pre><p><strong>套件测试</strong></p><p>“套件测试”是指捆绑几个单元测试并一起运行。 此功能在JUnit 4和TestNG中都可实现。 然而，两者都使用非常不同的方法来实现它。</p><p>JUnit 4</p><p>“@RunWith”和“@Suite”用于运行套件测试。下面的类代码表示在JunitTest5执行之后，单元测试“JunitTest1”和“JunitTest2”一起运行。 所有的声明都是在类内定义的。</p><pre><code>@RunWith(Suite.class)@Suite.SuiteClasses({        JunitTest1.class,        JunitTest2.class})public class JunitTest5 {}</code></pre><p>TestNG</p><p>XML文件用于运行套件测试。以下XML文件表示单元测试“TestNGTest1”和“TestNGTest2”将一起运行。</p><pre><code>&lt;suite name=&quot;My test suite&quot;&gt;  &lt;test name=&quot;testing&quot;&gt;    &lt;classes&gt;       &lt;class name=&quot;com.fsecure.demo.testng.TestNGTest1&quot; /&gt;       &lt;class name=&quot;com.fsecure.demo.testng.TestNGTest2&quot; /&gt;    &lt;/classes&gt;  &lt;/test&gt;&lt;/suite&gt;</code></pre><p>TestNG可以做捆绑类测试，也可以捆绑方法测试。 凭借TestNG独特的“分组”概念，每种方法都可以与一个组合相结合，可以根据功能对测试进行分类(分组)。 例如，</p><p>下面是一个有四个方法的类，三个组(method1，method2和method3)</p><pre><code>@Test(groups=&quot;method1&quot;)public void testingMethod1() {  System.out.println(&quot;Method - testingMethod1()&quot;);}@Test(groups=&quot;method2&quot;)public void testingMethod2() {    System.out.println(&quot;Method - testingMethod2()&quot;);}@Test(groups=&quot;method1&quot;)public void testingMethod1_1() {    System.out.println(&quot;Method - testingMethod1_1()&quot;);}@Test(groups=&quot;method4&quot;)public void testingMethod4() {    System.out.println(&quot;Method - testingMethod4()&quot;);}</code></pre><p>使用以下XML文件，可以仅使用组“method1”执行单元测试。</p><pre><code>&lt;suite name=&quot;My test suite&quot;&gt;  &lt;test name=&quot;testing&quot;&gt;      &lt;groups&gt;      &lt;run&gt;        &lt;include name=&quot;method1&quot;/&gt;      &lt;/run&gt;    &lt;/groups&gt;    &lt;classes&gt;       &lt;class name=&quot;com.fsecure.demo.testng.TestNGTest5_2_0&quot; /&gt;    &lt;/classes&gt;  &lt;/test&gt;&lt;/suite&gt;</code></pre><p>通过“分组”测试概念，集成测试的可能性是无限制的。 例如，我们只能从所有单元测试类中测试“DatabaseFuntion”分组。</p><p><strong>参数化测试</strong></p><p>“参数化测试”是指单位测试参数值的变化。 此功能在JUnit 4和TestNG中都实现。 然而，两者都使用非常不同的方法来实现它。</p><p>JUnit 4</p><p>“@RunWith”和“@Parameter”用于提供单元测试的参数值，@Parameters必须返回List []，参数将作为参数传入类构造函数。</p><pre><code>@RunWith(value = Parameterized.class)public class JunitTest6 {     private int number;     public JunitTest6(int number) {        this.number = number;     }     @Parameters     public static Collection&lt;Object[]&gt; data() {       Object[][] data = new Object[][] { { 1 }, { 2 }, { 3 }, { 4 } };       return Arrays.asList(data);     }     @Test     public void pushTest() {       System.out.println(&quot;Parameterized Number is : &quot; + number);     }}</code></pre><p>这里有很多限制，我们必须遵循“JUnit”的方式来声明参数，并且必须将参数传递给构造函数才能初始化类成员作为测试的参数值。参数类的返回类型为“List []”，数据已被限制为String或用于测试的原始类型值。</p><p>TestNG</p><p>XML文件或“@DataProvider”用于提供不同参数进行测试。</p><p>用于参数化测试的XML文件 -</p><p>只有“@Parameters”在需要参数测试的方法中声明，参数化数据将在TestNG的XML配置文件中提供。 通过这样做，我们可以使用不同数据集的单个测试用例，甚至获得不同的结果。 另外，即使是最终用户，QA还是QE都可以在XML文件中提供自己的数据进行测试。</p><pre><code>public class TestNGTest6_1_0 {@Test@Parameters(value=&quot;number&quot;)public void parameterIntTest(int number) {       System.out.println(&quot;Parameterized Number is : &quot; + number);    }}</code></pre><p>XML文件的内容如下 -</p><pre><code>&lt;suite name=&quot;My test suite&quot;&gt;  &lt;test name=&quot;testing&quot;&gt;    &lt;parameter name=&quot;number&quot; value=&quot;2&quot;/&gt;    &lt;classes&gt;       &lt;class name=&quot;com.fsecure.demo.testng.TestNGTest6_0&quot; /&gt;    &lt;/classes&gt;  &lt;/test&gt;&lt;/suite&gt;</code></pre><p>@DataProvider用于参数化测试</p><p>将数据值拉入XML文件可能非常方便，但测试偶尔会需要复杂的类型，这些类型不能被表示为一个字符串或一个原始类型值。 TestNG使用@DataProvider注解来处理这种情况，这有助于将复杂参数类型映射到测试方法。</p><p>@DataProvider for Vector，String或Integer作为参数，参考如下代码 -</p><pre><code>@Test(dataProvider = &quot;Data-Provider-Function&quot;)    public void parameterIntTest(Class clzz, String[] number) {       System.out.println(&quot;Parameterized Number is : &quot; + number[0]);       System.out.println(&quot;Parameterized Number is : &quot; + number[1]);    }    //This function will provide the patameter data    @DataProvider(name = &quot;Data-Provider-Function&quot;)    public Object[][] parameterIntTestProvider() {        return new Object[][]{                   {Vector.class, new String[] {&quot;java.util.AbstractList&quot;,&quot;java.util.AbstractCollection&quot;}},                   {String.class, new String[] {&quot;1&quot;, &quot;2&quot;}},                   {Integer.class, new String[] {&quot;1&quot;, &quot;2&quot;}}                  };    }</code></pre><p>@DataProvider作为对象的参数</p><p>“TestNGTest6_3_0”是一个简单的对象，只需使用get/set方法进行演示。</p><pre><code>@Test(dataProvider = &quot;Data-Provider-Function&quot;)public void parameterIntTest(TestNGTest6_3_0 clzz) {   System.out.println(&quot;Parameterized Number is : &quot; + clzz.getMsg());   System.out.println(&quot;Parameterized Number is : &quot; + clzz.getNumber());}//This function will provide the patameter data@DataProvider(name = &quot;Data-Provider-Function&quot;)public Object[][] parameterIntTestProvider() {    TestNGTest6_3_0 obj = new TestNGTest6_3_0();    obj.setMsg(&quot;Hello&quot;);    obj.setNumber(123);    return new Object[][]{               {obj}    };}</code></pre><p>TestNG的参数化测试非常用户友好和灵活(在XML文件或类内)。 它可以支持许多复杂的数据类型作为参数值，可能性是无限的。 如上例所示，我们甚至可以传入我们自己的对象(TestNGTest6_3_0)进行参数化测试</p><p><strong>依赖性测试</strong></p><p>“参数化测试”表示方法是依赖性测试，它将在所需方法之前执行。 如果依赖方法失败，则所有后续测试将会被跳过，不会被标记为失败。</p><p>JUnit 4</p><p>JUnit框架着重于测试隔离; 目前它不支持此功能。</p><p>TestNG</p><p>它使用“dependOnMethods”来实现依赖测试如下 -</p><pre><code>@Testpublic void method1() {   System.out.println(&quot;This is method 1&quot;);}@Test(dependsOnMethods={&quot;method1&quot;})public void method2() {    System.out.println(&quot;This is method 2&quot;);}</code></pre><p>“method2()”只有在“method1()”运行成功的情况下才会执行，否则“method2()”将跳过测试。</p><p><strong>结论</strong></p><p>在考虑所有功能比较之后，建议使用TestNG作为Java项目的核心单元测试框架，因为TestNG在参数化测试，依赖测试和套件测试(分组概念)方面更加突出。 TestNG用于高级测试和复杂集成测试。 它的灵活性对于大型测试套件尤其有用。 此外，TestNG还涵盖了整个核心的JUnit4功能。这样说来，好像也没有理由使用JUnit了。</p><h2 id="TestNG与spring或spring-boot结合"><a href="#TestNG与spring或spring-boot结合" class="headerlink" title="TestNG与spring或spring boot结合"></a>TestNG与spring或spring boot结合</h2><h1 id="mockito"><a href="#mockito" class="headerlink" title="mockito"></a>mockito</h1><p>mockito的官网：<a href="http://site.mockito.org/" target="_blank" rel="noopener">http://site.mockito.org/</a><br>在实际项目中写单元测试的过程中我们会发现需要测试的类有很多依赖，这些依赖项又会有依赖，导致在单元测试代码里几乎无法完成构建，尤其是当依赖项尚未构建完成时会导致单元测试无法进行。为了解决这类问题我们引入了Mock的概念，简单的说就是模拟这些需要构建的类或者资源，提供给需要测试的对象使用。业内的Mock工具有很多，也已经很成熟了，这里我们将直接使用最流行的Mockito进行实战演练，完成mockito教程。</p><p>EasyMock 以及 Mockito 都因为可以极大地简化单元测试的书写过程而被许多人应用在自己的工作中，但是这两种 Mock 工具都不可以实现对静态函数、构造函数、私有函数、Final 函数以及系统函数的模拟，但是这些方法往往是我们在大型系统中需要的功能。</p><h2 id="如何使用Mockito？"><a href="#如何使用Mockito？" class="headerlink" title="如何使用Mockito？"></a>如何使用Mockito？</h2><p>第一步：在项目的pom中添加依赖，我用的阿里库的mockito版本为2.9.0的版本，ali的maven库中找到mockito-core的依赖jar，导入项目pom<br>也可以直接去官网下载相应的jar包，更新到了2.17版本。</p><p>第二步：另外Mockito需要Junit配合使用，在Pom文件中同样引入：junit4的版本。</p><p>第三步：然后为了使代码更简洁，最好在测试类中导入静态资源，还有为了使用常用的junit关键字，也要引入junit的两个类Before和Test：</p><pre><code>import static org.mockito.Mockito.*;import static org.junit.Assert.*;import org.junit.Before;import org.junit.Test;</code></pre><p>第四步：然后就可以编写测试代码进行使用了，这里用junit的测试步骤来测试即可，mockito主要的功能就是模拟。。。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;测试是检查应用程序的功能的过程是否按要求工作，在开发人员层面进行单元测试，在采取适当措施来测试每一个实体（类或方法）以确保最终产品符合要求。单元测试是非常必要的，这是软件公司向他们的客户提供高质量的软件产品必要前提。&lt;/p&gt;
&lt;p&gt;较常用的测试框架是Junit4，这个是老框架，现在的互联网开发公司常用的新框架有testng和mockito两种。&lt;br&gt;单元测试用例是代码的一部分从而确保代码（方法）的另一部分工作正常。要快速实现这些理想的效果，测试框架是必需的。JUnit对于Java编程语言是完美的单元测试框架。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="java类库" scheme="http://yoursite.com/tags/java%E7%B1%BB%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>JAVA-理解文章汇总（不断更新）</title>
    <link href="http://yoursite.com/2018/04/03/java-se/"/>
    <id>http://yoursite.com/2018/04/03/java-se/</id>
    <published>2018-04-03T10:45:01.000Z</published>
    <updated>2018-04-03T18:18:41.957Z</updated>
    
    <content type="html"><![CDATA[<p>JAVA基础总结，持续更新，以防忘记。<br><a id="more"></a></p><h1 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h1><h2 id="JDK8后的接口新规"><a href="#JDK8后的接口新规" class="headerlink" title="JDK8后的接口新规"></a>JDK8后的接口新规</h2><p>在jdk8之前，interface之中可以定义变量和方法，变量必须是public、static、final的，方法必须是public、abstract的。由于这些修饰符都是默认的，所以在JDK8之前，下面的写法都是等价的。</p><pre><code>public interface JDK8BeforeInterface {      public static final int field1 = 0;      int field2 = 0;      public abstract void method1(int a) throws Exception;      void method2(int a) throws Exception;  }  </code></pre><p>接口变量的默认修饰是public static final，就是自动声明为常量，这些都是隐式默认的规则，所以直接用public声明也是一样的效果，变量必须是常量，而方法也必须的抽象方法，且限定修饰符必须是public，这些也是隐式规定的。</p><p>JDK8及以后，允许我们在接口中定义static方法和default方法。也就是静态方法和默认方法。<br>static方法和default方法都可以直接在接口里写方法体（方法的具体逻辑）了。<br>这就是java变相的让接口能够结合抽象类的功能。</p><pre><code>public interface JDK8Interface {      // static修饰符定义静态方法      static void staticMethod() {          System.out.println(&quot;接口中的静态方法&quot;);      }      // default修饰符定义默认方法      default void defaultMethod() {          System.out.println(&quot;接口中的默认方法&quot;);      }  }  </code></pre><p>再定义一个接口的实现类：</p><pre><code>public class JDK8InterfaceImpl implements JDK8Interface {      //实现接口后，因为默认方法不是抽象方法，所以可以不重写，但是如果开发需要，也可以重写  }  </code></pre><p>default修饰的方法可以不重写，根据其实现类的对象来调用这个接口的default方法<br>而静态方法则是只能这个接口名来直接调用。<br>静态方法，只能通过接口名调用，不可以通过实现类的类名或者实现类的对象调用。default方法，只能通过接口实现类的对象来调用。</p><pre><code>public class Main {      public static void main(String[] args) {          // static方法必须通过接口类调用          JDK8Interface.staticMethod();          //default方法必须通过实现类的对象调用          new JDK8InterfaceImpl().defaultMethod();      }  } </code></pre><p>当然如果接口中的默认方法不能满足某个实现类需要，那么实现类可以覆盖默认方法。</p><pre><code>public class AnotherJDK8InterfaceImpl implements JDK8Interface {      // 签名跟接口default方法一致,但是不能再加default修饰符      @Override      public void defaultMethod() {          System.out.println(&quot;接口实现类覆盖了接口中的default&quot;);      }  }      </code></pre><p>由于java支持一个实现类可以实现多个接口，如果多个接口中存在同样的static和default方法会怎么样呢？如果有两个接口中的静态方法一模一样，并且一个实现类同时实现了这两个接口，此时并不会产生错误，因为jdk8只能通过接口类调用接口中的静态方法，所以对编译器来说是可以区分的。但是如果两个接口中定义了一模一样的默认方法，并且一个实现类同时实现了这两个接口，那么必须在实现类中重写默认方法，否则编译失败。</p><p>例如JDK8Interface1也有一个defaultMethod()</p><pre><code>public interface JDK8Interface1 {      // static修饰符定义静态方法      static void staticMethod() {          System.out.println(&quot;JDK8Interface1接口中的静态方法&quot;);      }      // default修饰符定义默认方法      default void defaultMethod() {          System.out.println(&quot;JDK8Interface1接口中的默认方法&quot;);      }  } </code></pre><p>必须要覆盖defaultMethod()，然后调用的时候JVM才不会混乱，不然JVM不知道调用哪个default方法</p><pre><code>public class JDK8InterfaceImpl implements JDK8Interface,JDK8Interface1 {      // 由于JDK8Interface和JDK8Interface1中default方法一样,所以这里必须覆盖      @Override      public void defaultMethod() {          System.out.println(&quot;接口实现类覆盖了接口中的default&quot;);      }  } </code></pre><p>对象调用的是重写后的defaultMethod()。</p><pre><code>public class Main {      public static void main(String[] args) {          JDK8Interface.staticMethod();          JDK8Interface1.staticMethod();          new JDK8InterfaceImpl().defaultMethod();      }  }</code></pre><h1 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h1><p>多态是同一个行为具有多个不同表现形式或形态的能力。<br>多态就是同一个接口，使用不同的实例而执行不同操作，如图所示：</p><p><img src="/2018/04/03/java-se/p1.png" alt="logo"> </p><p>多态性是对象多种表现形式的体现。</p><p>现实中，比如我们按下 F1 键这个动作：<br>如果当前在 Flash 界面下弹出的就是 AS 3 的帮助文档；<br>如果当前在 Word 下弹出的就是 Word 帮助；<br>在 Windows 下弹出的就是 Windows 帮助和支持。</p><p>同一个事件发生在不同的对象上会产生不同的结果。</p><p>多态的优点<br>1.消除类型之间的耦合关系<br>2.可替换性<br>3.可扩充性<br>4.接口性<br>5.灵活性<br>6.简化性</p><p>多态存在的三个必要条件</p><p>1.继承<br>2.重写<br>3.父类引用指向子类对象</p><p>比如：<br>Parent p = new Child();//这就是典型的多态</p><p>当使用多态方式调用方法时，首先检查父类中是否有该方法，如果没有，则编译错误；如果有，再去调用子类的同名方法。<br>多态的好处：可以使程序有良好的扩展，并可以对所有类的对象进行通用处理。<br>以下是一个多态实例的演示，详细说明请看注释：</p><pre><code>public class Test {    public static void main(String[] args) {      show(new Cat());  // 以 Cat 对象调用 show 方法      show(new Dog());  // 以 Dog 对象调用 show 方法      Animal a = new Cat();  // 向上转型        a.eat();               // 调用的是 Cat 的 eat      Cat c = (Cat)a;        // 向下转型        c.work();        // 调用的是 Cat 的 work  }      public static void show(Animal a)  {      a.eat();          // 类型判断        if (a instanceof Cat)  {  // 猫做的事情             Cat c = (Cat)a;              c.work();          } else if (a instanceof Dog) { // 狗做的事情             Dog c = (Dog)a;              c.work();          }      }  }abstract class Animal {      abstract void eat();  }  class Cat extends Animal {      public void eat() {          System.out.println(&quot;吃鱼&quot;);      }      public void work() {          System.out.println(&quot;抓老鼠&quot;);      }  }  class Dog extends Animal {      public void eat() {          System.out.println(&quot;吃骨头&quot;);      }      public void work() {          System.out.println(&quot;看家&quot;);      }  }</code></pre><p>执行以上程序，输出结果为：</p><pre><code>吃鱼抓老鼠吃骨头看家吃鱼抓老鼠</code></pre><p>java多态，如何理解父类引用指向子类对象</p><p>要理解多态性，首先要知道什么是“向上转型”。</p><p>我定义了一个子类Cat，它继承了Animal类，那么后者就是前者是父类。我可以通过   Cat c = new Cat(); 实例化一个Cat的对象，这个不难理解。</p><p>但当我这样定义时：   Animal a = new Cat();  </p><p>表示定义了一个Animal类型的引用，指向新建的Cat类型的对象。由于Cat是继承自它的父类Animal，所以Animal类型的引用是可以指向Cat类型的对象的。</p><p>那么这样做有什么意义呢？因为子类是对父类的一个改进和扩充，所以一般子类在功能上较父类更强大，属性较父类更独特，   定义一个父类类型的引用指向一个子类的对象既可以使用子类强大的功能，又可以抽取父类的共性。 </p><p>所以，父类类型的引用可以调用父类中定义的所有属性和方法，而对于子类中定义而父类中没有的方法，它是无可奈何的；   同时，父类中的一个方法只有在父类中定义而在子类中没有重写的情况下，才可以被父类类型的引用调用；   对于父类中定义的方法，如果子类中重写了该方法，那么父类类型的引用将会调用子类中的这个方法，这就是动态连接。也可以叫做动态绑定。</p><p>动态绑定是指”在执行期间（而非编译期间）“判断所引用对象的实际类型，根据实际的类型调用其相应的方法。</p><p>看下面这段程序：</p><pre><code>class Father {    public void func1()    {        func2();    } // 这是父类中的func2()方法，因为下面的子类中重写了该方法 ，所以在父类类型的引用中调用时，这个方法将不再有效，取而代之的是将调用子类中重写的func2()方法    public void func2() {        System.out.println(&quot;AAA&quot;);    }}class Child extends Father { // func1(int i)是对func1()方法的一个重载   由于在父类中没有定义这个方法，所以它不能被父类类型的引用调用    所以在下面的main方法中child.func1(68)是不对的    public void func1(int i) {        System.out.println(&quot;BBB&quot;);    } // func2()重写了父类Father中的func2()方法   如果父类类型的引用中调用了func2()方法，那么必然是子类中重写的这个方法    public void func2() {        System.out.println(&quot;CCC&quot;);    }}public class PolymorphismTest {    public static void main(String[] args) {        Father child = new Child();        child.func1();// 打印结果将会是什么？ } }         上面的程序是个很典型的多态的例子。子类Child继承了父类Father，并重载了父类的func1()方法，重写了父类的func2()方法。重载后的 func1(int i)和func1()不再是同一个方法，由于父类中没有func1(int i)，那么，父类类型的引用child就不能调用func1(int  i)方法。而子类重写了func2()方法，那么父类类型的引用child在调用该方法时将会调用子类中重写的func2()    }}</code></pre><p>那么该程序将会打印出什么样的结果呢？       很显然，应该是“CCC”。     </p><p>对于多态，可以总结它为：       </p><p>一、使用父类类型的引用指向子类的对象；</p><p>二、该引用只能调用父类中定义的方法和变量；</p><p>三、如果子类中重写了父类中的一个方法，那么在调用这个方法的时候，将会调用子类中的这个方法；（动态连接、动态调用）</p><p>四、变量不能被重写（覆盖），”重写“的概念只针对方法，如果在子类中”重写“了父类中的变量，那么在编译时会报错。</p><p>多态的3个必要条件：<br>1.继承   2.重写   3.父类引用指向子类对象。</p><p>向上转型： Person p = new Man() ; //向上转型不需要强制类型转化<br>向下转型： Man man = (Man)new Person() ; //必须强制类型转化</p><h2 id="虚方法"><a href="#虚方法" class="headerlink" title="虚方法"></a>虚方法</h2><p>我们将介绍在Java中，当设计类时，被重写的方法的行为怎样影响多态性。<br>我们已经讨论了方法的重写，也就是子类能够重写父类的方法。<br>当子类对象调用重写的方法时，调用的是子类的方法，而不是父类中被重写的方法。<br>要想调用父类中被重写的方法，则必须使用关键字super。</p><pre><code>/* 文件名 : Employee.java */public class Employee {   private String name;   private String address;   private int number;   public Employee(String name, String address, int number) {      System.out.println(&quot;Employee 构造函数&quot;);      this.name = name;      this.address = address;      this.number = number;   }   public void mailCheck() {      System.out.println(&quot;邮寄支票给： &quot; + this.name       + &quot; &quot; + this.address);   }   public String toString() {      return name + &quot; &quot; + address + &quot; &quot; + number;   }   public String getName() {      return name;   }   public String getAddress() {      return address;   }   public void setAddress(String newAddress) {      address = newAddress;   }   public int getNumber() {     return number;   }}</code></pre><p>假设下面的类继承Employee类：</p><pre><code>/* 文件名 : Salary.java */public class Salary extends Employee{   private double salary; // 全年工资   public Salary(String name, String address, int number, double salary) {       super(name, address, number);       setSalary(salary);   }   public void mailCheck() {       System.out.println(&quot;Salary 类的 mailCheck 方法 &quot;);       System.out.println(&quot;邮寄支票给：&quot; + getName()       + &quot; ，工资为：&quot; + salary);   }   public double getSalary() {       return salary;   }   public void setSalary(double newSalary) {       if(newSalary &gt;= 0.0) {          salary = newSalary;       }   }   public double computePay() {      System.out.println(&quot;计算工资，付给：&quot; + getName());      return salary/52;   }}</code></pre><p>现在我们仔细阅读下面的代码，尝试给出它的输出结果：</p><pre><code>/* 文件名 : VirtualDemo.java */public class VirtualDemo {   public static void main(String [] args) {      Salary s = new Salary(&quot;员工 A&quot;, &quot;北京&quot;, 3, 3600.00);      Employee e = new Salary(&quot;员工 B&quot;, &quot;上海&quot;, 2, 2400.00);      System.out.println(&quot;使用 Salary 的引用调用 mailCheck -- &quot;);      s.mailCheck();      System.out.println(&quot;\n使用 Employee 的引用调用 mailCheck--&quot;);      e.mailCheck();    }}</code></pre><p>以上实例编译运行结果如下：</p><pre><code>Employee 构造函数Employee 构造函数使用 Salary 的引用调用 mailCheck -- Salary 类的 mailCheck 方法 邮寄支票给：员工 A ，工资为：3600.0使用 Employee 的引用调用 mailCheck--Salary 类的 mailCheck 方法 邮寄支票给：员工 B ，工资为：2400.0</code></pre><p>例子解析</p><p>实例中，实例化了两个 Salary 对象：一个使用 Salary 引用 s，另一个使用 Employee 引用 e。<br>当调用 s.mailCheck() 时，编译器在编译时会在 Salary 类中找到 mailCheck()，执行过程 JVM 就调用 Salary 类的 mailCheck()。<br>因为 e 是 Employee 的引用，所以调用 e 的 mailCheck() 方法时，编译器会去 Employee 类查找 mailCheck() 方法 。<br>在编译的时候，编译器使用 Employee 类中的 mailCheck() 方法验证该语句， 但是在运行的时候，Java虚拟机(JVM)调用的是 Salary 类中的 mailCheck() 方法。<br>以上整个过程被称为虚拟方法调用，该方法被称为虚拟方法。<br>Java中所有的方法都能以这种方式表现，因此，重写的方法能在运行时调用，不管编译的时候源代码中引用变量是什么数据类型。</p><p>多态的实现方式：</p><p>方式一：重写：<br>这个内容已经在上一章节详细讲过，就不再阐述，详细可访问：Java 重写(Override)与重载(Overload)。<br>方式二：接口</p><ol><li>生活中的接口最具代表性的就是插座，例如一个三接头的插头都能接在三孔插座中，因为这个是每个国家都有各自规定的接口规则，有可能到国外就不行，那是因为国外自己定义的接口类型。</li><li>java中的接口类似于生活中的接口，就是一些方法特征的集合，但没有方法的实现。具体可以看 java接口 这一章节的内容。<br>方式三：抽象类和抽象方法</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;JAVA基础总结，持续更新，以防忘记。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="javaSE" scheme="http://yoursite.com/tags/javaSE/"/>
    
  </entry>
  
  <entry>
    <title>Ajax技术浅谈</title>
    <link href="http://yoursite.com/2018/03/31/java-ajax/"/>
    <id>http://yoursite.com/2018/03/31/java-ajax/</id>
    <published>2018-03-31T06:05:40.000Z</published>
    <updated>2018-03-31T07:36:29.088Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是Ajax？"><a href="#什么是Ajax？" class="headerlink" title="什么是Ajax？"></a>什么是Ajax？</h1><p>AJAX即“Asynchronous Javascript And XML”（异步JavaScript和XML），是指一种创建交互式网页应用的网页开发技术。</p><p>AJAX 是一种用于创建快速动态网页的技术。</p><p>通过在后台与服务器进行少量数据交换，AJAX 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的网页（不使用 AJAX）如果需要更新内容，必须重载整个网页页面。AJAX 技术的广泛使用，对B/S模式应用慢慢取代了桌面软件起到了很大的推动作用。<br><a id="more"></a></p><h1 id="同步and异步？"><a href="#同步and异步？" class="headerlink" title="同步and异步？"></a>同步and异步？</h1><p>异步传输是面向字符的传输，它的单位是字符；而同步传输是面向比特的传输，它的单位是桢，它传输的时候要求接受方和发送方的时钟是保持一致的。</p><h2 id="异步传输"><a href="#异步传输" class="headerlink" title="异步传输"></a>异步传输</h2><p>具体来说，异步传输是将比特分成小组来进行传送。一般每个小组是一个8位字符，在每个小组的头部和尾部都有一个开始位和一个停止位，它在传送过程中接收方和发送方的时钟不要求一致，也就是说，发送方可以在任何时刻发送这些小组，而接收方并不知道它什么时候到达。</p><p>一个最明显的例子就是计算机键盘和主机的通信，按下一个键的同时向主机发送一个8比特位的ASCII代 码，键盘可以在任何时刻发送代码，这取决于用户的输入速度，内部的硬件必须能够在任何时刻接收一个键入的字符。这是一个典型的异步传输过程。</p><p>异步传输存在 一个潜在的问题，即接收方并不知道数据会在什么时候到达。在它检测到数据并做出响应之前，第一个比特已经过去了。这就像有人出乎意料地从后面走上来跟你说 话，而你没来得及反应过来，漏掉了最前面的几个词。因此，每次异步传输的信息都以一个起始位开头，它通知接收方数据已经到达了，这就给了接收方响应、接收 和缓存数据比特的时间；在传输结束时，一个停止位表示该次传输信息的终止。按照惯例，空闲（没有传送数据）的线路实际携带着一个代表二进制1的信号。步传输的开始位使信号变成0，其他的比特位使信号随传输的数据信息而变化。最后，停止位使信号重新变回1，该信号一直保持到下一个开始位到达。例如在键盘上数字“1”，按照8比特位的扩展ASCII编码，将发送“00110001”，同时需要在8比特位的前面加一个起始位，后面一个停止位。</p><h2 id="同步传输"><a href="#同步传输" class="headerlink" title="同步传输"></a>同步传输</h2><p>同步传输的比特分组要大得多。它不是独立地发送每个字符，每个字符都有自己的开始位和停止位，而是把它们组合起来一起发送。我们将这些组合称为数据帧，或简称为帧。</p><p>数据帧的第一部分包含一组同步字符，它是一个独特的比特组合，类似于前面提到的起始位，用于通知接收方一个帧已经到达，但它同时还能确保接收方的采样速度和比特的到达速度保持一致，使收发双方进入同步。</p><p>帧的最后一部分是一个帧结束标记。与同步字符一样，它也是一个独特的比特串，类似于前面提到的停止位，用于表示在下一帧开始之前没有别的即将到达的数据了。</p><p>同步传输通常要比异步传输快速得多。接收方不必对每个字符进行开始和停止的操作。一旦检测到帧同步字符，它就在接下来的数据到达时接收它们。另外，同步传输的开销也比较少。例如，一个典型的帧可能有500字节（即4000比特）的数据，其中可能只包含100比特的开销。这时，增加的比特位使传输的比特总数增加2.5%，这与异步传输中25 %的增值要小得多。随着数据帧中实际数据比特位的增加，开销比特所占的百分比将相应地减少。但是，数据比特位越长，缓存数据所需要的缓冲区也越大，这就限制了一个帧的大小。另外，帧越大，它占据传输媒体的连续时间也越长。在极端的情况下，这将导致其他用户等得太久。</p><p>了解了同步和异步的概念之后，大家应该对ajax为什么可以提升用户体验应该比较清晰了，它是利用异步请求方式的。打个比方，如果现在你家里所在的小区因 某种情况而面临停水，现在有关部门公布了两种方案，一是完全停水8个小时，在这8个小时内完全停水，8个小时后恢复正常。二是不完全停水10 个小时，在这10个小时内水没有完全断，只是流量比原来小了很多，在10个小时后恢复正常流量，那么，如果是你你会选择哪种方式呢？显然是后者。</p><h1 id="AJAX-所包含的技术"><a href="#AJAX-所包含的技术" class="headerlink" title="AJAX 所包含的技术"></a>AJAX 所包含的技术</h1><p>大家都知道ajax并非一种新的技术，而是几种原有技术的结合体。它由下列技术组合而成。</p><p>1.使用CSS和XHTML来表示。<br>2.使用DOM模型来交互和动态显示。<br>3.使用XMLHttpRequest来和服务器进行异步通信。<br>4.使用javascript来绑定和调用。</p><p>在上面几中技术中，除了XmlHttpRequest对象以外，其它所有的技术都是基于web标准并且已经得到了广泛使用的，XMLHttpRequest虽然目前还没有被W3C所采纳，但是它已经是一个事实的标准，因为目前几乎所有的主流浏览器都支持它。</p><h1 id="XMLHttpRequest-对象"><a href="#XMLHttpRequest-对象" class="headerlink" title="XMLHttpRequest 对象"></a>XMLHttpRequest 对象</h1><p>Ajax的原理简单来说通过XmlHttpRequest对象来向服务器发异步请求，从服务器获得数据，然后用javascript来操作DOM而更新页面。这其中最关键的一步就是从服务器获得请求数据。要清楚这个过程和原理，我们必须对 XMLHttpRequest有所了解。</p><p>XMLHttpRequest是ajax的核心机制，它是在IE5中首先引入的，是一种支持异步请求的技术。简单的说，也就是javascript可以及时向服务器提出请求和处理响应，而不阻塞用户。达到无刷新的效果。<br>所以我们先从XMLHttpRequest讲起，来看看它的工作原理。<br>首先，我们先来看看XMLHttpRequest这个对象的属性。<br>它的属性有：</p><p>onreadystatechange  每次状态改变所触发事件的事件处理程序。<br>responseText     从服务器进程返回数据的字符串形式。<br>responseXML    从服务器进程返回的DOM兼容的文档数据对象。<br>status           从服务器返回的数字代码，比如常见的404（未找到）和200（已就绪）<br>status Text       伴随状态码的字符串信息<br>readyState       对象状态值<br>　　0 (未初始化) 对象已建立，但是尚未初始化（尚未调用open方法）<br>　　1 (初始化) 对象已建立，尚未调用send方法<br>　　2 (发送数据) send方法已调用，但是当前的状态及http头未知<br>　　3 (数据传送中) 已接收部分数据，因为响应及http头不全，这时通过responseBody和responseText获取部分数据会出现错误，<br>　　4 (完成) 数据接收完毕,此时可以通过通过responseXml和responseText获取完整的回应数据<br>通常都是用readystate==4这个状态码判断传输是否完成。</p><h1 id="如何使用Ajax技术呢？"><a href="#如何使用Ajax技术呢？" class="headerlink" title="如何使用Ajax技术呢？"></a>如何使用Ajax技术呢？</h1><p>这里通常我们开发WEB项目若是用到Ajax技术，首先先要创建XMLHttpRequest这个对象，以为这是一个公共代码，我们可以直接在单独的js脚本文件中创建这个对象，以便所有的html5中都可以使用这个对象，只需要<script>调用这个js脚本即可。</p><pre><code>//获得ajax对象 function getXhr(){          var xhr=null;          if(window.XMLHttpRequest){              //非ie浏览器              xhr=new XMLHttpRequest();          }else{              //ie浏览器              xhr=new ActiveXObject(                      &quot;Microsoft.XMLHttp&quot;);          }          return xhr;}</code></pre><p>因为IE和其他浏览器的纷争，这里是W3C制定的统一规范，本来是微软发明的，但是微软不肯将自己的技术交给W3C，因此出现了IE浏览器要和其他浏览器做一个if判定。（中间微软和W3C关于ajax技术的所有权可以去看下相关报道）</p><pre><code>&lt;script type=&quot;text/javascript&quot;&gt;     function check_adminCode(){         //step1:先获得ajax对象         //在ajax.js文件中，外部引入         var xhr=getXhr();         //弹出这个xhr对象信息,测试js代码是否正确         //当触发事件的时候会调用这个函数       //alert(xhr);         //step2:发送请求         //a.准备工作(请求方式,发送地址?数据,是否异步)         //因为是get方式发送         //所以路径后面是要传递的数据         //$F是取得根据该节点id取得对应的值         var uri=&apos;check_admin.do?adminCode=&apos; + $F(&apos;adminCode&apos;);         //encodeURI是javascript函数，         xhr.open(&apos;get&apos;,encodeURI(uri),true);         //b.绑定事件处理函数         //用于处理服务器返回数据并用于展现         //因为事件处理函数也需要xhr对象进行判断         //所以这里的事件处理函数直接用匿名函数来写就好         xhr.onreadystatechange=function(){             //step3是编写服务器端的相关带代码             //step4编写事件处理函数             if(xhr.readyState==4 &amp;&amp; xhr.status==200){                 //通信状态为4，表示其完全收到服务端传来的数据                 //status为200，即表示成功                 var res=xhr.responseText;//返回的是文本                 //并将数据进行展示                // alert(res);弹出警告的方式不友好                 //先找到要显示的位置span标签                 //innerHTML是输出文本信息                 $(&apos;adminCode_msg&apos;).innerHTML=res;             }         };         //c.发送         //get方式的参数是null，post则是数据         xhr.send(null);     }&lt;/script&gt;</code></pre><p>以上这些代码是根据传统的模式，调用XMLHttpRequest对象的属性去赋值，显然太过麻烦。</p><p>一般是采用和Jquery框架结合的方法：<br>通过jQuery内置的$.ajax({“attribute”:”value”…});的写法即可完成异步传输。</p><pre><code>function quoto(){      //利用jQuery提供的方法来向服务器发送请求      $.ajax({          //url发送请求，然后服务器就会返回数据          &quot;url&quot;:&quot;quoto.do&quot;,          &quot;type&quot;:&quot;post&quot;,          &quot;dataType&quot;:&quot;json&quot;,          &quot;success&quot;:function(stocks){              //事件处理函数              //dataType会自动将json字符串转换为js对象              //success指定的这个匿名函数中的参数              //就是经过jquery转换的那个javascript对象              //追加数据之前要先清空之前的表格内容tbody              //不是remove而是empty。数据清空              $(&apos;#tb1&apos;).empty();              //因为服务器传来的数据是一个数组              //所以需要遍历输出              for(i=0;i&lt;stocks.length;i++){                  //注意js中没有int类型，统统都用var                  //所以用for循环的时候要注意                  var s=stocks[i];                  //更新表格                  //往tbody标签中插入数据,循环插入                  $(&apos;#tb1&apos;).append(                          &apos;&lt;tr&gt;&lt;td&gt;&apos; + s.code +                          &apos;&lt;/td&gt;&lt;td&gt;&apos; + s.name +                           &apos;&lt;/td&gt;&lt;td&gt;&apos; + s.price +                           &apos;&lt;/td&gt;&lt;/tr&gt;&apos;);              }          }      });  }</code></pre><h1 id="AJAX-的缺点"><a href="#AJAX-的缺点" class="headerlink" title="AJAX 的缺点"></a>AJAX 的缺点</h1><p>AJAX的优点不言而喻。</p><p>下面所阐述的ajax的缺陷都是它先天所产生的。<br>1、ajax干掉了back按钮，即对浏览器后退机制的破坏。后退按钮是一个标准的web站点的重要功能，但是它没法和js进行很好的合作。这是ajax所带来的一个比较严重的问题，因为用户往往是希望能够通过后退来取消前一次操作的。那么对于这个问题有没有办法？答案是肯定的，用过Gmail的知道，Gmail下面采用的ajax技术解决了这个问题，在Gmail下面是可以后退的，但是，它也并不能改变ajax的机制，它只是采用的一个比较笨但是有效的办法，即用户单击后退按钮访问历史记录时，通过创建或使用一个隐藏的IFRAME来重现页面上的变更。（例如，当用户在Google Maps中单击后退时，它在一个隐藏的IFRAME中进行搜索，然后将搜索结果反映到Ajax元素上，以便将应用程序状态恢复到当时的状态。）<br>但是，虽然说这个问题是可以解决的，但是它所带来的开发成本是非常高的，和ajax框架所要求的快速开发是相背离的。这是ajax所带来的一个非常严重的问题。</p><p>2、安全问题<br>技术同时也对IT企业带来了新的安全威胁，ajax技术就如同对企业数据建立了一个直接通道。这使得开发者在不经意间会暴露比以前更多的数据和服务器逻辑。ajax的逻辑可以对客户端的安全扫描技术隐藏起来，允许黑客从远端服务器上建立新的攻击。还有ajax也难以避免一些已知的安全弱点，诸如跨站点脚步攻击、SQL注入攻击和基于credentials的安全漏洞等。</p><p>3、对搜索引擎的支持比较弱。</p><p>4、破坏了程序的异常机制。至少从目前看来，像ajax.dll，ajaxpro.dll这些ajax框架是会破坏程序的异常机制的。关于这个问题，我曾经在开发过程中遇到过，但是查了一下网上几乎没有相关的介绍。后来我自己做了一次试验，分别采用ajax和传统的form提交的模式来删除一条数据……给我们的调试带来了很大的困难。</p><p>5、另外，像其他方面的一些问题，比如说违背了url和资源定位的初衷。例如，我给你一个url地址，如果采用了ajax技术，也许你在该url地址下面看到的和我在这个url地址下看到的内容是不同的。这个和资源定位的初衷是相背离的。</p><p>6、一些手持设备（如手机、PDA等）现在还不能很好的支持ajax，比如说我们在手机的浏览器上打开采用ajax技术的网站时，它目前是不支持的，当然，这个问题和我们没太多关系。</p></script></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是Ajax？&quot;&gt;&lt;a href=&quot;#什么是Ajax？&quot; class=&quot;headerlink&quot; title=&quot;什么是Ajax？&quot;&gt;&lt;/a&gt;什么是Ajax？&lt;/h1&gt;&lt;p&gt;AJAX即“Asynchronous Javascript And XML”（异步JavaScript和XML），是指一种创建交互式网页应用的网页开发技术。&lt;/p&gt;
&lt;p&gt;AJAX 是一种用于创建快速动态网页的技术。&lt;/p&gt;
&lt;p&gt;通过在后台与服务器进行少量数据交换，AJAX 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的网页（不使用 AJAX）如果需要更新内容，必须重载整个网页页面。AJAX 技术的广泛使用，对B/S模式应用慢慢取代了桌面软件起到了很大的推动作用。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="javascript" scheme="http://yoursite.com/tags/javascript/"/>
    
      <category term="ajax" scheme="http://yoursite.com/tags/ajax/"/>
    
  </entry>
  
  <entry>
    <title>谈SAAS</title>
    <link href="http://yoursite.com/2018/03/31/SAAS/"/>
    <id>http://yoursite.com/2018/03/31/SAAS/</id>
    <published>2018-03-30T16:37:39.000Z</published>
    <updated>2018-03-30T17:29:35.547Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Saas"><a href="#Saas" class="headerlink" title="Saas"></a>Saas</h1><p>SaaS是Software-as-a-Service（软件即服务）的简称，随着互联网技术的发展和应用软件的成熟， 在21世纪开始兴起的一种完全创新的软件应用模式。它与“on-demand software”（按需软件)，the application service provider(ASP，应用服务提供商)，hosted software(托管软件)所具有相似的含义。它是一种通过Internet提供软件的模式，厂商将应用软件统一部署在自己的服务器上，客户可以根据自己实际需求，通过互联网向厂商定购所需的应用软件服务，按定购的服务多少和时间长短向厂商支付费用，并通过互联网获得厂商提供的服务。<br><a id="more"></a></p><p>用户不用再购买软件，而改用向提供商租用基于Web的软件，来管理企业经营活动，且无需对软件进行维护，服务提供商会全权管理和维护软件，软件厂商在向客户提供互联网应用的同时，也提供软件的离线操作和本地数据存储，让用户随时随地都可以使用其定购的软件和服务。对于许多小型企业来说，SaaS是采用先进技术的最好途径，它消除了企业购买、构建和维护基础设施和应用程序的需要。</p><p>SaaS 应用软件的价格通常为“全包”费用，囊括了通常的应用软件许可证费、软件维护费以及技术支持费，将其统一为每个用户的月度租用费。 对于广大中小型企业来说，SaaS是采用先进技术实施信息化的最好途径。但SaaS绝不仅仅适用于中小型企业，所有规模的企业都可以从SaaS中获利。</p><p>SaaS有什么特别之处呢？其实在云计算还没有盛行的时代，我们已经接触到了一些SaaS的应用，通过浏览器我们可以使用Google、百度等搜索系统，可以使用E-mail，我们不需要在自己的电脑中安装搜索系统或者邮箱系统。典型的例子，我们在电脑上使用的Word、Excel、PowerPoint等办公软件，这些都是需要在本地安装才能使用的；而在GoogleDocs（DOC、XLS、ODT、ODS、RTF、CSV和PPT等）、MicrosoftOfficeOnline（WordOnline、ExcelOnline、PowerPointOnline和OneNoteOnline）网站上，无需在本机安装，打开浏览器，注册帐号，可以随时随地通过网络来使用这些软件编辑、保存、阅读自己的文档。对于用户只需要自由自在地使用，不需要自己去升级软件、维护软件等操作。由用户自主维护转化为公司为这些项目服务提供全套托管，用户不用担心升级软件所需要的东西，无需维护产品的安装包，全部操作都在WEB端进行。用户购买软件产品转为在网站租用公司的产品服务费用，改成租赁的形式。</p><p>关于这些数据的安全性，SaaS提供商通过有效的技术措施，可以保证每家企业数据的安全性和保密性。</p><p>SaaS采用灵活租赁的收费方式。一方面，企业可以按需增减使用帐号；另一方面，企业按实际使用账户和实际使用时间（以月/年计）付费。由于降低了成本，SaaS的租赁费用较之传统软件许可模式更加低廉。<br>企业采用SaaS模式在效果上与企业自建信息系统基本没有区别，但节省了大量资金，从而大幅度降低了企业信息化的门槛与风险。</p><p>这就是软件即服务。由以前去买软件，到现在去买服务。</p><p>CRM即客户关系管理（client relation message）<br>ERP系统是企业资源计划(Enterprise Resource Planning )的简称，企业全面化管理平台<br>EHR即电子人力资源管理系统（electric-human resources）<br>SCM即软件配置管理（software configuration Message）<br>OA即办公自动化平台（Office Automation）</p><p><strong>应该都可以Saas化</strong></p><p>a、实际上saas主要在CRM软件领域应用广泛。<br>b、另外，进销存，物流软件等也是一种应用。<br>C、更广义的是工具化SaaS，比如视频会议租用等，企业邮箱等成为SaaS应用的主要应用。</p><p>优点<br>对企业来说，SaaS的优点在于：<br>⒈ 从技术方面来看：SaaS是简单的部署，不需要购买任何硬件，刚开始只需要简单注册即可。企业无需再配备IT方面的专业技术人员，同时又能得到最新的技术应用，满足企业对信息管理的需求。<br>⒉ 从投资方面来看：企业只以相对低廉的“月费”方式投资，不用一次性投资到位，不占用过多的营运资金，从而缓解企业资金不足的压力；不用考虑成本折旧问题，并能及时获得最新硬件平台及最佳解决方案。<br>⒊ 从维护和管理方面来看：由于企业采取租用的方式来进行物流业务管理，不需要专门的维护和管理人员，也不需要为维护和管理人员支付额外费用。很大程度上缓解企业在人力、财力上的压力，使其能够集中资金对核心业务进行有效的运营；SaaS能使用户在世界上都是一个完全独立的系统。如果您连接到网络，就可以访问系统。</p><p>缺点<br>1.安全性：企业，尤其是大型企业，很不情愿使用SaaS正是因为安全问题，他们要保护他们的核心数据，不希望这些核心数据由第三方来负责。<br>2.标准化：SaaS解决方案缺乏标准化。这个行业刚刚起步，没有明确的解决办法，一家公司可以设计建立一个解决方案。鉴于复杂和高度可定制的ERP产品，这是一个冒险的建议。</p><h1 id="关于Saas的数据安全"><a href="#关于Saas的数据安全" class="headerlink" title="关于Saas的数据安全"></a>关于Saas的数据安全</h1><p>软件即服务已成为了流行的趋势，整个SaaS的范畴涵盖了广泛的用户可以获取并利用的应用，而SaaS的普及也代表着在未来随着互联网的发展，用户不必再投资于任何服务器或是自己的设备上安装任何软件。<br>从包含了在线Office应用程序的GoogleApps到Adobe的Buzzword服务，以及通过LiveOffice和Hotmail提供的电子邮件及即时消息服务都是很好的SaaS的例证。同时，你还会发现大量的在线备份和数据保护服务，无论是IronMoutain还是AmeriVault，当然，其中还包括一些规模较大的供应商，如EMC、IBM、HP，也加入到了这个市场中来，正在日益将其发展方向转向服务以扩大他们的市场。<br>通过提供这些软件，企业们提供了SaaS服务或是将你的数据存放在他的服务器上，以及获取捏计算机系统，所以，引伸出一个问题：用户使用这些服务的安全性到底如何？<br>“中小型企业必须非常谨慎的挑选供应商以存储他们宝贵的数据。”分析机构IDC的分析师Laura DuBois表示，这位分析师一直关注在线存储服务以及SaaS领域的发展动向，曾在一篇文章中表示，由于在线存储服务来势汹汹，IDC甚至没有为其准备好一个相应的分类方法。<br>很明显，可取的做法是尽可能多的了解该公司是如何提供SaaS服务的，他们为了您的信息的安全做了什么？如果你需要恢复数据，需要多久才能收到？该公司是否能够在低迷而又不稳定的市场中长久生存下去？这些都是你应该问问自己的关键问题–只有做出满意的答案才能够任何选择SaaS供应商的决定。<br>SaaS能够节省用户在部署应用时捆绑的软件许可、硬件以及管理成本，但是这并不意味着SaaS就是每一个人都是使用的。当打算选择一家SaaS供应商时，你应该深入了解这家供应商到底能够提供多少实质性内容，反面的典型就是不愿意向用户提供详细的参考资料或是只有很低用户口碑度。<br>“在SaaS的世界里，留住用户的数字是一个非常重要的宣传。”LiveOffice公司的总裁Matt Smith这样认为，他的公司提供电子邮件、即时消息以及其它SaaS产品，”一个可靠的公司的客户保持率应该至少在98%。”<br>如果这是一家刚刚成立的没有太多用户听说过的初创厂商，你就需要进行更加彻底的调查，以核实其原有的一些用户是否成功交付了。<br>从另一个角度来看，评价一个SaaS提供商还要看用户的支持度，也许有些供应商的设备看起来是豪华的，但是却可能是华而不实的并不中用，尤其是可能会很薄弱的售后支持，虽然在某些情况下，熟练的服务人员和专业的顶尖的技术支持可能与其高昂的价格相比并不值得。<br>“这实际上取决于公司想要什么，”Iron Mountain公司Digital Record Center for Images服务的总经理Tom Meyer认为，”一些供应商并不具备高度安全的内容管理系统，所以他们提供的在线存储空间价格低廉而且简单易行，但是这确实可能会被罚款的。”<br>很清楚的一件事是，安全应该是供应商在选择SaaS标准之前就应考虑的问题并且应该一直放在核心位置，这些在线服务提供商的一个重要的工作就是如何保持其数据的安全，并且确保保护这些数据的保障系统的安全，以免使其遭受灾难。<br>“小型企业的拥有者应该问问供应商如何存储他们的数据，”Smith认为，”<strong>一个好的供应商应该有多个镜像数据中心</strong>，这也就意味着客户端的数据备份在多个地点和多个时间内总是可以用的。”</p><p>SaaS厂商利用各种方式来保障他们的数据，他们其中的一些喜欢使用提供了数据加密功能的磁盘阵列，另外一些供应商的方法更加机械化，他们将数据存放在一个大的仓库中，并给予起一个孤立但是安全的位置。<br>Iron Mountain公司提供了一项名为Digital Record Center for Images的服务，这项服务为用户提供了数据加密传输、用户访问路径控制以及确保位于地下200英尺的数据中心的安全的服务。<br>备份和存储SaaS提供商Elephant Drive通过将数据存储在多个基于硬盘的存储池并进行复制的方法来保证用户数据的安全，数据复制保护功能被集成到其产品系统中，所有的数据都可以让用户在位于至少两个不同地点的独立站点进行访问。<br>AmeriVault也是一家在线备份服务提供商，其帮助用户在三个地点保存用户的备份数据，每个用户的数据都存放在两个不同的磁盘系统中，第三份备份则放置在1000公里之外的保证业务连续性的站点中。<br>在线备份提供商DS3则使用EMCClariion作为主存储设备，为了保证备份方便，他们将备份的数据保存在其他的高端磁盘系统中，在DS3的三个数据中心中，有一个数据中心专门用于保存用户的信息的备份。<br>“任何一家有个良好信誉的SaaS供应商都应该采取必要合适的措施确保他们服务器的安全，并且为每个用户都展现出所有的操作。”Smith表示。</p><p>服务满意度</p><p>服务级别协议是我们通常用来判断一个SaaS服务是否令用户满意的工具，SLA是一项针对提供某种程度上的稳定性的厂商的合同义务，Smith认为，当前使用SLA协议的用户达到了99%以上。<br>此外，SLA协议还包括如果合同到期的话，SaaS服务提供商应该如何处理用户数据的条款，在这种情况下，用户应该确保拥有这些信息的所有权，并且确认是受到法律保护的。<br>例如，Prince Street Capital Management公司采用了由Data Storage公司提供的备份服务，这项服务可以对企业的电子邮件系统实施保护，并对离线数据存储池进行保护，确保远程存储安全以及信息的快速恢复，SLA协议在其中也是一个重要的组成部分。<br>该公司的首席财务官Peter McKown表示，”在你寻找一款适合的备份和恢复解决方案时，对Microsoft Exchange的快速恢复是一个重要的考查标准，在选择了Data Storage服务作为我们的备份和恢复服务管理合作伙伴之后，我们的业务获得了充分的满足，服务水平超过了我们的想象。”</p><p>用户质疑SaaS是很正常的，但是从多个方面来看，在十几年前业界关于电子商务的不休争论时，这些质疑就已经存在了。<br>SaaS服务模式与传统许可模式软件有很大的不同，它是未来管理软件的发展趋势。相比较传统服务方式而言SaaS具有很多独特的特征：SaaS不仅减少了或取消了传统的软件授权费用，而且厂商将应用软件部署在统一的服务器上，免除了最终用户的服务器硬件、网络安全设备和软件升级维护的支出，客户不需要除了个人电脑和互联网连接之外的其它IT投资就可以通过互联网获得所需要软件和服务。此外，大量的新技术，如Web Service，提供了更简单、更灵活、更实用的SaaS。</p><p>另外，SaaS供应商通常是按照客户所租用的软件模块来进行收费的，因此用户可以根据需求按需订购软件应用服务，而且SaaS的供应商会负责系统的部署、升级和维护。而传统管理软件通常是买家需要一次支付一笔可观的费用才能正式启动。</p><p>ERP这样的企业应用软件，软件的部署和实施比软件本身的功能、性能更为重要，万一部署失败，那所有的投入几乎全部白费，这样的风险是每个企业用户都希望避免的。通常的ERP、CRM项目的部署周期至少需要一两年甚至更久的时间，而SaaS模式的软件项目部署通常只占五分之一时间，而且用户无需在软件许可证和硬件方面进行投资。传统软件在使用方式上受空间和地点的限制，必须在固定的设备上使用，而SaaS模式的软件项目可以在任何可接入互联网的地方与时间使用。相对于传统软件而言，SaaS模式在软件的升级、服务、数据安全传输等各个方面都有很大的优势。</p><p>SaaS已成为软件产业的一个重要力量。只要SaaS的品质和可信度能继续得到证实，它的魅力就不会消退。例如中企云软基于excel平台和excel服务器，使这一服务云端化，支持在线定制，在线服务，在线使用，让用户无需自建服务器即可轻松拥有saas+paas的平台。而协达软件的渡云SAAS则通过“微商务”的方式让用户低成本使用简洁易用的微型SAAS应用功能，从而逐步升级到更贴身的应用功能上。</p><p>过去，很多中小企业对于数据安全都有所顾虑，他们不知道是不是可以信任那些初创厂商，或是不太确定电子商务是一个稳定的业务模式，但是在10年之后，似乎每个人都多多少少和电子商务有所联系，不过，要是想让企业也接受这个全新的技术还要等一段时间。</p><p>同样的，SaaS服务也需要经历这样的循环，赢得人们的信任是SaaS服务提供商们不得不面对的一项日产共工作，但是对于那些只有几个技术人员或是根本没有IT部门的中小企业来说，SaaS确实有很重要的作用，能够为企业提供他们必须要完成的工作。</p><p>同时，如果你是Prince Street公司的话，或许你需要和多个厂商合作，DuBois认为，在判断究竟哪一个供应商才是可信的时候，用户需要问自己三个问题：谁是技术提供商？谁是管理他们数据的供应商？谁负责建设数据中心和他们的基本数据架构？</p><p>她认为：”在很多情况下，这些问题的答案指向不同的三个厂商，因此每个层次都会有危险存在，在任何情况下，用户要认真的了解隐私性、加密、可用性、恢复时间、SLA协议、成本以及合同期限等细节情况。”</p><p>总之，安全问题不容小觑，解决安全问题是SaaS模式继续存在并发展的前提，而周全的考虑各方面的安全性则是中小企业在选择SaaS服务商时必须注意的问题。</p><h1 id="如何保证数据安全性"><a href="#如何保证数据安全性" class="headerlink" title="如何保证数据安全性"></a>如何保证数据安全性</h1><p>除了选择优秀的Saas提供商以外，我们还需要注意：<br>如何辨别具体的一种SaaS是否安全，需要把握以下几点：</p><p>1、传输协议加密<br>首先，要看SaaS产品提供使用的协议，是https://还是一般的http://，别小看这个s，这表明所有的数据在传输过程中都是加密的。如果不加密，网上可能有很多“嗅探器”软件能够轻松的获得您的数据，甚至是您的用户名和密码；实际上网上很多聊天软件帐号被盗大多数都是遭到“嗅探器”的“招”了。<br>其次，传输协议加密还要看是否全程加密，即软件的各个部分都是https://协议访问的，有部分软件只做了登录部分，这是远远不够的。比如Salesforce、XToolsCRM都是采取全程加密的。<br>2、服务器安全证书<br>服务器安全证书是用户识别服务器身份的重要标示，有些不正规的服务厂商并没有使用全球认证的服务器安全证书。用户对服务器安全证书的确认，表示服务器确实是用户访问的服务器，此时可以放心的输入用户名和密码，彻底避免“钓鱼”型网站，大多数银行卡密码泄漏都是被“钓鱼”站钓上的。<br>3、URL数据访问安全码技术<br>对于一般用户来说，复杂的URL看起来只是一串没有意义的字符而已。但是对于一些IT高手来说，这些字符串中可能隐藏着一些有关于数据访问的秘密，通过修改URL，很多黑客可以通过诸如SQL注入等方式攻入系统，获取用户数据。<br>4、数据的管理和备份机制<br>SaaS服务商的数据备份应该是完善的，用户必须了解自己服务商为您提供了什么样的数据备份机制，一旦出现重大问题，如何恢复数据等。服务商在内部管理上如何保证用户数据不被服务商所泄露，也是需要用户和服务商沟通的。<br>5、运营服务系统的安全<br>在评估SaaS产品安全度的时侯，最重要的是看公司对于服务器格局的设置，只有这样的格局才是可以信任的，包括：运营服务器与网站服务器分离。<br>服务器的专用是服务器安全最重要的保证。试想，如果一台服务器安装了SaaS系统，但同时又安装了网站系统、邮件系统、论坛系统……，他还能安全吗?在黑客角度来说，越多的系统就意味着越多的漏洞，况且大多数网站使用的网站系统、邮件系统和论坛系统都是在网上能够找到源代码的免费产品，有了源代码，黑客就可以很容易攻入。很多网站被攻入都是因为论坛系统的漏洞。<br>因此，一个优秀的软件SaaS运营商，运营服务器和网站服务器应该完全隔离的，甚至域名也应该分开。</p><p>总而言之，SaaS 最大特色是虽是软件在线使用，数据却能本地存储，保证数据安全.（就是服务和数据是分离开的，数据在网络上传输，处理，然后汇集到本地的数据库里来，数据的储存虽然是本地储存，但是由于数据的交互全都是在网络上执行和传输，所以存在相当的风险。）</p><p><strong>“云”取代“SaaS”成为新的热点</strong></p><p>———更新线———</p><h1 id="云和Saas又有什么不同"><a href="#云和Saas又有什么不同" class="headerlink" title="云和Saas又有什么不同"></a>云和Saas又有什么不同</h1><p>云计算是Grid计算和（广义的基于SOA的）SaaS技术和理念融合、提升、和发展后的产物。</p><p>SaaS不是云计算，云计算也不等于SaaS。SaaS是云计算上的应用表现，云计算是SaaS的后端基础服务保障。</p><p>云计算将弱化SaaS门槛，促进SaaS发展。云计算应用直接剥离出去，将平台留下，做平台的始终做平台，做云计算资源的人专心做好资深的调度和服务。SaaS服务商只需要关注自己的软件功能表现，无需投入大量资金到后端基础系统建设。</p><p>因为SOA就是如此设计的，面向服务的架构，但是现在又有新的技术出来替代这个SOA设计模式了，那就是微服务架构，将软件开发完全的组件化。<br>当然云计算也是可以和微服务结合的。</p><p>云计算系统建立起来之后SaaS将获得跨越式的发展，云计算将大力推动SaaS发展。</p><p>根据NIST的权威定义，云计算有SPI， 即SaaS、PaaS和IaaS三大服务模式。这是目前被业界最广泛认同的划分。PaaS和IaaS源于SaaS理念。</p><p>1.SaaS：提供给客户的服务是运营商运行在云计算基础设施上的应用程序，用户可以在各种设备上通过搜客户端界面访问，如浏览器。消费者不需要管理或控制任何云计算基础设施，包括网络、服务器、操作系统、存储等等；<br>NIST云计算划分<br>NIST云计算划分<br>2.PaaS：提供给消费者的服务是把客户采用提供的开发语言和工具（例如Java，python, .Net等）开发的或收购的应用程序部署到供应商的云计算基础设施上去。客户不需要管理或控制底层的云基础设施，包括网络、服务器、操作系统、存储等，但客户能控制部署的应用程序，也可能控制运行应用程序的托管环境配置；<br>3。IaaS: 提供给消费者的服务是对所有设施的利用，包括处理器、存储、网络和其它基本的计算资源，用户能够部署和运行任意软件，包括操作系统和应用程序。消费者不管理或控制任何云计算基础设施，但能控制操作系统的选择、储存空间、部署的应用，也有可能获得有限制的网络组件（例如，防火墙，负载均衡器等）的控制。</p><h2 id="用云计算还是Saas？"><a href="#用云计算还是Saas？" class="headerlink" title="用云计算还是Saas？"></a>用云计算还是Saas？</h2><p>主要还是看需求。</p><p>一些网络声音总结：</p><p>云计算是一种新兴的共享基础架构的方法，可以将巨大的系统池连接在一起以提供各种基于互联网的IT服务。而IaaS、PaaS、SaaS是云计算最主要的三种落地方式。其中IaaS是第一层：基础设施即服务，代表公司：阿里云、腾讯云等；PaaS是第二层：平台即服务，代表公司：数人云；SaaS是第三层：软件即服务，代表公司：用友财务软件、微软office.</p><p>云计算（cloud computing）是基于互联网的相关服务的增加、使用和交付模式，通常涉及通过互联网来提供动态易扩展且经常是虚拟化的资源。 SaaS：提供给客户的服务是运营商运行在云计算基础设施上的应用程序，用户可以在各种设备上通过客户端界面访问，如浏览器，消费者不需要管理或控制任何云计算基础设施，包括网络、服务器、操作系统、存储等等 。SaaS带来的是商业模式的转变，云计算带来的是技术的变革。云计算不仅继承了SAAS的所有优点，而且在此基础上还创造了属于自己的特点。      云计算的出现，恰好解决了SaaS发展过程中面临的一些问题，当SaaS提供商的客户快速增加到一定程度，客户所消耗的巨大资源将迫使SaaS供应商提供更多的硬件资源，但由于成本的问题，SaaS又不想花费大量资金购买硬件或带宽资源的时候，云计算无疑是个不错的选择。根据通常的概念，云计算处于SaaS的更底层，而SaaS位于云计算和最终客户之间，如果SaaS在最初开发的时候是基于云计算架构的，那么就很容易利用云计算架构来获取海量的资源，并提供给最终用户。这就一劳永逸的解决SaaS发展的瓶颈问题。</p><p>等等。来自知乎</p><h1 id="与物联网的合作"><a href="#与物联网的合作" class="headerlink" title="与物联网的合作"></a>与物联网的合作</h1><p>物联网的两种业务模式</p><ol><li>MAI（M2M Application Integration), 内部MaaS</li><li>MaaS（M2M As A Service), MMO, Multi-Tenants(多租户模型）随着物联网业务量的增加，对数据存储和计算量的需求将带来对“云计算”能力的要求：<br>云计算：从计算中心到数据中心在物联网的初级阶段，PoP即可满足需求<br>在物联网高级阶段，可能出现MVNO/MMO营运商（国外已存在多年），需要虚拟化云计算技术，SOA等技术的结合实现物联网的泛在服务： TaaS （everyTHING As A Service)。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Saas&quot;&gt;&lt;a href=&quot;#Saas&quot; class=&quot;headerlink&quot; title=&quot;Saas&quot;&gt;&lt;/a&gt;Saas&lt;/h1&gt;&lt;p&gt;SaaS是Software-as-a-Service（软件即服务）的简称，随着互联网技术的发展和应用软件的成熟， 在21世纪开始兴起的一种完全创新的软件应用模式。它与“on-demand software”（按需软件)，the application service provider(ASP，应用服务提供商)，hosted software(托管软件)所具有相似的含义。它是一种通过Internet提供软件的模式，厂商将应用软件统一部署在自己的服务器上，客户可以根据自己实际需求，通过互联网向厂商定购所需的应用软件服务，按定购的服务多少和时间长短向厂商支付费用，并通过互联网获得厂商提供的服务。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具类" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7%E7%B1%BB/"/>
    
    
      <category term="软件架构" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/"/>
    
      <category term="云计算" scheme="http://yoursite.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Saas" scheme="http://yoursite.com/tags/Saas/"/>
    
  </entry>
  
  <entry>
    <title>JVM-GC机制</title>
    <link href="http://yoursite.com/2018/03/30/JVM-GC/"/>
    <id>http://yoursite.com/2018/03/30/JVM-GC/</id>
    <published>2018-03-30T04:30:17.000Z</published>
    <updated>2018-03-30T05:39:34.473Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么需要GC"><a href="#为什么需要GC" class="headerlink" title="为什么需要GC"></a>为什么需要GC</h1><p>应用程序对资源操作，通常简单分为以下几个步骤：</p><p>1、为对应的资源分配内存</p><p>2、初始化内存</p><p>3、使用资源</p><p>4、清理资源</p><p>5、释放内存<br><a id="more"></a></p><p>应用程序对资源（内存使用）管理的方式，常见的一般有如下几种：</p><p>1、手动管理：C,C++</p><p>2、计数管理：COM</p><p>3、自动管理：.NET,Java,PHP,GO…</p><p>但是，手动管理和计数管理的复杂性很容易产生以下典型问题：</p><p>1.程序员忘记去释放内存</p><p>2.应用程序访问已经释放的内存</p><p>产生的后果很严重，常见的如内存泄露、数据内容乱码，而且大部分时候，程序的行为会变得怪异而不可预测，还有Access Violation（访问违例）等。</p><p>.NET、Java等给出的解决方案，就是通过自动垃圾回收机制GC进行内存管理。这样，问题1自然得到解决，问题2也没有存在的基础。</p><p>总结：无法自动化的内存管理方式极容易产生bug，影响系统稳定性，尤其是线上多服务器的集群环境，程序出现执行时bug必须定位到某台服务器然后dump内存再分析bug所在，极其打击开发人员编程积极性，而且源源不断的类似bug让人厌恶。因此自动化的GC机制就很重要。</p><p>GC的工作流程主要分为如下几个步骤：</p><p>1、标记(Mark)</p><p>2、计划(Plan)</p><p>3、清理(Sweep)</p><p>4、引用更新(Relocate)</p><p>5、压缩(Compact)</p><p><img src="/2018/03/30/JVM-GC/main.png" alt="logo"><br>（一）、标记</p><p>目标：找出所有引用不为0(live)的实例</p><p>方法：找到所有的GC的根结点(GC Root), 将他们放到队列里，然后依次递归地遍历所有的根结点以及引用的所有子节点和子子节点，将所有被遍历到的结点标记成live。弱引用不会被考虑在内</p><p>（二）、计划和清理</p><p>1、计划</p><p>目标：判断是否需要压缩</p><p>方法：遍历当前所有的generation上所有的标记(Live),根据特定算法作出决策</p><p>2、清理</p><p>目标：回收所有的free空间</p><p>方法：遍历当前所有的generation上所有的标记(Live or Dead),把所有处在Live实例中间的内存块加入到可用内存链表中去</p><p>（三）、引用更新和压缩</p><p>1、引用更新</p><p>目标： 将所有引用的地址进行更新</p><p>方法：计算出压缩后每个实例对应的新地址，找到所有的GC的根结点(GC Root), 将他们放到队列里，然后依次递归地遍历所有的根结点以及引用的所有子节点和子子节点，将所有被遍历到的结点中引用的地址进行更新，包括弱引用。</p><p>2、压缩</p><p>目标：减少内存碎片</p><p>方法：根据计算出来的新地址，把实例移动到相应的位置。</p><p>GC的根节点也即GC Root是个什么东西呢？</p><p>每个应用程序都包含一组根（root）。每个根都是一个存储位置，其中包含指向引用类型对象的一个指针。该指针要么引用托管堆中的一个对象，要么为null。</p><p>在应用程序中，只要某对象变得不可达，也就是没有根（root）引用该对象，这个对象就会成为垃圾回收器的目标。</p><p>用一句简洁的英文描述就是:GC roots are not objects in themselves but are instead references to objects.而且，Any object referenced by a GC root will automatically survive the next garbage collection. </p><p>.NET中可以当作GC Root的对象有如下几种：</p><p>1、全局变量</p><p>2、静态变量</p><p>3、栈上的所有局部变量(JIT)</p><p>4、栈上传入的参数变量</p><p>5、寄存器中的变量</p><p>注意，只有引用类型的变量才被认为是根，值类型的变量永远不被认为是根。只有深刻理解引用类型和值类型的内存分配和管理的不同，才能知道为什么root只能是引用类型。</p><p>顺带提一下JAVA，在Java中，可以当做GC Root的对象有以下几种：</p><p>1、虚拟机（JVM）栈中的引用的对象</p><p>2、方法区中的类静态属性引用的对象</p><p>3、方法区中的常量引用的对象（主要指声明为final的常量值）</p><p>4、本地方法栈中JNI的引用的对象</p><h1 id="GC什么时候发生"><a href="#GC什么时候发生" class="headerlink" title="GC什么时候发生"></a>GC什么时候发生</h1><p>1、当应用程序分配新的对象，GC的代的预算大小已经达到阈值，比如GC的第0代已满</p><p>2、代码主动显式调用System.GC.Collect()，System.gc()；当然这只是建议GC去处理垃圾，而不是立刻执行，主动权完全在JVM上。</p><p>3、其他特殊情况，比如，windows报告内存不足、CLR卸载AppDomain、CLR关闭，甚至某些极端情况下系统参数设置改变也可能导致GC回收</p><h1 id="GC中的代"><a href="#GC中的代" class="headerlink" title="GC中的代"></a>GC中的代</h1><p>代（Generation)引入的原因主要是为了提高性能（Performance),以避免收集整个堆（Heap）。一个基于代的垃圾回收器做出了如下几点假设：<br>在JAV中也叫新生代和老年代。<br>1、对象越新，生存期越短</p><p>2、对象越老，生存期越长</p><p>3、回收堆的一部分，速度快于回收整个堆</p><p>.NET的垃圾收集器将对象分为三代（Generation0,Generation1,Generation2）。不同的代里面的内容如下：</p><p>1、G0 小对象(Size&lt;85000Byte)</p><p>2、G1:在GC中幸存下来的G0对象</p><p>3、G2:大对象(Size&gt;=85000Byte);在GC中幸存下来的G1对象</p><p>object o = new Byte[85000]; //large object<br>Console.WriteLine(GC.GetGeneration(o)); //output is 2,not 0<br>这里必须知道，CLR要求所有的资源都从托管堆（managed heap）分配，CLR会管理两种类型的堆，小对象堆（small object heap，SOH）和大对象堆（large object heap，LOH），其中所有大于85000byte的内存分配都会在LOH上进行。一个有趣的问题是为什么是85000字节？</p><p>代收集规则：当一个代N被收集以后，在这个代里的幸存下来的对象会被标记为N+1代的对象。GC对不同代的对象执行不同的检查策略以优化性能。每个GC周期都会检查第0代对象。大约1/10的GC周期检查第0代和第1代对象。大约1/100的GC周期检查所有的对象。</p><h1 id="使用GC"><a href="#使用GC" class="headerlink" title="使用GC"></a>使用GC</h1><p>（1）除了释放不再被引用的对象，垃圾收集器还要处理堆碎块。请求分配新对象时可能不得不增大堆空间的大小，虽然可以使用的空闲空间是足够的，但是堆中没有没有连续的空间放得下新对象。可能会导致虚拟机产生不必要的”内存不足“错误。</p><p>（2）使用垃圾收集堆，有一个潜在的缺陷就是加大程序的负担，可能影响程序的性能。因为虚拟机需要追踪哪些对象被正在执行的程序引用，还要动态释放垃圾对象。</p><p>（3）程序可以调用System.gc()建议jvm去收集垃圾， 但是不能为垃圾回收机制指定某个对象是不是垃圾。即便调用了gc（），并不会马上进行垃圾回收，甚至不一定会执行垃圾回收。所有的内存分配和回收权限都在jvm，不在开发人员手里。</p><p>Example：</p><pre><code>public class RubbishRelease {    // 类的finalize方法，可以告诉垃圾回收器应该执行的操作，该方法从Object类继承而来。    // 在从堆中永久删除对象之前，垃圾回收器调用该对象的finalize方法。    public void finalize() {        System.out.println(&quot;the Object is going...&quot;);    }    public static void main(String[] args) {        for (int i = 0; i &lt; 100; i++) {            // 下面不断创建对象，但是这些对象都没有被引用            new RubbishRelease();            new RubbishRelease();            new RubbishRelease();            System.gc();        }        System.out.println(&quot;The program is over!&quot;);    }}</code></pre><p>运行结果：</p><p><img src="/2018/03/30/JVM-GC/p1.png" alt="logo"></p><p>（4）垃圾收集算法有很多，但任何垃圾收集算法都必须做两件事情。首先，它必须检测出垃圾对象。其次，它必须回收垃圾对象所使用的堆空间并还给程序。</p><h2 id="区分活动对象和垃圾的两个基本方法是引用计数和跟踪"><a href="#区分活动对象和垃圾的两个基本方法是引用计数和跟踪" class="headerlink" title="区分活动对象和垃圾的两个基本方法是引用计数和跟踪"></a>区分活动对象和垃圾的两个基本方法是引用计数和跟踪</h2><p><strong>引用计数</strong>是垃圾收集的早期策略。在这种方法中，堆中每一个对象都有一个引用计数。一个对象被创建了，并且指向该对象的引用被分配给一个变量，这个对象的引用计数被置为1。当任何其他变量被赋值为对这个对象的引用时，计数加1。当一个对象的引用超过了生存期或者被设置一个新的值时，对象的引用计数减1。任何引用计数为0的对象可以被当作垃圾收集。当一个对象被垃圾收集的时候，它引用的任何对象计数值减1。这种方法的好处是，引用计数收集器可以很快地执行，交织在程序的运行之中。这个特性对于程序不能被长时间打断的实时环境很有利。坏处就是，引用计数无法检测出循环(即两个或者更多的对象互相引用)。</p><ul><li>引用计数算法（Reference Counting） java不用<br>介绍：给对象添加一个引用计数器，每当一个地方引用它时，数据器加1；当引用失效时，计数器减1；计数器为0的即可被回收。</li></ul><p>优点：实现简单，判断效率高</p><p>缺点：很难解决对象之间的相互循环引用（objA.instance = objB; objB.instance = objA）的问题，所以java语言并没有选用引用计数法管理内存</p><p><strong>跟踪收集器</strong>追踪从根节点开始的对象引用图。给追踪过程中遇到对象以某种方式打上标记。追踪结束时，未被标记的对象就是无法触及的，从而被收集。基本的追踪算法被称作“标记并清除”，这个名字指出垃圾收集过程的两个阶段。</p><ul><li>根搜索算法（GC Root Tracing）</li></ul><p>Java和C#都是使用根搜索算法来判断对象是否存活。通过一系列的名为“GC Root”的对象作为起始点，从这些节点开始向下搜索，搜索所有走过的路径称为引用链（Reference Chain）,当一个对象到GC Root没有任何引用链相连时（用图论来说就是GC Root到这个对象不可达时），证明该对象是可以被回收的。</p><p><img src="/2018/03/30/JVM-GC/p2.png" alt="logo"></p><p>在Java中哪些对象可以成为GC Root?（在上面提过了，再写一遍）</p><p>虚拟机栈（栈帧中的本地变量表）中的引用对象<br>方法区中的类静态属性引用的对象<br>方法区中的常量引用对象<br>本地方法栈中JNI（即Native方法）的引用对象</p><p>Java虚拟机的垃圾收集器可能有对付堆碎块的策略。<strong>标记并清除收集器通常使用的两种策略是压缩和拷贝</strong>。这两种方法都是快速地移动对象来减少堆碎块。</p><p><strong>压缩收集器</strong>把活动的对象越过空闲区滑动到堆的一端，在这个过程中，堆的另一端出现一个大的连续空闲区。所有被移动的对象的引用也被更新，指向新的位置。</p><p><strong>拷贝收集器</strong>把所有的活动的对象移动到一个新的区域。在拷贝过程中，被紧挨着布置，这样可以消除原本它们在旧区域的空隙。即空闲区。一般的拷贝收集器算法被称为“停止并拷贝”。此方案中，堆被分成两个区域，任何时候都使用一个区域。对象在同一个区域中分配直到被耗尽。此时，程序执行被中止，堆被遍历，遍历时遇到活动的对象被拷贝到另个区域。当停止和拷贝过程结束时，程序恢复执行。依次往复，对于指定大小的堆来说需要两倍大小的内存，由于任何时候都只使用其中的一半，这就是该方法带来的代价。</p><ul><li>复制算法（Copying）</li></ul><p>将内存划分为大小相等的两块，每次只使用其中的一块。当这块内存用完了，就将还存活的对象复制到另一块内存上，然后把已使用过的内存空间一次清理掉。</p><p><img src="/2018/03/30/JVM-GC/p4.png" alt="logo"></p><p>优点：每次只对其中一块进行GC,不用考虑内存碎片的问题，并且实现简单，运行高效</p><p>缺点：内存缩小了一半</p><p>注：现在的商业虚拟机都是用这种收集算法回收新生代。内存分为一块较大的Eden空间和两块较小的Survior空间，每次使用Eden和其中的一块Survior.当回收时，将Eden和Survior中还存活的对象一次性拷贝到另外一块Survior空间上，最后清理Eden和刚才用过的Survior空间。</p><p>按代收集：根据对象的存活周期（一次垃圾收集为一个周期）的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用拷贝算法，只需要付出少量存活对象的拷贝成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，可以使用“标记并清除”算法。</p><p>据对象的存活周期的不同将内存划分为几块，一般就分为新生代和老年代，根据各个年代的特点采用不同的收集算法。新生代（少量存活）用复制算法，老年代（对象存活率高）“标记-清理”算法</p><p>补充：分代划分内存介绍</p><p>整个JVM内存总共划分为三代：年轻代（Young Generation）、年老代（Old Generation）、持久代（Permanent Generation）</p><p>1、年轻代：所有新生成的对象首先都放在年轻代内存中。年轻代的目标就是尽可能快速的手机掉那些生命周期短的对象。年轻代内存分为一块较大的Eden空间和两块较小的Survior空间，每次使用Eden和其中的一块Survior.当回收时，将Eden和Survior中还存活的对象一次性拷贝到另外一块Survior空间上，最后清理Eden和刚才用过的Survior空间。</p><p>2、年老代：在年轻代经历了N次GC后，仍然存活的对象，就会被放在老年代中。因此可以认为老年代存放的都是一些生命周期较长的对象。</p><p>3、持久代：基本固定不变，用于存放静态文件，例如Java类和方法。持久代对GC没有显著的影响。持久代可以通过-XX:MaxPermSize=<n>进行设置。</n></p><p>终结方法（finalize），这个在上面第3点也有提到：这个方法是垃圾收集器在释放对象前必须运行。这个可能存在的终结方法使得任何Java虚拟机的垃圾收集器要完成的工作更加复杂。因为终结方法可能“复活”了某些不再被引用的对象（本身或者其他对象）。</p><p>堆中的每一个对象都有三种状态之一：可触及的、可复活的以及不可触及的。可触及状态好理解。关于可复活状态：它在从根节点开始的追踪图中不可触及，但是又可能在垃圾收集器执行某些终结方法时触及。不仅仅是那些声明了finalize方法的对象，而是所有的对象都要经过可复活状态。而不可触及状态标志着不但对象不再被触及，而且也不可能通过任何终结方法复活。不可触及的对象不再对程序的执行产生影响，可自由地回收它们占据的内存。</p><p>一些其他算法总结：</p><ul><li>标记-清除算法（Mark-Sweep）</li></ul><p>首先标记出需要回收的对象，在标记完成后统一回收掉所有的被标记对象。</p><p><img src="/2018/03/30/JVM-GC/p3.png" alt="logo"></p><p>缺点：效率问题和空间问题（标记清除后会产生大量的不连续内存碎片，内存碎片过多可能会导致程序需要分配较大对象时找不到足够大的连续内存空间而不得不提前触发另一次垃圾回收动作）</p><ul><li>标记-整理算法（Mark-Compact）</li></ul><p>　让所有存活对象都向一端移动，然后直接清理掉端边界以外的所有内存。<br><img src="/2018/03/30/JVM-GC/p5.png" alt="logo"></p><h2 id="对象的强，软，弱，虚引用。"><a href="#对象的强，软，弱，虚引用。" class="headerlink" title="对象的强，软，弱，虚引用。"></a>对象的强，软，弱，虚引用。</h2><p>强引用：如果一个对象具有强引用，垃圾回收器绝不会回收它。当内存空间不足，JVM宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会考随意回收具有强引用的对象来解决内存不足的问题。</p><p>软引用：如果一个对象具有软引用。如果内存空间足够。垃圾回收器不会回收它。如果内存不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。</p><p>弱引用：如果一个对象具有弱引用。当垃圾回收器发现只具有弱引用对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现只具有弱引用的对象。</p><p>虚引用：虚引用不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</p><h2 id="谨慎显式调用GC"><a href="#谨慎显式调用GC" class="headerlink" title="谨慎显式调用GC"></a>谨慎显式调用GC</h2><p>GC的开销通常很大，而且它的运行具有不确定性，微软的编程规范里是强烈建议你不要显式调用GC。但你的代码中还是可以使用framework中GC的某些方法进行手动回收，前提是你必须要深刻理解GC的回收原理，否则手动调用GC在特定场景下很容易干扰到GC的正常回收甚至引入不可预知的错误。</p><p>比如如下代码：</p><pre><code>void SomeMethod(){    object o1 = new Object();    object o2 = new Object();    o1.ToString();    System.gc(); // this forces o2 into Gen1, because it&apos;s still referenced    o2.ToString();}</code></pre><p>如果没有GC.Collect()，o1和o2都将在下一次垃圾自动回收中进入Gen0，但是加上GC.Collect()，o2将被标记为Gen1，也就是0代回收没有释放o2占据的内存</p><p>还有的情况是编程不规范可能导致死锁，比如流传很广的一段代码：</p><pre><code>var instance = new MyClass();Monitor.Enter(instance);instance = null;GC.Collect();GC.WaitForPendingFinalizers();Console.WriteLine(&quot;instance is gabage collected&quot;);</code></pre><p>上述代码将会导致死锁。原因分析如下：</p><p>1、客户端主线程调用代码Monitor.Enter(instance)代码段lock住了instance实例</p><p>2、接着手动执行GC回收，主（Finalizer)线程会执行MyClass析构函数</p><p>3、在MyClass析构函数内部，使用了lock (this)代码，而主（Finalizer)线程还没有释放instance（也即这里的this），此时主线程只能等待</p><p>虽然严格来说，上述代码并不是GC的错，和多线程操作似乎也无关，而是Lock使用不正确造成的。</p><p>同时请注意，GC的某些行为在Debug和Release模式下完全不同（Jeffrey Richter在&lt;<clr via="" c#="">&gt;举过一个Timer的例子说明这个问题）。比如上述代码，在Debug模式下你可能发现它是正常运行的，而Release模式下则会死锁。</clr></p><h2 id="当GC遇到多线程"><a href="#当GC遇到多线程" class="headerlink" title="当GC遇到多线程"></a>当GC遇到多线程</h2><p>前面讨论的垃圾回收算法有一个很大的前提就是：只在一个线程运行。而在现实开发中，经常会出现多个线程同时访问托管堆的情况，或至少会有多个线程同时操作堆中的对象。一个线程引发垃圾回收时，其它线程绝对不能访问任何线程，因为垃圾回收器可能移动这些对象，更改它们的内存位置。CLR想要进行垃圾回收时，会立即挂起执行托管代码中的所有线程，正在执行非托管代码的线程不会挂起。然后，CLR检查每个线程的指令指针，判断线程指向到哪里。接着，指令指针与JIT生成的表进行比较，判断线程正在执行什么代码。</p><p>如果线程的指令指针恰好在一个表中标记好的偏移位置，就说明该线程抵达了一个安全点。线程可在安全点安全地挂起，直至垃圾回收结束。如果线程指令指针不在表中标记的偏移位置，则表明该线程不在安全点，CLR也就不会开始垃圾回收。在这种情况下，CLR就会劫持该线程。也就是说，CLR会修改该线程栈，使该线程指向一个CLR内部的一个特殊函数。然后，线程恢复执行。当前的方法执行完后，他就会执行这个特殊函数，这个特殊函数会将该线程安全地挂起。然而，线程有时长时间执行当前所在方法。所以，当线程恢复执行后，大约有250毫秒的时间尝试劫持线程。过了这个时间，CLR会再次挂起线程，并检查该线程的指令指针。如果线程已抵达一个安全点，垃圾回收就可以开始了。但是，如果线程还没有抵达一个安全点，CLR就检查是否调用了另一个方法。如果是，CLR再一次修改线程栈，以便从最近执行的一个方法返回之后劫持线程。然后，CLR恢复线程，进行下一次劫持尝试。所有线程都抵达安全点或被劫持之后，垃圾回收才能使用。垃圾回收完之后，所有线程都会恢复，应用程序继续运行，被劫持的线程返回最初调用它们的方法。</p><p>实际应用中，CLR大多数时候都是通过劫持线程来挂起线程，而不是根据JIT生成的表来判断线程是否到达了一个安全点。之所以如此，原因是JIT生成表需要大量内存，会增大工作集，进而严重影响性能。</p><p>这里再说一个真实案例。某web应用程序中大量使用Task，后在生产环境发生莫名其妙的现象，程序时灵时不灵，根据数据库日志（其实还可以根据Windows事件跟踪（ETW）、IIS日志以及dump文件），发现了Task执行过程中有不规律的未处理的异常，分析后怀疑是CLR垃圾回收导致，当然这种情况也只有在高并发条件下才会暴露出来。</p><h2 id="开发中的一些建议和意见"><a href="#开发中的一些建议和意见" class="headerlink" title="开发中的一些建议和意见"></a>开发中的一些建议和意见</h2><p>由于GC的代价很大，平时开发中注意一些良好的编程习惯有可能对GC有积极正面的影响，否则有可能产生不良效果。</p><p>1、尽量不要new很大的object，大对象（&gt;=85000Byte）直接归为G2代，GC回收算法从来不对大对象堆（LOH）进行内存压缩整理，因为在堆中下移85000字节或更大的内存块会浪费太多CPU时间</p><p>2、不要频繁的new生命周期很短object，这样频繁垃圾回收频繁压缩有可能会导致很多内存碎片，可以使用设计良好稳定运行的对象池（ObjectPool）技术来规避这种问题</p><p>3、使用更好的编程技巧，比如更好的算法、更优的数据结构、更佳的解决策略等等</p><h2 id="GC线程和Finalizer线程"><a href="#GC线程和Finalizer线程" class="headerlink" title="GC线程和Finalizer线程"></a>GC线程和Finalizer线程</h2><p>GC在一个独立的线程中运行来删除不再被引用的内存。</p><p>Finalizer则由另一个独立（高优先级CLR)线程来执行Finalizer的对象的内存回收。</p><p>对象的Finalizer被执行的时间是在对象不再被引用后的某个不确定的时间，并非和C++中一样在对象超出生命周期时立即执行析构函数。</p><p>GC把每一个需要执行Finalizer的对象放到一个队列(从终结列表移至freachable队列）中去，然后启动另一个线程而不是在GC执行的线程来执行所有这些Finalizer，GC线程继续去删除其他待回收的对象。</p><p>在下一个GC周期，这些执行完Finalizer的对象的内存才会被回收。也就是说一个实现了Finalize方法的对象必需等两次GC才能被完全释放。这也表明有Finalize的方法（Object默认的不算）的对象会在GC中自动“延长”生存周期。因为Finalize是在GC回收对象前调用，所以在类中若是写了Finalize方法，那么GC在收集这个对象时会先执行这个方法，因为优先级较高，然后跑去收集别的了，等到最后再回来收集这个对象，可以说是变相的延长了对象的寿命。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;为什么需要GC&quot;&gt;&lt;a href=&quot;#为什么需要GC&quot; class=&quot;headerlink&quot; title=&quot;为什么需要GC&quot;&gt;&lt;/a&gt;为什么需要GC&lt;/h1&gt;&lt;p&gt;应用程序对资源操作，通常简单分为以下几个步骤：&lt;/p&gt;
&lt;p&gt;1、为对应的资源分配内存&lt;/p&gt;
&lt;p&gt;2、初始化内存&lt;/p&gt;
&lt;p&gt;3、使用资源&lt;/p&gt;
&lt;p&gt;4、清理资源&lt;/p&gt;
&lt;p&gt;5、释放内存&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="底层原理" scheme="http://yoursite.com/tags/%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>java书单</title>
    <link href="http://yoursite.com/2018/03/30/java%E4%B9%A6%E5%8D%95/"/>
    <id>http://yoursite.com/2018/03/30/java书单/</id>
    <published>2018-03-29T16:00:12.000Z</published>
    <updated>2018-03-29T17:17:02.287Z</updated>
    
    <content type="html"><![CDATA[<p>多数都是在知乎和ImportNew上收集的，作为自己的知识储备。作为一个java开发工程师，若想在职业这条道路上走的更远，不仅要学会底层的知识，学习各种虚拟机，明白各种设计模式，web微服务开发框架，半个DBA，大数据方向作知识储备，hadoop和spark集群演变和原理实现，爬虫与反爬，各种最新的框架和API，跟上java版本更新，保持学习动力。</p><a id="more"></a><ul><li>《Effective Java中文版》 </li></ul><p>人手一本？谷歌出品，必属精品？</p><p>《Effective Java中文版》的作者是Joshua Bloch，这个人就很厉害了，他是谷歌的首席架构师，属于超级技术大牛级别了吧，呵呵。由于没有看过这本书，所以我不好发表评论，但是从这本书的知名度以及其作者的来头来看（多提一句，这本书也是Java之父James Gosling博士推崇的一本书），我相信这一定是一本值得一看的好书。</p><p>好的代码是每个Java程序员都应该去追求的，不是说我今天写一段好代码相比写一段烂代码对性能会有多大的提升，更多的应该是提升了代码的可读性以及可以规避许多潜在的、未知的问题，避免代码上线之后出问题而花时间去维护—-无论从时间成本、人力成本还是风险成本来说，这都是非常高的。</p><ul><li>《深入分析Java Web技术内幕》，作者许令波，淘宝工程师。</li></ul><p>这本书我用一个字概括就是：全。真的非常全，HTTP、DNS、CDN、静态化、Jetty、Tomcat、Servlet、Spring、MyBatis等等，什么都有，涉及知识面非常广，但又不像专门精讲某个知识点的书籍一样讲得非常深入，感觉这本书就是尽量去用短的篇幅讲清楚一些Java Web使用到的技术的内幕，让读者对这些知识点的技术内幕有一个理性的认识。</p><p>不过，尽管每个知识点的篇幅都不多，但是重点都基本讲到了，是一本让人真正有收获的书。如果想进一步了解这些技术的技术内幕，就要自己去买相关书籍或者自己上网查资料了，有种抛砖引玉，或者说师傅领进门、修行在个人的感觉。</p><ul><li>《大型网站技术架构 核心原理与案例分析》的作者是李智慧，原阿里巴巴技术专家</li></ul><p>Java的大多数应用都是用在Web上的，现在只要稍微大型一点的Web应用，都一定是一个分布式系统，那么一个分布式系统用到了哪些技术？一个大型网站是如何从一个小型网站成长起来的？如何保证你的网站安全？分布式系统使用到了缓存，有哪些缓存？缓存的使用有哪些值得注意的事项？</p><p>关于分布式的知识点，都在这本书里面有体现，只有你想不到，没有他写不到，而且写得非常易懂，基本属于看一两遍，再记一些笔记就知道是怎么一回事儿了。多看几遍，对分布式的理解一定会加深不少。而且里面不仅仅是分布式的知识，还非常接地气地写了如何做一个好的架构师，其实我认为这不仅仅是写给想做架构师的读者看的，就是给读者一些建议，如何更好地提出意见、如何更让别人关注你的声音、如何看到他人的优点，入木三分，让人获益匪浅。</p><ul><li>《大型网站系统与Java中间件实践》作者曾宪杰，是淘宝的技术总监，算起来应该在阿里有至少P8的级别了吧。</li></ul><p>中间件读物，如果产品开发中涉及到中间件，可以一读。</p><p>这本书的部分内容和上面一本李智慧的《大型网站技术架构 核心原理与案例分析》有所重合，像分布式系统的演化、CDN、CAP理论和BASE理论等等，这也更说明这些都是分布式系统或者说是一个大型网站重点关注的内容，当作一次再学习也不错。</p><p>本书要突出的重点是中间件三个字，中间件是分布式系统中一个非常重要的东西，其最重要的作用应该就是解耦，降低模块与模块之间的强依赖，不同的模块之间的依赖度降低，便可以各自独立地开发自己的功能，这也可以说是软件工程发展的目标和驱动力。</p><p>因此，本书有一部分的内容就是基于中间件，详细讲解了中间件与JMS的各种知识，适合对分布式系统比较熟悉并且想要往中间件方面有一定研究的读者。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;多数都是在知乎和ImportNew上收集的，作为自己的知识储备。作为一个java开发工程师，若想在职业这条道路上走的更远，不仅要学会底层的知识，学习各种虚拟机，明白各种设计模式，web微服务开发框架，半个DBA，大数据方向作知识储备，hadoop和spark集群演变和原理实现，爬虫与反爬，各种最新的框架和API，跟上java版本更新，保持学习动力。&lt;/p&gt;
    
    </summary>
    
      <category term="工具类" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7%E7%B1%BB/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="书单" scheme="http://yoursite.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
      <category term="架构" scheme="http://yoursite.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="代码" scheme="http://yoursite.com/tags/%E4%BB%A3%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>JAVA-线程重读</title>
    <link href="http://yoursite.com/2018/03/29/java-thread/"/>
    <id>http://yoursite.com/2018/03/29/java-thread/</id>
    <published>2018-03-29T08:05:14.000Z</published>
    <updated>2018-03-29T16:30:35.025Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/03/29/java-thread/main.png" alt="logo"><br><a id="more"></a></p><h1 id="传统线程及并发处理"><a href="#传统线程及并发处理" class="headerlink" title="传统线程及并发处理"></a>传统线程及并发处理</h1><p>关于同步及互斥，对象锁与类锁，wait(),notify(),notifyAll()这三种方法怎么用这是最关键的问题。</p><p>wait，notify，notifyAll 是定义在Object类的实例方法，用于控制线程状态。</p><p>三个方法都必须在synchronized 同步关键字所限定的作用域中调用，否则会报错java.lang.IllegalMonitorStateException ，意思是因为没有同步，所以线程对对象锁的状态是不确定的，不能调用这些方法。</p><p>wait 表示持有对象锁的线程A准备释放对象锁权限，释放cpu资源并进入等待。<br>notify 表示持有对象锁的线程A准备释放对象锁权限，通知jvm唤醒某个竞争该对象锁的线程X。线程A synchronized 代码作用域结束后，线程X直接获得对象锁权限，其他竞争线程继续等待(即使线程X同步完毕，释放对象锁，其他竞争线程仍然等待，直至有新的notify ,notifyAll被调用)。<br>notifyAll 表示持有对象锁的线程A准备释放对象锁权限，通知jvm唤醒所有竞争该对象锁的线程，线程A synchronized 代码作用域结束后，jvm通过算法将对象锁权限指派给某个线程X，所有被唤醒的线程不再等待。线程X synchronized 代码作用域结束后，之前所有被唤醒的线程都有可能获得该对象锁权限，这个由JVM算法决定。<br>wait有三个重载方法，同时必须捕获非运行时异常InterruptedException。</p><p>wait() 进入等待，需要notify ,notifyAll才能唤醒<br>wait(long timeout) 进入等待，经过timeout 超时后，若未被唤醒，则自动唤醒<br>wait(timeout, nanos) 进入等待，经过timeout 超时后，若未被唤醒，则自动唤醒。相对wait(long timeout) 更加精确时间。</p><p>那么对象锁又是什么？类锁又是啥？</p><p>synchronized关键字</p><p>synchronized关键字有如下两种用法：</p><p>1、 在需要同步的方法的方法签名中加入synchronized关键字。<br>在非静态方法中加入synchronized关键字是对象级别的</p><pre><code>synchronized public void getValue() {    System.out.println(&quot;getValue method thread name=&quot;            + Thread.currentThread().getName() + &quot; username=&quot; + username            + &quot; password=&quot; + password);}</code></pre><p>上面的代码修饰的synchronized是非静态方法，如果修饰的是静态方法（static）含义是完全不一样的。具体不一样在哪里，后面会详细说清楚。<br>而在静态方法中加入synchronized关键字是类级别的（静态方法是类直接调用的）<br>    synchronized static public void getValue() {<br>        System.out.println(“getValue method thread name=”</p><pre><code>            + Thread.currentThread().getName() + &quot; username=&quot; + username            + &quot; password=&quot; + password);}</code></pre><p>2、使用synchronized块对需要进行同步的代码段进行同步。<br>因为同步是对系统开销很大的一种操作，若是要执行高并发就必须要用到同步，因此为了尽量减少同步的内容要用到同步块，对方法里的一部分进行加锁。<br>同步块所锁住的参数也是对应不同的级别<br>同步代码块的synchronized (this)用法和synchronized (非this对象)的用法锁的是对象<br>同步代码块的synchronized (类.class)用法锁的是类<br>包括上面所声明的在方法前加关键字，syncronized总共有5种方法</p><pre><code>public void serviceMethod() {    try {        synchronized (this) {            System.out.println(&quot;begin time=&quot; + System.currentTimeMillis());            Thread.sleep(2000);            System.out.println(&quot;end    end=&quot; + System.currentTimeMillis());        }    } catch (InterruptedException e) {        e.printStackTrace();    }}</code></pre><p>上面的代码块是synchronized (this)用法，还有synchronized (非this对象)以及synchronized (类.class)这两种用法，这些使用方式的含义也是有根本的区别的。我们先带着这些问题继续往下看。</p><p>1.一段synchronized的代码被一个线程执行之前，他要先拿到执行这段代码的权限；（执行代码的权限就是对象锁）<br>2.在Java里边就是拿到某个同步对象的锁（一个对象只有一把锁）；<br>3.如果这个时候同步对象的锁被其他线程拿走了，他（这个线程）就只能等了（线程阻塞在锁池等待队列中）。<br>4.取到锁后，他就开始执行同步代码(被synchronized修饰的代码）；<br>5.线程执行完同步代码后马上就把锁还给同步对象，其他在锁池中等待的某个线程就可以拿到锁执行同步代码了。<br>6.这样就保证了同步代码在统一时刻只有一个线程在执行。</p><p>上面提到锁，这里先引出锁的概念。先来看看下面这些啰嗦而必不可少的文字。</p><p><strong>多线程的线程同步机制实际上是靠锁的概念来控制的。</strong></p><p>在Java程序运行时环境中，JVM需要对两类线程共享的数据进行协调：<br>1）保存在堆中的实例变量（对象信息放在堆中Heap）<br>2）保存在方法区中的类变量（类信息放在方法区中Method Area）</p><p>这两类数据是被所有线程共享的。<br>（程序不需要协调保存在Java 栈当中的数据。因为这些数据是属于拥有该栈的线程所私有的。）</p><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。</p><p>栈：在Java中，JVM中的栈记录了线程的方法调用。每个线程拥有一个栈。在某个线程的运行过程中，如果有新的方法调用，那么该线程对应的栈就会增加一个存储单元，即帧(frame)。在frame中，保存有该方法调用的参数、局部变量和返回地址。</p><p>堆是JVM中一块可自由分配给对象的区域。当我们谈论垃圾回收(garbage collection)时，我们主要回收堆(heap)的空间。<br>Java的普通对象存活在堆中。与栈不同，堆的空间不会随着方法调用结束而清空。因此，在某个方法中创建的对象，可以在方法调用结束之后，继续存在于堆中。这带来的一个问题是，如果我们不断的创建新的对象，内存空间将最终消耗殆尽。</p><p>在java虚拟机中，每个对象和类在逻辑上都是和一个监视器相关联的。<br>对于对象来说，相关联的监视器保护对象的实例变量。</p><p>对于类来说，监视器保护类的类变量。</p><p>（如果一个对象没有实例变量，或者一个类没有变量，相关联的监视器就什么也不监视。）<br>为了实现监视器的排他性监视能力，java虚拟机为每一个对象和类都关联一个锁。代表任何时候只允许一个线程拥有的特权。线程访问实例变量或者类变量不需锁。</p><p>但是如果线程获取了锁，那么在它释放这个锁之前，就没有其他线程可以获取同样数据的锁了。（锁住一个对象就是获取对象相关联的监视器）</p><p>类锁实际上用对象锁来实现。当虚拟机装载一个class文件的时候，它就会创建一个java.lang.Class类的实例。当锁住一个对象的时候，实际上锁住的是那个类的Class对象。</p><p>一个线程可以多次对同一个对象上锁。对于每一个对象，java虚拟机维护一个加锁计数器，线程每获得一次该对象，计数器就加1，每释放一次，计数器就减 1，当计数器值为0时，锁就被完全释放了。</p><p>java编程人员不需要自己动手加锁，对象锁是java虚拟机内部使用的。</p><p>在java程序中，只需要使用synchronized块或者synchronized方法就可以标志一个监视区域。当每次进入一个监视区域时，java 虚拟机都会自动锁上对象或者类。</p><blockquote><p>参考这篇文章 ：<a href="https://blog.csdn.net/u013142781/article/details/51697672" target="_blank" rel="noopener">https://blog.csdn.net/u013142781/article/details/51697672</a></p></blockquote><p>在这篇文章中你将会学到如何使用 wait、notify 和 notifyAll 来实现线程间的通信，从而解决生产者消费者问题。如果你想要更深入地学习Java中的多线程同步问题，我强烈推荐阅读Brian Goetz所著的《Java Concurrency in Practice | Java 并发实践》，不读这本书你的 Java 多线程征程就不完整哦！这是我最向Java开发者推荐的书之一。</p><p>回到wait(),notify(),notifyAll()这三个方法中来</p><p>这里用药店窗口取药的模型可以很好的解释这一点。。。</p><p>wait( )，notify( )，notifyAll( )都不属于Thread类，而是属于Object基础类，也就是每个对象都有wait( )，notify( )，notifyAll( ) 的功能，因为每个对象都有锁，锁是每个对象的基础，当然操作锁的方法也是最基础了。</p><p>当需要调用以上的方法的时候，一定要对竞争资源进行加锁，如果不加锁的话，则会报 IllegalMonitorStateException 异常</p><p>当想要调用wait( )进行线程等待时，必须要取得这个锁对象的控制权（对象监视器），一般是放到synchronized(obj)代码中。</p><p>在while循环里而不是if语句下使用wait，这样，会在线程暂停恢复后都检查wait的条件，并在条件实际上并未改变的情况下处理唤醒通知</p><p>调用obj.wait( )释放了obj的锁，否则其他线程也无法获得obj的锁，也就无法在synchronized(obj){ obj.notify() } 代码段内唤醒A。</p><p>notify( )方法只会通知等待队列中的第一个相关线程（不会通知优先级比较高的线程）</p><p>notifyAll( )通知所有等待该竞争资源的线程（也不会按照线程的优先级来执行）</p><p>假设有三个线程执行了obj.wait( )，那么obj.notifyAll( )则能全部唤醒tread1，thread2，thread3，但是要继续执行obj.wait（）的下一条语句，必须获得obj锁，因此，tread1，thread2，thread3只有一个有机会获得锁继续执行，例如tread1，其余的需要等待thread1释放obj锁之后才能继续执行。</p><p>当调用obj.notify/notifyAll后，调用线程依旧持有obj锁，因此，thread1，thread2，thread3虽被唤醒，但是仍无法获得obj锁。直到调用线程退出synchronized块，释放obj锁后，thread1，thread2，thread3中的一个才有机会获得锁继续执行。</p><p>wait()与sleep()的区别：</p><p>1.首先sleep()是Thread()类的方法，而wait()是Object类的方法，包括notify()，notifyAll()都是Object类的方法</p><p>2.sleep()方法是休眠，阻塞线程的同时仍然会持有锁，也就是说它休眠期间其他线程仍然无法获得锁，同时sleep()休眠时自动醒           的；而调用wait()方法时，则自动释放锁，也就是其他线程可以获得锁，而且wait()是无法自动醒的，只有通过notify()或 notifyAll()         才行。如果不设置wait自动醒的时间，那么wait将会一直等下去直至notify来唤醒，进入锁池去获取对象锁。</p><p>notify()与notifyAll()的区别</p><p>notify()一次只能激活一个对这个对象进行wait()的线程，当多个线程都对此对象wait()时，是随机挑一个notify()，而notifyAll()是一次      性激活所以对此对象进行wait()的线程。</p><p>接下来说说利用wait()和notify()来实现<strong>生产者和消费者并发问题</strong>：</p><p>显然要保证生产者和消费者并发运行不出乱，主要要解决：当生产者线程的缓存区为满的时候，就应该调用wait()来停止生产者继续生产，而当生产者满的缓冲区被消费者消费掉一块时，则应该调用notify()唤醒生产者，通知他可以继续生产；同样，对于消费者，当消费者线程的缓存区为空的时候，就应该调用wait()停掉消费者线程继续消费，而当生产者又生产了一个时就应该调用notify()来唤醒消费者线程通知他可以继续消费了。</p><p>当然我们必须在wait()和notify()的时候锁住我们所要操作的对象,这里即缓存区，下面是一个使用wait()的notify()的规范代码模板：<br>synchronized的背景下和那个被多线程共享的对象上调用</p><pre><code>synchronized (sharedObject) { //锁住操作对象，锁的是对象      while (condition) { //当某个条件下      sharedObject.wait(); //进入wait，这个shareObject就是所有线程共享的对象，在生产者-消费者模型里面这个对象就是缓冲区队列     }       // 做了什么事，就可以激活，注意在while循环外     shareObject.notify();  } </code></pre><p>wait, notify 和 notifyAll，这些在多线程中被经常用到的保留关键字，在实际开发的时候很多时候却并没有被大家重视。本文对这些关键字的使用进行了描述。</p><p>在 Java 中可以用 wait、notify 和 notifyAll 来实现线程间的通信。。举个例子，如果你的Java程序中有两个线程——即生产者和消费者，那么生产者可以通知消费者，让消费者开始消耗数据，因为队列缓冲区中有内容待消费（不为空）。相应的，消费者可以通知生产者可以开始生成更多的数据，因为当它消耗掉某些数据后缓冲区不再为满。</p><p>我们可以利用wait()来让一个线程在某些条件下暂停运行。例如，在生产者消费者模型中，生产者线程在缓冲区为满的时候，消费者在缓冲区为空的时候，都应该暂停运行。如果某些线程在等待某些条件触发，那当那些条件为真时，你可以用 notify 和 notifyAll 来通知那些等待中的线程重新开始运行。不同之处在于，notify 仅仅通知一个线程，并且我们不知道哪个线程会收到通知，然而 notifyAll 会通知所有等待中的线程。换言之，如果只有一个线程在等待一个信号灯，notify和notifyAll都会通知到这个线程。但如果多个线程在等待这个信号灯，那么notify只会通知到其中一个，而其它线程并不会收到任何通知，而notifyAll会唤醒所有等待中的线程。</p><p>如何使用Wait</p><p>尽管关于wait和notify的概念很基础，它们也都是Object类的函数，但用它们来写代码却并不简单。如果你在面试中让应聘者来手写代码，用wait和notify解决生产者消费者问题，我几乎可以肯定他们中的大多数都会无所适从或者犯下一些错误，例如在错误的地方使用 synchronized 关键词，没有对正确的对象使用wait，或者没有遵循规范的代码方法。说实话，这个问题对于不常使用它们的程序员来说确实令人感觉比较头疼。</p><p>第一个问题就是，我们怎么在代码里使用wait()呢？因为wait()并不是Thread类下的函数，我们并不能使用Thread.call()。事实上很多Java程序员都喜欢这么写，因为它们习惯了使用Thread.sleep()，所以他们会试图使用wait() 来达成相同的目的，但很快他们就会发现这并不能顺利解决问题。<strong>正确的方法是对在多线程间共享的那个Object来使用wait。在生产者消费者问题中，这个共享的Object就是那个缓冲区队列。</strong></p><p>第二个问题是，既然我们应该在synchronized的函数或是对象里调用wait，那哪个对象应该被synchronized呢？答案是，那个你希望上锁的对象就应该被synchronized，即那个在多个线程间被共享的对象。在生产者消费者问题中，应该被synchronized的就是那个缓冲区队列。（我觉得这里是英文原文有问题……本来那个句末就不应该是问号不然不太通……）</p><p>永远在循环（loop）里调用 wait 和 notify，不是在 If 语句，常用的是while循环</p><p>现在你知道wait应该永远在被synchronized的背景下和那个被多线程共享的对象上调用，下一个一定要记住的问题就是，你应该永远在while循环，而不是if语句中调用wait。因为线程是在某些条件下等待的——在我们的例子里，即“如果缓冲区队列是满的话，那么生产者线程应该等待”，你可能直觉就会写一个if语句。但if语句存在一些微妙的小问题，导致即使条件没被满足，你的线程你也有可能被错误地唤醒。所以如果你不在线程被唤醒后再次使用while循环检查唤醒条件是否被满足，你的程序就有可能会出错——例如在缓冲区为满的时候生产者继续生成数据，或者缓冲区为空的时候消费者开始消耗数据。所以记住，永远在while循环而不是if语句中使用wait！我会推荐阅读《Effective Java》，这是关于如何正确使用wait和notify的最好的参考资料。</p><p>就像我之前说的一样，在while循环里使用wait的目的，是在线程被唤醒的前后都持续检查条件是否被满足。如果条件并未改变，wait被调用之前notify的唤醒通知就来了，那么这个线程并不能保证被唤醒，有可能会导致死锁问题。</p><p>下面我们提供一个使用wait和notify的范例程序。在这个程序里，我们使用了上文所述的一些代码规范。</p><p>我们有两个线程，分别名为PRODUCER（生产者）和CONSUMER（消费者），他们分别继承了了Producer和Consumer类，而Producer和Consumer都继承了Thread类。Producer和Consumer想要实现的代码逻辑都在run()函数内。</p><p>Main线程开始了生产者和消费者线程，并声明了一个LinkedList作为缓冲区队列（在Java中，LinkedList实现了队列的接口）。生产者在无限循环中持续往LinkedList里插入随机整数直到LinkedList满。我们在while(queue.size == maxSize)循环语句中检查这个条件。请注意到我们在做这个检查条件之前已经在队列对象上使用了synchronized关键词，因而其它线程不能在我们检查条件时改变这个队列。如果队列满了，那么PRODUCER线程会在CONSUMER线程消耗掉队列里的任意一个整数，并用notify来通知PRODUCER线程之前持续等待。在我们的例子中，wait和notify都是使用在同一个共享对象上的。</p><p>这一套程序如果能在面试中写出来那就给劲了，其实逻辑并不难，只需要按照套路来即可。</p><pre><code>import java.util.LinkedList; import java.util.Queue; import java.util.Random; /**     * Simple Java program to demonstrate How to use wait, notify and notifyAll()     * method in Java by solving producer consumer problem.    *     * @author Javin Paul     */public class ProducerConsumerInJava {     public static void main(String args[]) {         System.out.println(&quot;How to use wait and notify method in Java&quot;);         System.out.println(&quot;Solving Producer Consumper Problem&quot;);         Queue&lt;Integer&gt; buffer = new LinkedList&lt;&gt;();         int maxSize = 10;         Thread producer = new Producer(buffer, maxSize, &quot;PRODUCER&quot;);         Thread consumer = new Consumer(buffer, maxSize, &quot;CONSUMER&quot;);         producer.start(); consumer.start(); }     }     /**         * Producer Thread will keep producing values for Consumer         * to consumer. It will use wait() method when Queue is full         * and use notify() method to send notification to Consumer         * Thread.         *         * @author WINDOWS 8         *         */    class Producer extends Thread     { private Queue&lt;Integer&gt; queue;         private int maxSize;         public Producer(Queue&lt;Integer&gt; queue, int maxSize, String name){             super(name); this.queue = queue; this.maxSize = maxSize;         }         @Override public void run()         {             while (true)                 {                     synchronized (queue) {                         while (queue.size() == maxSize) { //queue满了，那么Producer就要被wait                            try {                                 System.out .println(&quot;Queue is full, &quot; + &quot;Producer thread waiting for &quot; + &quot;consumer to take something from queue&quot;);                                 queue.wait();                             } catch (Exception ex) {                                 ex.printStackTrace(); }                             }                             Random random = new Random();                             int i = random.nextInt();                             System.out.println(&quot;Producing value : &quot; + i);                             queue.add(i);                             queue.notifyAll();                         }                     }                 }             }     /**         * Consumer Thread will consumer values form shared queue.         * It will also use wait() method to wait if queue is         * empty. It will also use notify method to send         * notification to producer thread after consuming values         * from queue.         *         * @author WINDOWS 8         *         */    class Consumer extends Thread {         private Queue&lt;Integer&gt; queue;         private int maxSize;         public Consumer(Queue&lt;Integer&gt; queue, int maxSize, String name){             super(name);             this.queue = queue;             this.maxSize = maxSize;         }         @Override public void run() {             while (true) {                 synchronized (queue) {                     while (queue.isEmpty()) {   //queue空的时候，Consumer要被wait                        System.out.println(&quot;Queue is empty,&quot; + &quot;Consumer thread is waiting&quot; + &quot; for producer thread to put something in queue&quot;);                         try {                             queue.wait();                         } catch (Exception ex) {                             ex.printStackTrace();                         }                     }                     System.out.println(&quot;Consuming value : &quot; + queue.remove());                     queue.notifyAll();                 }             }         }     }</code></pre><blockquote><p>参考资料：<a href="http://www.importnew.com/16453.html" target="_blank" rel="noopener">http://www.importnew.com/16453.html</a><br>如何在 Java 中正确使用 wait, notify 和 notifyAll – 以生产者消费者模型为例 </p></blockquote><p>为了更好地理解这个程序，我建议你在debug模式里跑这个程序。一旦你在debug模式下启动程序，它会停止在PRODUCER或者CONSUMER线程上，取决于哪个线程占据了CPU。因为两个线程都有wait()的条件，它们一定会停止，然后你就可以跑这个程序然后看发生什么了（很有可能它就会输出我们以上展示的内容）。你也可以使用Eclipse里的Step into和Step over按钮来更好地理解多线程间发生的事情。</p><ol><li><p>你可以使用wait和notify函数来实现线程间通信。你可以用它们来实现多线程（&gt;3）之间的通信。</p></li><li><p>永远在synchronized的函数或对象里使用wait、notify和notifyAll，不然Java虚拟机会生成 IllegalMonitorStateException。</p></li><li><p>永远在while循环里而不是if语句下使用wait。这样，循环会在线程睡眠前后都检查wait的条件，并在条件实际上并未改变的情况下处理唤醒通知。</p></li><li><p>永远在多线程间共享的对象（在生产者消费者模型里即缓冲区队列）上使用wait。</p></li><li><p>基于前文提及的理由，更倾向用 notifyAll()，而不是 notify()。</p></li></ol><h1 id="来点新东西吧"><a href="#来点新东西吧" class="headerlink" title="来点新东西吧"></a>来点新东西吧</h1><p>在JAVA1.8或1.9中，并发工具的改变</p><p>Java 8 中 Concurrent package的改变</p><p>java.util.concurrent中新的类和接口</p><p>增加了两个新接口和4个新类:</p><p>接口 CompletableFuture.AsynchronousCompletionTask<br>接口 CompletionStage<br>类 CompletableFuture<br>类 ConcurrentHashMap.KeySetView<br>类 CountedCompleter<br>类 CompletionException<br>java.util.concurrent.ConcurrentHashMap的新方法</p><p>集合框架 在Java 8中做了修订，基于 stream 和 lambda表达式 添加了很多聚合方法。因此 ConcurrentHashMap 也引入了30几个新方法，包括各种 foreach 方法(forEach , forEachKey , forEachValue , 和 forEachEntry )、搜索方法( search , searchKeys , searchValues , 和 searchEntries )和reduction方法( reduce ,reduceToDouble , reduceToLong 等)。</p><p>也添加了一些其它方法，比如 mappingCount 和 newKeySet 。并且当前版本的 ConcurrentHashMap 的更适合做cache，因为增加了当键值不存在的时候的检查方法。</p><p>java.util.concurrent.atomic中的新类</p><p>为了并发计算count、sum， 新引入了 DoubleAccumulator , DoubleAdder , LongAccumulator , LongAdder 类，比Atomic提供更高的吞吐率。</p><p>java.util.concurrent.ForkJoinPool的新方法</p><p>静态的 commonPool() 新加入，可以为ForkJoinTask提供通用池。</p><p>两个方法 getCommonPoolParallelism() 和 commonPool() 提供不同的配置。</p><p>新类 java.util.concurrent.locks.StampedLock</p><p>新类 StampedLock 提供三种模式(写，读，乐观读)，用来提高性能。</p><p>Java 9 中 Concurrent package的改变</p><p>主要是 JEP 266: More Concurrency Updates , 包括publish-subscribe, CompletableFuture 接口的加强等。</p><p>支持Reactive Streams publish-subscribe框架，四个接口 Processor 、 Publisher 、 Subscriber 、 Subscription ，容器类 java.util.concurrent.Flow 、java.util.concurrent.SubmissionPublisher<br>CompletableFuture类加强，支持delays, timeout, subclassing 以及其它方法<br>调优以及修改javadoc</p><blockquote><p>可以参考：<a href="http://www.importnew.com/28319.html" target="_blank" rel="noopener">http://www.importnew.com/28319.html</a></p></blockquote><h1 id="普及JAVA内存管理机制"><a href="#普及JAVA内存管理机制" class="headerlink" title="普及JAVA内存管理机制"></a>普及JAVA内存管理机制</h1><p>因为线程调度跟内存分配有着很大的关系。</p><p>转载内容，觉得这篇是我看过讲得最好的：<a href="https://blog.csdn.net/u013142781/article/details/50830754" target="_blank" rel="noopener">https://blog.csdn.net/u013142781/article/details/50830754</a></p><p><img src="/2018/03/29/java-thread/p1.png" alt="logo"></p><p>请注意上图的这个：</p><p><img src="/2018/03/29/java-thread/p2.png" alt="logo"></p><p>我们再来复习下进程与线程吧：</p><p>进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。</p><p>线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。</p><p>似乎现在更好理解了一些：</p><p>方法区和堆是分配给进程的，也就是所有线程共享的。</p><p>而栈和程序计数器，则是分配给每个独立线程的，是运行过程中必不可少的资源。</p><p>下面我们逐个看下栈、堆、方法区和程序计数器。</p><p>1、方法区（Method Area）</p><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。</p><p>2、程序计数器（Program Counter Register）</p><p>程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><p>下面重点解下Java内存管理中的栈和堆。</p><p>3、栈（Stacks）</p><p>在Java中，JVM中的栈记录了线程的方法调用。每个线程拥有一个栈。在某个线程的运行过程中，如果有新的方法调用，那么该线程对应的栈就会增加一个存储单元，即帧(frame)。在frame中，保存有该方法调用的参数、局部变量和返回地址。</p><p>Java的参数和局部变量只能是基本类型的变量(比如int)，或者对象的引用(reference)。因此，在栈中，只保存有基本类型的变量和对象引用。引用所指向的对象保存在堆中。(引用可能为Null值，即不指向任何对象)。</p><p>当被调用方法运行结束时，该方法对应的帧将被删除，参数和局部变量所占据的空间也随之释放。线程回到原方法，继续执行。当所有的栈都清空时，程序也随之运行结束。</p><p>本地方法栈与虚拟机栈的区别：</p><p>本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p><p>4、堆（Heap）</p><p>堆是JVM中一块可自由分配给对象的区域。当我们谈论垃圾回收(garbage collection)时，我们主要回收堆(heap)的空间。</p><p>Java的普通对象存活在堆中。与栈不同，堆的空间不会随着方法调用结束而清空。因此，在某个方法中创建的对象，可以在方法调用结束之后，继续存在于堆中。这带来的一个问题是，如果我们不断的创建新的对象，内存空间将最终消耗殆尽。</p><p>垃圾回收（Garbage Collection，GC）</p><p>垃圾回收(garbage collection，简称GC)可以自动清空堆中不再使用的对象。垃圾回收机制最早出现于1959年，被用于解决Lisp语言中的问题。垃圾回收是Java的一大特征。并不是所有的语言都有垃圾回收功能。比如在C/C++中，并没有垃圾回收的机制。程序员需要手动释放堆中的内存。</p><p>由于不需要手动释放内存，程序员在编程中也可以减少犯错的机会。利用垃圾回收，程序员可以避免一些指针和内存泄露相关的bug(这一类bug通常很隐蔽)。但另一方面，垃圾回收需要耗费更多的计算时间。垃圾回收实际上是将原本属于程序员的责任转移给计算机。使用垃圾回收的程序需要更长的运行时间。</p><p>在Java中，对象的是通过引用使用的(把对象相像成致命的毒物，引用就像是用于提取毒物的镊子)。如果不再有引用指向对象，那么我们就再也无从调用或者处理该对象。这样的对象将不可到达(unreachable)。垃圾回收用于释放不可到达对象所占据的内存。这是垃圾回收的基本原则。</p><p>早期的垃圾回收采用引用计数(reference counting)的机制。每个对象包含一个计数器。当有新的指向该对象的引用时，计数器加1。当引用移除时，计数器减1。当计数器为0时，认为该对象可以进行垃圾回收。</p><p>然而，一个可能的问题是，如果有两个对象循环引用(cyclic reference)，比如两个对象互相引用，而且此时没有其它(指向A或者指向B)的引用，我们实际上根本无法通过引用到达这两个对象。</p><p>因此，我们以栈和static数据为根(root)，从根出发，跟随所有的引用，就可以找到所有的可到达对象。也就是说，一个可到达对象，一定被根引用，或者被其他可到达对象引用。</p><p>5、再整理下</p><p>通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用内存中的栈空间；</p><p>而通过new关键字和构造器创建的对象放在堆空间；</p><p>程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在静态区中；</p><p>栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，理论上整个内存没有被其他进程使用的空间甚至硬盘上的虚拟内存都可以被当成堆空间来使用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/03/29/java-thread/main.png&quot; alt=&quot;logo&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="java类库" scheme="http://yoursite.com/tags/java%E7%B1%BB%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>JAVA I/O流详解</title>
    <link href="http://yoursite.com/2018/03/28/java-io/"/>
    <id>http://yoursite.com/2018/03/28/java-io/</id>
    <published>2018-03-28T04:55:49.000Z</published>
    <updated>2018-03-29T08:11:30.079Z</updated>
    
    <content type="html"><![CDATA[<h1 id="流的概念和作用"><a href="#流的概念和作用" class="headerlink" title="流的概念和作用"></a>流的概念和作用</h1><p>流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。<br>集合框架相当于数据结构，那么IO框架就相当于数据传输。<br><a id="more"></a></p><h1 id="IO流的分类"><a href="#IO流的分类" class="headerlink" title="IO流的分类"></a>IO流的分类</h1><p>根据处理数据类型的不同分为：字符流和字节流<br>根据数据流向不同分为：输入流和输出流</p><p>对输入流只能进行读操作，对输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。</p><p>java.io包中提供了大量的流类，其中所有的输入流都是InputStream抽象类或抽象类Reader的子类，而所有的输出流都是outputStream抽象类或Writer的抽象类，所有继承自InputStream与outputStream的流都是字节流，而所有继承自Reader与Writer的流都是字符流。</p><p>要知道所有的高级流都需要借助低级流来操作文件，字节流属于低级流，而字符流属于改进只针对于文字的高级流，但是字符流中也有方法可以直接操作文件不需要借助低级流，但是一般的高级流操作都需要以低级流作为基础。</p><p><img src="/2018/03/28/java-io/p1.png" alt="logo"> </p><p>其中IO流具体的类或接口有哪些；<br>File                  文件类<br>RandomAccessFile      随机存取文件类<br>InputStream           字节输入流<br>OutputStream          字节输出流<br>Reader                字符输入流<br>writer                字符输出流</p><p>首先先从文件的路径解释下：</p><p>文件和目录路径名的抽象表示形式。</p><p>用户界面和操作系统使用与系统相关的路径名字符串 来命名文件和目录。此类呈现分层路径名的一个抽象的、与系统无关的视图。抽象路径名 有两个组件：</p><p>一个可选的与系统有关的前缀 字符串，比如盘符，”/“ 表示 UNIX 中的根目录，”\\“ 表示 Microsoft Windows UNC 路径名。<br>零个或更多字符串名称 的序列。<br>抽象路径名中的第一个名称是目录名，对于 Microsoft Windows UNC 路径名则是主机名。抽象路径名中第一个名称之后的每个名称表示一个目录；最后一个名称既可以表示目录，也可以表示文件。空 抽象路径名没有前缀和名称序列。<br>路径名字符串与抽象路径名之间的转换与系统有关。将抽象路径名转换为路径名字符串时，每个名称与下一个名称之间用一个默认分隔符 隔开。默认名称分隔符由系统属性 file.separator 定义，可通过此类的公共静态字段 separator 和 separatorChar 使其可用。将路径名字符串转换为抽象路径名时，可以使用默认名称分隔符或者底层系统支持的任何其他名称分隔符来分隔其中的名称。</p><p>无论是抽象路径名还是路径名字符串，都可以是绝对 路径名或相对 路径名。绝对路径名是完整的路径名，不需要任何其他信息就可以定位它所表示的文件。相反，相对路径名必须使用取自其他路径名的信息进行解释。默认情况下，java.io 包中的类总是根据当前用户目录来解析相对路径名。此目录由系统属性 user.dir 指定，通常是 Java 虚拟机的调用目录。</p><p>调用此类的 getParent() 方法可以获取抽象路径名的父 路径名，它由路径名前缀以及路径名名称序列中的每个名称（最后一个除外）组成。对于任何具有绝对抽象路径名的 File 对象，如果其绝对抽象路径名以某个目录的绝对路径名开头，那么该目录的绝对路径名是该 File 对象的祖先。例如，抽象路径名 “/usr” 表示的目录是路径名 “/usr/local/bin” 所表示目录的一个祖先。</p><p>在处理 UNIX 平台的根目录，以及 Microsoft Windows 平台的盘符、根目录和 UNC 路径名时，将用到前缀这一概念。如下所示：</p><p>对于 UNIX 平台，绝对路径名的前缀始终是 “/“。相对路径名没有前缀。表示根目录的绝对路径名的前缀为 “/“ 且名称序列为空。<br>对于 Microsoft Windows 平台，包含盘符的路径名前缀由驱动器号和一个 “:” 组成。如果路径名是绝对路径名，还可能后跟 “\“。UNC 路径名的前缀是 “\\“；主机名和共享名是名称序列中的前两个名称。没有指定驱动器的相对路径名没有前缀。<br>此类的实例可能表示（也可能不表示）实际文件系统对象，如文件或目录。如果它表示这种对象，那么该对象驻留在一个分区 中。分区是文件系统特定于操作系统的存储分区。一个存储设备（例如，物理磁盘驱动器、闪存、CD-ROM）可以包含多个分区。对象（如果有）将驻留在此路径名（绝对形式）某个祖先指定的分区上。</p><p>文件系统可以实现对实际文件系统对象上的某些操作（比如，读、写、执行）进行限制。这些限制统称为访问权限。文件系统可以对一个对象设置多个访问权限。例如，一个设置可能适用于对象的所有者，另一个设置则可能适用于所有其他用户。对象上的访问权限可能导致此类的某些方法执行失败。</p><h2 id="File"><a href="#File" class="headerlink" title="File"></a>File</h2><p>最基础的文件流，java 处理文件的类 File,java提供了十分详细的文件处理方法<br>主要是创建文件，（不存在则新建，存在则替代），主要是封装了所有文件的属性和元数据。</p><p>File类是对文件系统中文件以及文件夹进行封装的对象，可以通过对象的思想来操作文件和文件夹。 File类保存文件或目录的各种元数据信息，包括文件名、文件长度、最后修改时间、是否可读、获取当前文件的路径名，判断指定文件是否存在、获得当前目录中的文件列表，创建、删除文件和目录等方法。</p><p>File 类的实例是不可变的；也就是说，一旦创建，File 对象表示的抽象路径名将永不改变。 </p><p>这个类中的方法有常用几个：</p><p>boolean    mkdir()<br>创建此抽象路径名指定的目录。<br>boolean    mkdirs()<br>创建此抽象路径名指定的目录，包括所有必需但不存在的父目录。<br>boolean    renameTo(File dest)<br>重新命名此抽象路径名表示的文件。<br>long    length()<br>返回由此抽象路径名表示的文件的长度。<br>boolean    isDirectory()<br>测试此抽象路径名表示的文件是否是一个目录。<br>boolean    isFile()<br>测试此抽象路径名表示的文件是否是一个标准文件。<br>boolean    isHidden()<br>测试此抽象路径名指定的文件是否是一个隐藏文件。<br>long    lastModified()<br>返回此抽象路径名表示的文件最后一次被修改的时间。<br>String    getName()<br>返回由此抽象路径名表示的文件或目录的名称。<br>String    getParent()<br>返回此抽象路径名父目录的路径名字符串；如果此路径名没有指定父目录，则返回 null。<br>File    getParentFile()<br>返回此抽象路径名父目录的抽象路径名；如果此路径名没有指定父目录，则返回 null。<br>boolean    delete()<br>删除此抽象路径名表示的文件或目录。<br>boolean    exists()<br>测试此抽象路径名表示的文件或目录是否存在。<br>boolean    createNewFile()<br>当且仅当不存在具有此抽象路径名指定名称的文件时，不可分地创建一个新的空文件。</p><pre><code>public class FileExample{      public static void main(String[] args) {          createFile();      }    /**    * 文件处理示例    */    public static void createFile() {       File f=new File(&quot;E:/电脑桌面/jar/files/create.txt&quot;);          try{              f.createNewFile();  //当且仅当不存在具有此抽象路径名指定名称的文件时，不可分地创建一个新的空文件。              System.out.println(&quot;该分区大小&quot;+f.getTotalSpace()/(1024*1024*1024)+&quot;G&quot;); //返回由此抽象路径名表示的文件或目录的名称。              f.mkdirs();  //创建此抽象路径名指定的目录，包括所有必需但不存在的父目录。  //            f.delete(); //  删除此抽象路径名表示的文件或目录             System.out.println(&quot;文件名  &quot;+f.getName());  //  返回由此抽象路径名表示的文件或目录的名称。             System.out.println(&quot;文件父目录字符串 &quot;+f.getParent());// 返回此抽象路径名父目录的路径名字符串；如果此路径名没有指定父目录，则返回 null。          }catch (Exception e) {              e.printStackTrace();          }    }  }  </code></pre><h2 id="RamdomAccessFile"><a href="#RamdomAccessFile" class="headerlink" title="RamdomAccessFile"></a>RamdomAccessFile</h2><p>该对象并不是流体系中的一员，其封装了字节流，同时还封装了一个缓冲区（字符数组），通过内部的指针来操作字符数组中的数据。 该对象特点：</p><p>该对象只能操作文件，所以构造函数接收两种类型的参数：a.字符串文件路径；b.File对象。<br>该对象既可以对文件进行读操作，也能进行写操作，在进行对象实例化时可指定操作模式(r,rw)，r是只读不能写，rw是读写模式。<br>注意：该对象在实例化时，如果要操作的文件不存在，会自动创建；如果文件存在，写数据未指定位置，会从头开始写，即覆盖原有的内容。 可以用于多线程下载或多个线程同时写数据到文件。</p><p>此类的实例支持对随机访问文件的读取和写入。随机访问文件的行为类似存储在文件系统中的一个大型 byte 数组。存在指向该隐含数组的光标或索引，称为文件指针；输入操作从文件指针开始读取字节，并随着对字节的读取而前移此文件指针。如果随机访问文件以读取/写入模式创建，则输出操作也可用；输出操作从文件指针开始写入字节，并随着对字节的写入而前移此文件指针。写入隐含数组的当前末尾之后的输出操作导致该数组扩展。该文件指针可以通过 getFilePointer 方法读取，并通过 seek 方法设置。</p><p>通常，如果此类中的所有读取例程在读取所需数量的字节之前已到达文件末尾，则抛出 EOFException（是一种 IOException）。如果由于某些原因无法读取任何字节，而不是在读取所需数量的字节之前已到达文件末尾，则抛出 IOException，而不是 EOFException。需要特别指出的是，如果流已被关闭，则可能抛出 IOException。</p><p>常用方法：</p><p>void    close()<br>关闭此随机访问文件流并释放与该流关联的所有系统资源。<br>long    getFilePointer()<br>返回此文件中的当前偏移量。<br>long    length()<br>返回此文件的长度。<br>int    read()<br>从此文件中读取一个数据字节。<br>int    read(byte[] b)<br>将最多 b.length 个数据字节从此文件读入 byte 数组。<br>int    read(byte[] b, int off, int len)<br>将最多 len 个数据字节从此文件读入 byte 数组。<br>void    seek(long pos)<br>设置到此文件开头测量到的文件指针偏移量，在该位置发生下一个读取或写入操作。<br>void    setLength(long newLength)<br>设置此文件的长度。<br>void    write(int b)<br>向此文件写入指定的字节。</p><h2 id="InputStream"><a href="#InputStream" class="headerlink" title="InputStream"></a>InputStream</h2><p>InputStream 是所有的输入字节流的父类，它是一个抽象类。<br>ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。PipedInputStream 是从与其它线程共用的管道中读取数据，与Piped 相关的知识后续单独介绍。<br>ObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）。</p><p>常用方法：<br>void    close()<br>关闭此输入流并释放与该流关联的所有系统资源。<br>void    mark(int readlimit)<br>在此输入流中标记当前的位置。<br>boolean    markSupported()<br>测试此输入流是否支持 mark 和 reset 方法。<br>abstract  int    read()<br>从输入流中读取数据的下一个字节。<br>int    read(byte[] b)<br>从输入流中读取一定数量的字节，并将其存储在缓冲区数组 b 中。<br>int    read(byte[] b, int off, int len)<br>将输入流中最多 len 个数据字节读入 byte 数组。<br>void    reset()<br>将此流重新定位到最后一次对此输入流调用 mark 方法时的位置。<br>long    skip(long n)<br>跳过和丢弃此输入流中数据的 n 个字节。</p><p>有哪些常用的子类：FileInputStream，ObjectInputStream等</p><p>分别实例其用法，方便快速回顾：</p><p>1.FileInputStream（文件字节输入流）</p><pre><code>package io;  import java.io.File;  import java.io.FileInputStream;  import java.io.IOException;  import java.io.InputStream;  public class ByteInput {      public static void main(String[] args) throws IOException {          //1、定义要使用的文件          File file = new File(&quot;F:&quot; + File.separator + &quot;byteInput.txt&quot;);          file.createNewFile();   //文件存在的时候不会执行，不存在的时候会执行          //2、定义字节输入流指定为文件输入流          InputStream input = new FileInputStream(file);          byte[] b = new byte[(int) file.length()]; // file.length()获取文件的长度返回long类型          int len = input.read(b);          input.close();          //3、验证输入结果          System.out.println(&quot;文件的内容长度为 : &quot; + len);          System.out.println(&quot;文件的内容为: &quot; + new String(b));      }  } </code></pre><p>2.ObjectInputStream（对象输入流）本例需要对象实现序列化接口，实现对文件内容的逐个对象处理<br>先定义一个实现Serializable接口的pojo实体类</p><pre><code>package io;    import java.io.Serializable;    public class StudentInfo implements Serializable{      private String stuno;      private String name;      private Integer age;      public StudentInfo() {      }      public StudentInfo(String stuno, String name, Integer age) {          super();          this.stuno = stuno;          this.name = name;          this.age = age;      }    //省略所有get/set方法 } package io;  import java.io.File;  import java.io.FileInputStream;  import java.io.IOException;  import java.io.ObjectInputStream;  public class ObjectInput {      public static void main(String[] args) throws IOException, ClassNotFoundException {          File file=new File(&quot;F:&quot;+File.separator+&quot;object.txt&quot;);          file.createNewFile();          ObjectInputStream in=new ObjectInputStream(new FileInputStream(file));          StudentInfo stu=(StudentInfo)in.readObject();          in.close();          System.out.println(stu);      }  }  </code></pre><h2 id="OutputStream"><a href="#OutputStream" class="headerlink" title="OutputStream"></a>OutputStream</h2><p>OutputStream 是所有的输出字节流的父类，它是一个抽象类。<br>ByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。PipedOutputStream 是向与其它线程共用的管道中写入数据，<br>ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。</p><p>常用方法：<br>void    close()<br>关闭此输出流并释放与此流有关的所有系统资源。<br>void    flush()<br>刷新此输出流并强制写出所有缓冲的输出字节。<br>void    write(byte[] b)<br>将 b.length 个字节从指定的 byte 数组写入此输出流。<br>void    write(byte[] b, int off, int len)<br>将指定 byte 数组中从偏移量 off 开始的 len 个字节写入此输出流。<br>abstract  void    write(int b)<br>将指定的字节写入此输出流。</p><p>有哪些常用的子类呢：FileOutputStream，ObjectOutputStream等</p><p>分别实例其用法，方便快速回顾：</p><p>1.FileOutputStream（文件字节输出流）实现对文件内容的逐字节处理</p><pre><code>package io;  import java.io.File;  import java.io.FileOutputStream;  import java.io.IOException;  import java.io.OutputStream;  public class ByteOutput {      public static void main(String[] args) throws IOException{          //1、获取要操作的文件          File file=new File(&quot;F:&quot;+File.separator+&quot;byteOutput.txt&quot;);          file.createNewFile();          //2、写入指定的内容          String str=&quot;I Like Java!&quot;;          OutputStream output=new FileOutputStream(file);          output.write(str.getBytes(), 0, str.length()); //写入字符串          output.close();      }  }  </code></pre><p>2.ObjectOutputStream（对象输出流）本例需要对象实现序列化接口，实现对文件内容的逐个对象处理<br>pojo对象同5例中的StudentInfo对象，测试类如下（用到ObjectInputStream的那个对象）</p><pre><code>package io;  import java.io.File;  import java.io.FileOutputStream;  import java.io.IOException;  import java.io.ObjectOutputStream;  public class ObjectOutput {      public static void main(String[] args) throws IOException {          File file=new File(&quot;F:&quot;+File.separator+&quot;object.txt&quot;);          file.createNewFile();          StudentInfo student=new StudentInfo(&quot;10001&quot;,&quot;zhangsan&quot;,20);          ObjectOutputStream output=new ObjectOutputStream(new FileOutputStream(file));          output.writeObject(student);          output.close();      }  } </code></pre><h2 id="Reader"><a href="#Reader" class="headerlink" title="Reader"></a>Reader</h2><p>Reader 是所有的输入字符流的父类，它是一个抽象类。<br>CharReader、StringReader 是两种基本的介质流，它们分别将Char 数组、String中读取数据。PipedReader 是从与其它线程共用的管道中读取数据。<br>BufferedReader 很明显就是一个装饰器，它和其子类负责装饰其它Reader 对象。<br>FilterReader 是所有自定义具体装饰流的父类，其子类PushbackReader 对Reader 对象进行装饰，会增加一个行号。<br>InputStreamReader 是一个连接字节流和字符流的桥梁，它将字节流转变为字符流。FileReader 可以说是一个达到此功能、常用的工具类，在其源代码中明显使用了将FileInputStream 转变为Reader 的方法。我们可以从这个类中得到一定的技巧。Reader 中各个类的用途和使用方法基本和InputStream 中的类使用一致。后面会有Reader 与InputStream 的对应关系。</p><p>常用子类：FileReader，BufferedReader等</p><p>分别实例其用法，方便快速回顾：</p><p>1.FileReader（文件字符输入流）实现对文件内容的逐字符处理</p><pre><code>package io;  import java.io.File;  import java.io.FileReader;  import java.io.IOException;  import java.io.Reader;  public class CharInput {      public static void main(String[] args) throws IOException {          //1、指定要操作的文件          File file=new File(&quot;F:&quot;+File.separator+&quot;charInput.txt&quot;);          file.createNewFile();          //2、指定字节输入流          Reader reader=new FileReader(file);          char[] c=new char[(int)file.length()];          int len=reader.read(c);          reader.close();          //3、验证          System.out.println(&quot;字符流读取文件的长度为: &quot;+len);          System.out.println(&quot;字符流读取文件的内容: &quot;+new String(c));      }  } </code></pre><p>2.BufferedReader（缓存文件输入流）实现对文件内容的逐行处理</p><pre><code>package io;  import java.io.BufferedReader;  import java.io.File;  import java.io.FileReader;  import java.io.IOException;  public class BufferReaderDemo {      public static void main(String[] args) throws IOException {          //指定文件          File file = new File(&quot;F:&quot; + File.separator + &quot;buffered.txt&quot;);          file.createNewFile();          //定义需要验证的变量          int i = 1;          String str;          StringBuffer buffer = new StringBuffer();          //定义逐行读入的流          BufferedReader br = new BufferedReader(new FileReader(file));          while ((str = br.readLine()) != null) {    //逐行读取并验证              System.out.println(&quot;读取的行数: &quot; + (i));              buffer.append(str);              System.out.println(&quot;第&quot; + (i++) + &quot;行的内容为: &quot; + str);          }          br.close();          //打印最终结果          System.out.println(&quot;\n文件中的全部内容为: &quot;+buffer.toString());      }  }  </code></pre><h2 id="Writer"><a href="#Writer" class="headerlink" title="Writer"></a>Writer</h2><p>Writer 是所有的输出字符流的父类，它是一个抽象类。<br>CharArrayWriter、StringWriter 是两种基本的介质流，它们分别向Char 数组、String 中写入数据。PipedWriter 是向与其它线程共用的管道中写入数据，<br>BufferedWriter 是一个装饰器为Writer 提供缓冲功能。<br>PrintWriter 和PrintStream 极其类似，功能和使用也非常相似。<br>OutputStreamWriter 是OutputStream 到Writer 转换的桥梁，它的子类FileWriter 其实就是一个实现此功能的具体类（具体可以研究一SourceCode）。功能和使用和OutputStream 极其类似，后面会有它们的对应图。</p><p>常用子类：FileWriter，BufferedWriter等</p><p>分别实例其用法，方便快速回顾：</p><p>1.FileWriter（文件字符输出流）实现对文件内容的逐字符处理</p><pre><code>package io;  import java.io.File;  import java.io.FileWriter;  import java.io.IOException;  import java.io.Writer;  public class CharOutput {      public static void main(String[] args) throws IOException {          File file = new File(&quot;F:&quot; + File.separator + &quot;charOutput.txt&quot;);          file.createNewFile();          Writer writer = new FileWriter(file);          writer.write(&quot;I Love Basketball！&quot;, 0, 18);          writer.close();      }  } </code></pre><p>2.BufferedWriter（缓存文件输出流）实现对文件内容的逐行处理</p><pre><code>package io;  import java.io.BufferedWriter;  import java.io.File;  import java.io.FileWriter;  import java.io.IOException;  import java.io.Writer;  public class BufferedWriterDemo {      public static void main(String[] args) throws IOException{          //指定文件          File file=new File(&quot;F:&quot;+File.separator+&quot;buffered.txt&quot;);          file.createNewFile();          //指定          Writer bw=new BufferedWriter(new FileWriter(file,true));          bw.write(&quot;\r\n&quot;);          bw.write(&quot;XiaoHuangRen like banana!&quot;);          bw.write(&quot;\r\n&quot;);          bw.write(&quot;XiaoHuangRen like bana!&quot;);          bw.close();      }  }</code></pre><p>资料参考：<a href="https://blog.csdn.net/qq_34207422/article/details/76149026" target="_blank" rel="noopener">https://blog.csdn.net/qq_34207422/article/details/76149026</a>  </p><h2 id="那么如何使用这4种类型呢？"><a href="#那么如何使用这4种类型呢？" class="headerlink" title="那么如何使用这4种类型呢？"></a>那么如何使用这4种类型呢？</h2><p>关于字节流和字符流到底用哪个来处理实际的业务需求呢</p><p>字符流的由来： 因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流读取时，去查了指定的码表。 字节流和字符流的区别：</p><p>读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。<br>处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。</p><p>结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。字节流可以处理全部数据类型的传输，但是字符流就只适合读写纯文字的数据。</p><h2 id="关于缓冲流（常用）"><a href="#关于缓冲流（常用）" class="headerlink" title="关于缓冲流（常用）"></a>关于缓冲流（常用）</h2><p>java.io提供了四种数据传输的缓冲技术</p><p>BufferedInputStream<br>BufferedOutputStream<br>BufferedReader<br>BufferedWriter </p><p>其常用的构造方法：</p><p>BufferedReader（Reader in）<br>BufferedReader（Reader in,int sz）//sz为自定义缓冲区大小<br>BufferedWriter （Writer out）<br>BufferedWriter （ Writer out, int sz）<br>BufferedInputStream（InputStream in）<br>BufferedInputStream（ InputStream in,int size）<br>BufferedOutputStream （OutputStream out）<br>BufferedOutputStream （OutputStream out,int size）<br>前四个四字符流，后四个是字节流</p><p>带缓冲的字节输入流：上面我们知道文件字节输入流的读取时，是直接同字节流中读取的。由于字节流是与硬件（存储介质）进行的读取，所以速度较慢。而CPU需要使用数据时通过read()、read(byte[])读取数据时就要受到硬件IO的慢速度限制。我们又知道，CPU与内存发生的读写速度比硬件IO快10倍不止，所以优化读写的思路就有了：在内存中建立缓存区，先把存储介质中的字节读取到缓存区中。CPU需要数据时直接从缓冲区读就行了，缓冲区要足够大，在被读完后又触发fill()函数自动从存储介质的文件字节内容中读取字节存储到缓冲区数组。</p><p>BufferedInputStream 内部有一个缓冲区，默认大小为8M，每次调用read方法的时候，它首先尝试从缓冲区里读取数据，若读取失败（缓冲区无可读数据），则选择从物理数据源 （譬如文件）读取新数据（这里会尝试尽可能读取多的字节）放入到缓冲区中，最后再将缓冲区中的内容返回给用户.由于从缓冲区里读取数据远比直接从存储介质读取速度快，所以BufferedInputStream的效率很高。</p><h2 id="转换流（常用）"><a href="#转换流（常用）" class="headerlink" title="转换流（常用）"></a>转换流（常用）</h2><p>字符流与字节流转换</p><p>转换流的特点：</p><p>其是字符流和字节流之间的桥梁<br>可对读取到的字节数据经过指定编码转换成字符<br>可对读取到的字符数据经过指定编码转换成字节<br>何时使用转换流？</p><p>当字节和字符之间有转换动作时；<br>流操作的数据需要编码或解码时。<br>具体的对象体现：</p><p>InputStreamReader:字节到字符的桥梁<br>OutputStreamWriter:字符到字节的桥梁<br>这两个流对象是字符体系中的成员，它们有转换作用，本身又是字符流，所以在构造的时候需要传入字节流对象进来。</p><blockquote><p>InputStreamReader演示：</p></blockquote><p>InputStreamReader是字节流通向字符流的桥梁，它使用指定的charset读取字节并将其解码为字符。它拥有一个InputStream类型的变量，并继承了Reader，使用了对象的适配器模式</p><p>根据InputStream的实例创建InputStreamReader的方法有4种：</p><p>InputStreamReader(InputStream in);<br>//根据默认字符集创建<br>InputStreamReader(InputStream in, Charset cs);<br>//使用给定字符集创建<br>InputStreamReader(InputStream in, CharsetDecoder dec);<br>//使用给定字符集解码器创建<br>InputStreamReader(InputStream in, String charsetName);<br>//使用指定字符集创建 </p><p>后面的3个构造函数都指定了一个字符集，最后一个是最简单的，可以直接指定字符集的名称来创建，例如GB2312等。</p><p>每次调用InputStreamReader中的一个read()方法都会导致从底层输入流读取一个或多个字节。要启用从字节到字符的有效转换，可以提前从底层流读取更多的字节，使其超过满足当前读取操作所需的字节。共有3个可用的read()方法：</p><p>int read();<br>//读取单个字符<br>int read(char[] cbuf, int offset, int length);<br>//将字符读入数组中的某一部分<br>boolean ready();<br>//判断此流是否已经准备好用于读取 </p><p>InputStreamReader继承自Reader，因此该类的实例可以被各种输入字符流包装。为了达到最高效率，可以考虑在BufferedReader内包装InputStreamReader。我们首先创建了一个FileInputStream类的实例，然后转换为InputStreamReader对象is，最后使用BufferedReader进行包装。这样就可以将字节流转换为带缓冲功能的字符流。</p><pre><code>public class TestInputStreamReader {      public static void main(String[] args) {          try {  // 创建输入流  FileInputStream fis = new FileInputStream(&quot;D:/demo/test.txt&quot;);  InputStreamReader is = new InputStreamReader(fis);  BufferedReader bis = new BufferedReader(is);  // 从输入流读取数据  while (bis.ready()) {      int c = bis.read();      System.out.print((char)c);  }  // 关闭输入流  bis.close();  is.close();  fis.close();          } catch (IOException e) {          }      }  } </code></pre><blockquote><p>OutputStreamWriter演示：</p></blockquote><p>OutputStreamWriter是字符流通向字节流的桥梁，可使用指定的charset将要写入流中的字符编码成字节。因此，它拥有一个OutputStream类型的变量，并继承了Writer，使用了对象的适配器模式</p><p>根据OutputStream的实例创建OutputStreamWriter的方法有4种：</p><p>OutputStreamReader(OutputStream out);<br>//根据默认字符集创建<br>OutputStreamReader(OutputStream out, Charset cs);<br>//使用给定字符集创建<br>OutputStreamReader(OutputStream out, CharsetDecoder dec);<br>//使用给定字符集解码器创建<br>OutputStreamReader(OutputStream out, Stroutg charsetName);<br>//使用指定字符集创建 </p><p>后面的3个构造函数都制定了一个字符集，最后一个是最简单的，可以直接指定字符集的名称来创建，例如GB2312等。</p><p>每次调用write()方法都会导致在给定字符（或字符集）上调用编码转换器。在写入底层输出流之前，得到的这些字节将在缓冲区中累积。可以指定此缓冲区的大小，不过，默认的缓冲区对多数用途来说已足够大。注意，传递给write()方法的字符没有缓冲。共有3个可用的write()方法：</p><p>void write(char[] cbuf, int off, int len);//写入字符数组的某一部分<br>void write(int c);//写入单个字符<br>void write(String str, int off, int len);//写入字符串的某一部分<br>OutputStreamWriter继承自Writer，因此该类的实例可以被各种输出字符流包装。为了达到最高效率，可以考虑在BufferedWriter内包装OutputStreamWriter。我们首先创建了一个FileOutputStream类的实例，然后转换为OutputStreamReader对象os，最后使用BufferedWriter进行包装。这样就可以将字节流转换为带缓冲功能的字符流。</p><pre><code>public class TestOutputStreamWriter {      public static void main(String[] args) {          try {          // 创建输出流              FileOutputStream fos = new FileOutputStream(&quot;D:/demo/test.txt&quot;);              OutputStreamWriter os = new OutputStreamWriter(fos);              BufferedWriter bos = new BufferedWriter(os);              // 写入数组数据              char[] buf = new char[3];              buf[0] = &apos;a&apos;;              buf[1] = &apos;b&apos;;              buf[2] = &apos;中&apos;;              bos.write(buf);              // 关闭输出流              bos.close();              os.close();              fos.close();          } catch (IOException e) {          }      }  } </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;流的概念和作用&quot;&gt;&lt;a href=&quot;#流的概念和作用&quot; class=&quot;headerlink&quot; title=&quot;流的概念和作用&quot;&gt;&lt;/a&gt;流的概念和作用&lt;/h1&gt;&lt;p&gt;流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。&lt;br&gt;集合框架相当于数据结构，那么IO框架就相当于数据传输。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="java类库" scheme="http://yoursite.com/tags/java%E7%B1%BB%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>创业之路--企业技术支持</title>
    <link href="http://yoursite.com/2018/03/26/%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E6%90%AD%E5%BB%BA01/"/>
    <id>http://yoursite.com/2018/03/26/从无到有搭建01/</id>
    <published>2018-03-25T16:20:30.000Z</published>
    <updated>2018-03-26T12:48:23.629Z</updated>
    
    <content type="html"><![CDATA[<p>中小型互联网企业的技术支持到底有哪些（数据来源于网络爬虫及本人总结），项目包括多终端接口（WEB,IOS,Android），接入微服务架构，服务端软件层面主要语言为JAVA开发，考虑架构稳定性以及可拓展性，灵活性，硬件层面包括完整的企业级应用主机服务器，服务器商业托管服务，数据管理中心，云计算，大数据，OA系统，ERP软件，数据库储存方案等等，企业对接服务包括400电话，企业邮箱，企业公众号等等，关于这些技术我都会做总结。我尽量用最简洁的语言来做阐述，帮助我的合作伙伴解决技术疑惑。</p><a id="more"></a><h1 id="硬件支持"><a href="#硬件支持" class="headerlink" title="硬件支持"></a>硬件支持</h1><p>上面一堆屁话，让人云里雾里心生恐惧，为什么一个小型项目需要这么多的技术支持！！先解释一下，一个多终端设备并且以网络用户作为企业交互人群的项目公司都可以成为互联网企业，首先做一个略微完整的项目需要的最小项目软硬件架构是什么，首先先做下分析：</p><p>首先根据你的产品预估你的访问量和人数大概在什么位置：</p><p>网站统计中的PV(访问量)：UV(独立访客)：IP(独立IP)的定义与区别（名词解释）</p><p>PV(访问量)：即Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次。</p><p>UV(独立访客)：即Unique Visitor,访问您网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次。</p><p>IP(独立IP)：即Internet Protocol,指独立IP数。00:00-24:00内相同IP地址之被计算一次。</p><p>QPS：每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。</p><p>要想分析自己的产品大概需求是什么样的，可以看“日PV”这个数据，就是说网站在各种终端中累计点击多少次，打个比喻，你的产品拥有完整的各终端接口服务，一天有100个手机用户点击你的软件，每人点击数量不一致，可预估取中间值也就是20次刷新页面（考虑到现在的异步更新功能以减少页面刷新提高用户体验的技术，取20次），而手机系统分为IOS和Android，结果乘2,100<em>20</em>2=4000次页面访问，web端属于PC端页面服务，考虑到现在移动端使用频繁于WEB端，所以取1000点击，那么你的软件日PV就是5000的访问量级。</p><p>目前互联网中如果某个系统的日pv在千万级别以上,他就可能是一个高并发的系统，中小型的互联网企业的日均PV在10w~300w这个级别。<br>我们的项目系统不只有用户在访问，还有企业的访问量，开发的访问量等等，以这个区间作为系统搭建的参数。</p><p>下面贴出我去年做的软硬件系统拓展的流程图：可以看下互联网硬件为了应付日益增多的用户应该如何做好技术选型的</p><p><img src="/2018/03/26/从无到有搭建01/p1.jpg" alt="logo"><br><img src="/2018/03/26/从无到有搭建01/p2.jpg" alt="logo"><br><img src="/2018/03/26/从无到有搭建01/p3.jpg" alt="logo"><br><img src="/2018/03/26/从无到有搭建01/p4.jpg" alt="logo"></p><p>如果我们按照中小型互联网的PV参数作为技术选型标准的话，该从什么方面去选择硬件。</p><h2 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h2><p>首先一个企业的核心是一台交互处理所有信息的主机，也就是服务器，所有移动端接口都对接到这里，数据库也对接到这里，网站也对接这里，处理数据，储存数据，展示数据，页面访问控制，业务需要和所有的功能实现都要在一个服务器里实现。</p><p>这里有4个方案：（除了物理服务器是真实可见的，其他三个都升虚拟的）</p><p>1.云服务器<br>2.物理服务器（前期转中期）<br>3.VPS<br>4.虚拟主机</p><h3 id="区别和解释"><a href="#区别和解释" class="headerlink" title="区别和解释"></a>区别和解释</h3><ul><li>什么是云服务器</li></ul><p>云服务器是在一组集群服务器上虚拟出多个类似独立服务器的部分，集群中每个服务器上都有云服务器的一个镜像，从而大大提高了虚拟服务器的安全稳定性，除非所有的集群内服务器全部出现问题，云服务器才会无法访问。</p><p>云主机是一群服务器做镜像然后分割的虚拟机，价格适中，但是很稳定，基本没有宕机。<br>宕机，指操作系统无法从一个严重系统错误中恢复过来，或系统硬件层面出问题，以致系统长时间无响应，而不得不重新启动计算机的现象。它属于电脑运作的一种正常现象，任何电脑都会出现这种情况。</p><p>云服务器就是将多个传统的服务器连接在一起，形成一个大的超级计算机，这个超级计算机里有多个类似独立服务器的部分，可以根据用户的需求提供给予其使用。由于可以按需付费，并且可以弹性伸缩，所以成本低廉，是现在很多企业倾向于选择的一种方式。而且现在做云服务器提供商越来越多，这也是市场的需求和选择，最著名的肯定就是BAT，还有一些专业型的比如小鸟云计算这一类公司，所以个人认为，这应该是一种时代趋势吧。</p><ul><li>什么是物理服务器 （也叫独立服务器）</li></ul><p>独立服务器是客户拥有整台服务器的软硬件资源，可以自行配置或通过主机管理工具实现web、mail、ftp等多种网络服务。由于整台服务器只有一个用户使用，在服务器硬件资源以及带宽资源上都得到了极大的保障。  优势/适用范围：稳定安全、独享带宽、可绑定多个IP地址、可单独设置防火墙，可扩展硬件等。适用于中高端用户。</p><p>服务器就是一台主机，你自己买自己用，没有专业维护人员的话要托管，费用比较高。一般公司不推荐。涉及到专业服务器硬件托管公司。</p><ul><li>什么是VPS主机</li></ul><p>VPS主机是在强大的 互联网服务器集群上，利用虚拟化及集中存储等技术构建的主机租用产品，每个VPS主机都是一台虚拟独立的服务器，具有完整的服务器功能，并且比同配置的物理服务器更灵活，具有更安全更稳定的性能。</p><p>具有完整的物理服务器 功能，同时具有高性价比、高安全性、高灵活性。适用于业务快速成长的的商业运营公司/需要各地分支机构共享内部资源筹建信息化服务平台的大中型行业门户网站。  vps是一台主机虚拟出来的，和人家合用一台机器，见不到物理的机器，但是可以挂自己的网站，价格便宜但是不稳定。</p><ul><li>什么是虚拟主机</li></ul><p>所谓虚拟主机，也叫“网站空间”，即把一台运行在互联网上的服务器划分成多个具有一定大小的硬盘空间，每个空间都给予相应的FTP权限和Web访问权限，以用于网站发布。</p><p>低成本高利用率，是中小企业提高企业竞争力的重要手段。适用于个人网站或中小型网站。</p><h3 id="如何选型"><a href="#如何选型" class="headerlink" title="如何选型"></a>如何选型</h3><p>既然初创产业没那么多资金，物理服务器当然不需要考虑，而且没有这么多当量的数据量，购买或租用独立服务器的成本在创业预算范围之外。<br>另外虚拟主机的局限性也有，只适合做门户网站，对于响应的业务处理没有两者优。</p><p>考虑云服务或者VPS。。。<br>1.如果同台服务器的1台VPS被攻击，将直接影响其他的所有VPS无法运行。同等情况下云服务器只影响被攻击云计算服务器，其他同服务器的云计算服务器不受影响。  </p><p>2.云计算服务器运行前会预先将硬件内存分配好,如果服务器上有4G内存绝不能分配出5G的内存出来,而VPS服务器自生拥有4G内存可以虚拟100G的内存，并分配给100个独立操作系统。  </p><p>3.在同等性能的前提下,降低你在数据中心消费成本的一半以上  </p><p>4.vps对运营商来说成本较低,因为1台服务器可以虚拟上数十个VPS主机,云计算服务器对运营商来说相当于独立服务器出租。成本略低于独立服务器出租,需要有相当实力的运营商才能提供。  目前提供云服务的国外亚马逊比较牛叉，国内的话有腾讯云、阿里云、盛大云等大企业。</p><p>产品选型建议选择云计算服务器，均衡性能</p><h3 id="关于市面上的云计算产品的报价"><a href="#关于市面上的云计算产品的报价" class="headerlink" title="关于市面上的云计算产品的报价"></a>关于市面上的云计算产品的报价</h3><p>阿里云计算各项产品（报价均衡在每个月200到500不等）</p><p><img src="/2018/03/26/从无到有搭建01/p5.png" alt="logo"><br><img src="/2018/03/26/从无到有搭建01/p6.png" alt="logo"><br><img src="/2018/03/26/从无到有搭建01/p7.png" alt="logo"></p><p>还有阿里的全套产品线</p><p><img src="/2018/03/26/从无到有搭建01/p8.png" alt="logo"></p><p>腾讯云计算各项产品</p><h1 id="移动端开发"><a href="#移动端开发" class="headerlink" title="移动端开发"></a>移动端开发</h1><p>一个项目计划若想要加入移动端数据支持，那么需要多少成本来筹建到完成产品呢？</p><p>就大部分的App项目而言，开发一个app标配的项目需要开发一套后台管理系统（CMS） + 安卓客户端 + iOS客户端，大多数项目的开发成本在12 - 25万不等，具体需要根据App的功能复杂度，质量要求，开发哪些平台等因素来确定具体的价格。另外，个人兼职，团队或工作室，或者专业的app开发公司，报价的成本会有比较大的差距，开发出来的质量也会有比较大的差距，一般报价的成本：个人 &lt; 团队 &lt; 公司，而质量也是跟价格成正比：个人兼职 &lt; 团队 &lt; 公司。</p><p>接下来分析如果一个初创公司若想实现移动端，无非就是两种开发手段</p><p>1.自建团队<br>2.外包项目</p><p>首先初创公司想要召集一批人来做移动端实现，那么需要哪些人</p><ol><li><p>开发一个App项目的人员配置比较复杂。开发网站只需要一个端的开发人员即可以了，而开发app需要三个端的开发人员，通常也相对同样功能的网站开发成本的三倍工作量。App项目的人员基本配置有：产品经理，项目经理一名，UI设计师一名，后台开发工程师两名，安卓开发工程师两名，iOS开发工程师两名，测试人员两名。这里是对专业的App开发公司而言，一般个人或团队可能一个人会身兼多职，所以开发出来的项目质量也不能得到保证； </p></li><li><p>App开发的人工成本相对网站要高一些。通常一个有一两年安卓或iOS开发经验的开发人员，人工成本就要达到1万左右（由于当前的市场环境对开发人才的需求较高，使得技术开发的人工成本也较高）。通常一个app项目的基本人工成本达到2-5来万，再加上员工福利，设备，场地，人员管理，营销成本和商务沟通成本，基本上一个app项目的基本投入成本就要去到8-10万左右。这个暂且不计人员的空档期，招聘的成本，项目的风险等因素。这是对于一个已经具备成熟App开发团队的公司所需要付出的价位，对于完全没有App开发团队和相关开发经验的公司而言，这个成本估计至少需要翻一倍，开发周期要拉很长，基本才能达到前者类似的效果。</p></li></ol><p>开发一个app需要多少钱，需要综合评估app的功能需求，质量要求，需要开发哪些平台端，以此评估出需要投入多少的人工设计和开发量，即可基本测算出app的开发成本。</p><p>自建团队的优点：</p><ol><li><p>沟通高效：由于都在同个办公室，沟通方便，随时可以面对面交流，可以快速讨论出解决方案并执行；</p></li><li><p>需求把握更准确：选择开发公司合作，通常开发成本都需要在合同签订前就确定下来，所以设计通常也被预算所限定，一旦设计确定下来后，就不允许频繁地变更需求，除非只是一是很小的调整，或者额外追加开发的成本。而自建团队的话，通常开发过程中有一些不理想或不合理的设计，调整和优化的灵活度会高很多，可以更纯粹地考虑产品项目本身的合理性和用户体验性，弱化开发成本的控制；</p></li><li><p>可以充分配合实际的项目运营：比如后期项目需要做活动，或者临时有一些额外的需求需要增加，自建团队可以在极短的时间内讨论出方案并执行，而跟第三方技术团队合作，则前期需要沟通需求，评估开发成本，还有安排开发时间等等工作，通常需要好多个来回的沟通，导致浪费了好多时间；</p></li></ol><p>自建团队的缺点：</p><ol><li><p>开发周期长：创业前期需要组建团队，磨合，且人手经常不够用，导致开发周期会被拉长；</p></li><li><p>需要解决人员招聘，人员流动性等问题，特别是非技术基因的团队，很难招聘或留住技术人才；</p></li><li><p>需要分散很多的精力放在技术上面，特别是在项目启动前期，需要投入非常多的精力开发系统；</p></li><li><p>项目管理成本高：由于开发一套系统，在不同的时间点，需要不同的专业技能，且任务有前后置的衔接关系，这会导致经常在某个专业领域缺人，无法执行后续的开发，或者执行完某个任务后，就会空出一些人手暂时用不上，导致管理成本非常高。相对而言，技术公司由于同时会进行多个项目，所以可以最大程度减少人力成本的浪费，减少管理成本；</p></li></ol><p>那么回归到我们这个问题本身：应该采用自建团队开发，还是找技术公司合作的方案呢？我觉得这个问题的核心关键点需要看创始团队的人员配置。</p><p>1.偏技术型团队：通常创始团队大都比较擅长技术，并且拥有丰富的开发经验。那么，自建技术团队开发是最省成本，也是最合适的方案。这里面存在两种情况：一是技术方面只有一个核心骨干，或只擅长其中的某一部分（如整套系统涵盖app开发和网站开发，但技术创始人只擅长web端的开发），这时会导致系统前期的开发周期会拉长，可以采取招聘其他的技术人才，或众包的方式；二是技术团队很强大，基本可以开发整套系统，那么基本可以自行搞定开发完整套系统。但通常技术类型的团队前期很容易犯的一个错误是，把大多数的时间投入在技术和系统的开发方面，却忽视了设计，营销推广等领域的积累和学习，导致一些项目开发出来后，却没能运营推广起来，最终导致项目半路夭折（比如我们团队初期就犯过这样一个错误）。</p><p>2.偏运营型团队：这种类型的团队比较擅长运营及营销推广这个领域，但不具备技术的基因。通常运营团队的创业项目核心在运营层面，技术相对次要，所以建议还是找一家技术开发公司合作，把技术相关的开发工作交给技术合作公司搞定，团队专攻运营领域。有些创业者由于预算有限，技术公司的开发成本又太高，可能会觉得自己搭建一个技术团队会更省成本，更高效。我觉得这是一个错误的认知。首先，运营型的团队通常不在技术这个圈子，认识的技术人才非常有限，加上创业前期招聘人才本身就比较困难，通常需要很长的时间才能招聘到相应的技术人才，可能还不是优秀的技术人才；其次，开发一个IT系统需要的专业人才比较多，比如开发一个app，按照专业开发公司的配置，需要产品经理，UI设计师，安卓，iOS，后台开发工程师，测试工程师等专业人才，创业型公司不可能会有这么豪华的人才配置，通常都是一人当几个人用，而这样导致的结果是开发出来的系统质量一般；再者，通常系统的启动初期，对技术人才是一个比较大的缺口，但一旦系统开发完成，后期只需要较少量的运维工作，并不需要这么多的技术人员，所以可能会导致人员和成本浪费，这也是一块比较大的成本损失。当然，如果找技术公司合作的话，能否找到靠谱的合作团队，是这个项目成败的一个非常关键的要点。这方面建议多一点慎重的考量，不要为了节省小额的开发成本，而忽视了对项目质量，以及技术团队的要求。</p><p>3.综合配置型团队：相对而言，这种类型的创业团队人员配置较为合理，既有技术人才，也有运营和营销专长，各个领域也有相应的人才资源和圈子，所以项目的成活率也会高很多。这种类型的团队可以考虑找技术公司合作，也可以自己招聘技术人才自行开发，两个方案的可行性都比较高。从长远的角度看，如果要真正做好一个项目，最终还是需要建立自己的技术团队，这样才能减少沟通的成本，严格把控好每一个需求点，并打磨好项目的每一个细节。但这个可能需要基于团队有技术基因，或者资金允许的情况下。这需要一个过程，毕竟技术团队的招聘，搭建，磨合，开发流程的优化等等都需要有一段路要走，特别是对于没有技术基因的团队，可能是一个需要用很多精力和时间投入才能去克服的一个问题。除了创始团队的配置外，项目的类型（比如是偏技术型项目，像今日头条，还是偏运营的项目，像大多数自建的电商平台），也是其中的一个重点考量因素。创业者需要根据自身的团队的优劣势，人员的配置情况，项目类型，以及对于各个领域的人才需求情况做一个整体的评估，再决定是否需要自建一支技术团队。术业有专攻，创业初期，务必要把最核心的资源和力量，放在刀刃上面，并懂得借助第三方的资源和力量。因为第三方的资源和技术本身就是为了顺应创业市场的要求而出现的。</p><p>市场经验：（我们的项目属于综合配置型团队）</p><p>案例一：（有技术合伙人，对软件开发流程有详细认知，可维护，可选择外包后拿回源码自己改，后期迭代升级组建团队）</p><p>我公司这边也有不少项目是外包出去的。在初期，为了快速实现，把项目外包出去是一个好的选择，毕竟自建团队需要投入的资金和时间，还有管理都是很庞大的。但是慢慢的，问题也随之而来。对于外包项目，外包公司使用的是最简单最快实现的框架去做，对于各种情况诸如兼容性（此问题手机端尤其突出）、扩展性、软件访问效率等问题都不会考虑，他们只负责交付给你一个能用的产品，而不是可用的产品，并帮你维护一段时间，合约便结束了。而且在维护期内，如果你有什么其他需求或改动，都是需要另收费的，很麻烦，有时候即使你反应了问题，也不会立刻帮你修改，而是要等。更为麻烦的是，在之后，你还是需要找人去接手这个项目，拿回源码自己去做修改自己去做开发。所以，我的建议是，自建团队是最好的。我们公司的初期项目，为了市场推广的需要，先是找了外包公司做了webview，我们自己开发网页端嵌入，这样就能进行快速迭代，满足市场需要，所以页面的变动都是在网页端，而不需要经过外包公司和上架审核。然后在这段时间内自建ios和android团队，拿回外包的源码自己维护，以及自己开发真正的app，因为经过市场反馈，我们app需要的功能也很明确，之前的接口都是可用，所以开发可以很快.然后替换掉webview..</p><p>案例二：（纯外包，没有技术合伙人，闹得很尴尬）</p><p>客户A：传统招聘行业，老板准备投几百万嫁装互联网的招聘平台，在朋友推荐下跟一家软件公司合作，以远超行业价格的费用签约，原本按行业水平三个月能开发好的系统，硬是拖了半年才完成，但功能简陋，设计毫无美观，项目因为不达标一直没有上线。一年后，准备投第二笔钱做项目的迭代优化，原先的供应商又报了一个离谱的价格。老板无奈之下重新选择了供应商，由于原开发的项目代码混乱，设计糟糕，把之前的项目推翻从零再次开发，但已错过了互联网项目最佳的推广时期；<br>客户B：法律行业，拿了天使投资准备开发一个互联网法律服务平台，创始团队有律师背景，产品经理，运营人才，只差一个技术合伙人。在没有技术基础的情况下，选择自建技术团队，前前后后招聘技术人才花了不少时间（2014年互联网人才非常紧缺），后经过长达一年的项目开发，把一个一流的设计方案，开发出了三流的山寨效果，项目因为质量原因，迟迟不能上线，也基本把项目的所有开发预算耗完。后请求投资人意见，希望再度投钱重新启动开发项目；<br>客户C：教育行业，由于朋友公司刚好有技术团队有空档，整个项目外包给朋友的技术开发团队，因技术负责人不懂产品设计，不擅沟通，且没有做好项目进度和质量管控，项目严重延期，且质量远远达不到预期。客户C无奈下，选择终止合作，但经过长达半个多月的交涉，才完成项目交接，且双方也闹得不太愉快。</p><p>如何找一个给力且满意的技术第三方？</p><p>靠谱的技术服务商需要具备哪些条件？<br>通过哪些渠道可以找到比较高质量的技术服务商？<br>如何在锁定的几家技术服务商中选择一个最适合的团队合作？</p><p>靠谱的技术服务商需要具备哪些条件？</p><p>甲方–我们公司        乙方–第三方技术提供方</p><p>1.做事诚信靠谱：这个是首要考虑的条件，做事靠谱是最重要的，不然在后续的合作过程中会出现很多坑。比如价格低开高走，为了追求利润而进行错误的引导，提出的问题拖着不解决，各种不配合，设置系统的后门等等。有很多人咨询过关于合同制订的问题，怕合同里面有什么不合理的条约，我觉得合同这些都是次要的，在中国这样的人情社会，合同对于乙方的约束并不大，而且诉讼流程漫长而繁琐。核心的关键点还是在于乙方的靠谱程度，即使在合同约束范围外的问题，靠谱的服务商也会尽心尽力地去帮甲方解决问题；</p><p>2.专业能力强：这方面主要考察专业的深度问题，通常项目开发的成败主要是技术和设计这两方面决定的，设计决定了项目的呈现效果和交互体验，技术决定了项目的最终质量，稳定性和实际体验，所以需要重点对技术和设计的深度做了解。由于对接人一般是业务或产品经理，并不能对这方面有一个深入的了解，一般只能通过公司过往的实际案例，团队的基因，工作经验年限，公司的一些原创文章去做了解和判断。</p><p>3.综合能力全面：一个完整的项目开发流程不单单只是技术，还牵涉到设计，管理，测试等环节，如果在某一些环节上面出现严重的短板，务必对项目的最终效果会产生很大的影响。这里牵涉到专业能力的广度问题，涉及到的能力范畴有：商务的对接能力，需求的梳理能力，业务的理解能力，产品的设计能力，UI的设计能力，技术的开发能力，项目的管理能力，质量把控的测试能力。对于任意一家服务商，都有他们擅长的领域，通常创始团队的基因决定了公司擅长的领域，比如业务型的团队擅长营销，技术型的团队技术上面很有优势，而设计出身的团队能产出更好的设计方案。一般都没有面面俱全的公司，需要评估公司的综合能力，避免在某个领域存在致命的短板；</p><p>通过哪些渠道可以找到比较高质量的技术服务商？</p><p>找行业内专业的朋友推荐（靠谱指数：5星）：这个是找服务商的首选方式，但朋友一定是专业，并且懂行的人，这个非常重要，因为他会帮你做初步的筛选和甄别，并且会站在客观的立场帮你做分析，推荐合适的公司或开发团队；</p><p>通过高质量的文章查找服务商（靠谱指数：4星）：通过知乎，微信，论坛，新媒体等平台，查找一些跟项目相关的高质量文章，如搜索”APP开发”，”微信开发”，”网站开发”之类的业务关键词，然后找到里面的一些高质量高水平的文章（硬广的广告一律pass掉），通常文章里面会留有作者或公司的一些联系方式，尝试跟这个领域的专家勾搭联系，然后让他（她）通过自荐或推荐的方式，找到匹配的技术服务商；</p><p>通过搜索引擎查找服务商（靠谱指数：3星）：相对前两种方式，通过这种方式可以快速地找到几百上千家技术服务商，这类公司通常知名度较高，但基本都是非常擅长投放百度竞价或SEO优化的公司，营销和市场能力较强，但技术和设计能力反而不是特别出色。由于业务量和咨询人数较多，做得好的公司有一定人数规模，收费相对而言也比较贵，性价比总体而言不高；</p><p>通过众包平台查找服务商（靠谱指数：3星）：比如通过程序员客栈，码市等众包平台寻找接包方。这类平台相对而言，聚焦了一批相对优质的个人开发者，价格相对猪八戒等平台要偏高一些，但相对整包给公司，价格要少一些。优点是质量相对可控，有一定的成本优势，缺点是由于项目的开发人员都通过远程协助开发的方式，且没有经过长期的团队配合，有些开发人员是兼职开发，对于项目周期及开发人员比较难把控，适合有技术合伙人的公司去对接零散的异地开发人员；</p><p>通过一些中介平台查找服务商（靠谱指数：2星）：比如猪八戒，一品威客，智城等。这类平台汇集了比较多的低端开发者和公司，价格便宜，但服务和项目质量低，适合一些小项目或对质量要求不高，价格敏感的创业者。</p><p>如何在锁定的几家技术服务商中选择一个最适合的团队合作？<br>经过前面一轮初步的筛选和沟通，最终可以锁定了几家技术服务商，并经过细致的沟通后拿到了各个服务商的报价方案。那么，在最终选择服务商的时候，应该怎么选择最合适并且匹配的服务商呢？这里面牵涉到很多专业性的判断和技巧，如果身边有专业的朋友，建议咨询一下朋友的专业意见，从报价的合理性，服务商的技术，设计能力，需求梳理规划的合理性提供一些参考意见。</p><p>以下提供一些不需要专业技能进行判断选择的方法：</p><p>项目与服务商的匹配度：如果只是做做一个很小的app项目，比如开发一个计算器之类的小应用，找一个兼职的设计师和一个兼职的APP开发人员，或者一个小的开发团队即可完成这个项目；如果你的预算不多，对质量要求也不高，但牵涉到多个端的开发的话，找一个报价低，专业能力一般的小公司开发就足以应付这个项目；如果你项目较大，质量要求高，且牵涉到有一定技术难点的应用，如AR功能，就需要找专业的开发公司来开发了，价格肯定也不会比较贵。有些创业者只有几万的预算，却总想着找一个专业能力强，牛人多，且开发一个复杂的应用，这个时候就只能去购买标准的产品了，而不是走定制的方向，能力越强，规模越大的公司，收费也越贵。如果预算方面比较充裕，请忽略这一点；</p><p>价格的比较：相信很多人拿到多份报价方案的时候，一脸茫然，不知道怎么去进行对比，每家公司报的价格出入很大，而且需求描述，功能规划也不尽相同，采用什么技术方案也没有说明，没有一个标准的对比性。这时对于非专业的人来说可能只看最终的价格，这是很大的一个误区。理想的情况下，作为甲方，应该尽可能地把自己的需求描述清楚，最好写一份文字说明文档，并多一些耐心跟每一个服务商沟通清楚，确定大家对于需求理解上的一致。其次，尽可能套出每个供应商的能接受的最低价格。如果大家的理解都是准确的话，拿到报价后对功能进行逐一对比就有了标准需求的参照，这时需要特别留意报价方案上面有没有遗漏的功能点，或者在某些需求描述上面含糊不清，这个对最终的价格也有很大的影响。一般价格选择上面，会更偏向于中等或中等偏上的供应商。</p><p>最终的选择：结合上面提到的诚信靠谱度，专业能力，综合能力这三个维度，对每一个供应商进行一个综合的打分。如果供应商有开发过类似行业的应用，或者类似的功能，是一个加分项。最后结合价格做一个最终的权衡，基本就可以得出应该要选哪个供应商了。</p><p>当然，权衡利弊，若要自己选择搭建可靠地团队，需要付出的是开发时间成本，但是产品的走向可以根据自己的来，质量完全由自己控制，还有人力资源，因为若想要自己筹建团队来搞这个项目，首先你要招人，这些招聘开销以及人员的工资，让一个项目从零到1开发出来，时间不固定，若是有完整可靠地开发团队想跟你走这个创业的道路当然是最好。<br>若是选择外包，质量永远不可能像自己写的这么好，而且项目一旦在谈产品需求报价确定后，是不可能进行频繁修改的，这其中也有很高的联系成本，产品开发出来是什么样就是什么样了，只能自己维护，当然外包也有好处，就是交由第三方先把总体框架写出来，上线快，可以很快的投入使用，因为外包公司做项目，里面肯定有一些已经现成做好的功能，只需要作为模块添加到你的产品组装即可，开发时间较快。</p><p>综合考虑，若是要拿出具体的成品再来谈风投的话，可以选择自己筹钱去谈外包，把外部框架快速做好再取跟风投谈。<br>若是没有成品的前提下要去谈风投的话，则等到风投钱到位后，召集人马自己搭建团队做项目即可。这无疑是最好的办法。</p><p>IT外包对于创业公司来说，又爱又恨，不得已而为之者居多。初创公司，有多少是在跑DEMO，因此预算控制，是最重要的一件事。预算有多少，就去做多大的事，量力而行，活在当下，摸着石头过河，是期待问题，而不是技术实现问题。因此，创业公司CEO首先应该做的是根据目前的情况，计算可靠预算，同时，管理自己的期望，做好市场预期规划。而不是，好大喜功，妄图花小钱办大事，世界上没有免费的午餐，即使如此，占得一时便宜，也绝不具有持续性。</p><p>IT外包能够最快最大限度实现产品和服务的落地，成本低廉，但是产品质量和后续维护的坑多到难以置信，让你”万万想不到”！</p><p>最常见的坑是：</p><p>1.项目需求对接不清，成本差异过大，技术公司要求追加高昂费用，烂尾机率很大</p><p>2.因为语言不统一，项目按人工时间成本计算价格，重新学习他人语言逻辑时间成本耗时费力，一般项目难以找到接盘侠，大概率推翻重做，前期投入均为空</p><p>3.大外包公司，成本高昂，但服务质量缩水，对创业公司友好度低，有质量得技术基本都在别的大项目组，很可能碰到实习生水平的技术但花着比政府项目还多的钱；</p><p>4.小外包公司，人员素质水平差异大，难以判断，后续支持力不足，长期维护难度大，技术实现风险高………………</p><p>既然如此，建立自己的开发团队是最好的也最长久的选择，但是初创公司自己建立团队的难点在哪儿呢？</p><p>1.初创公司，市场预期不明确，项目风险大，项目是否有良好的盈利能力不能准确预期，如此前提，养着一个开发团队造成现金流巨大压力，可能直接导致项目毙命</p><p>2.IT团队的cto可遇而不可求，寻找合伙人本身就难度很大，与资源和人脉，自身魅力，公司前景，运气都有极大关系，样样具备，难上加难，一个不合格的合伙人也会直接导致团队溃败…………如此，初创公司在钱不多，在跑demo又急于落地，最佳选择，是不存在的！！！但是我们可以有曲线救国的选项！！！控制成本，项目落地，管理预期风险是最重要的生存保障，那么，策略是：管理预期需求，提升it技术知识经验，在成本控制范围内寻找靠谱的外包公司实现核心需求的落地。随着项目落地，有一定变现能力，寻找投资，搭建技术团队，推倒重建，进行迭代。</p><p>我的想法：</p><p>若是我们有一定的资金但是没有风投又急于快速占领市场，可以选择快速外包，然后合伙人部分做维护，同时让产品快速进入运营期以补贴亏损，一旦赚到钱或者获得风投，迅速招人，广纳良将，作为初创公司的第一批技术储备力量，从外包公司的源码做升级迭代优化，甚至完全替换。</p><p>若是以项目完整度拿到风投资金，则完全不考虑外包或者可以考虑部分外包，只做框架，或者我们招美工去设计，由自己掌控，让产品快速上线。</p><h2 id="国内外包移动端服务公司数据收集及评定"><a href="#国内外包移动端服务公司数据收集及评定" class="headerlink" title="国内外包移动端服务公司数据收集及评定"></a>国内外包移动端服务公司数据收集及评定</h2><p>先列出网络数据源收集的公司，之后我再做系统的综合评定。。。</p><p>可以选择知名公司去做（安全稳定，但是报价高），可以选择新外包企业（因为也不排除一些新公司想通过质量去赢得市场），主要是看运气，能不能找到一家质量高又价钱合理的公司，因为做生意总想着找便宜又质量好的东西。</p><p>1.广州微匠互联网科技有限公司<br>广州市海珠区新港中路浩蕴大厦1105房（地铁客村D出口，TIT创意园正对面）<br>致力于互联网移动端项目从0到1一站式开发，新公司，案例少，但是质量有可能较高。</p><p>2.</p><p>资源收集：<br><a href="https://www.zhihu.com/question/31155811" target="_blank" rel="noopener">https://www.zhihu.com/question/31155811</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;中小型互联网企业的技术支持到底有哪些（数据来源于网络爬虫及本人总结），项目包括多终端接口（WEB,IOS,Android），接入微服务架构，服务端软件层面主要语言为JAVA开发，考虑架构稳定性以及可拓展性，灵活性，硬件层面包括完整的企业级应用主机服务器，服务器商业托管服务，数据管理中心，云计算，大数据，OA系统，ERP软件，数据库储存方案等等，企业对接服务包括400电话，企业邮箱，企业公众号等等，关于这些技术我都会做总结。我尽量用最简洁的语言来做阐述，帮助我的合作伙伴解决技术疑惑。&lt;/p&gt;
    
    </summary>
    
      <category term="创业之路" scheme="http://yoursite.com/categories/%E5%88%9B%E4%B8%9A%E4%B9%8B%E8%B7%AF/"/>
    
    
      <category term="创业" scheme="http://yoursite.com/tags/%E5%88%9B%E4%B8%9A/"/>
    
      <category term="技术支持" scheme="http://yoursite.com/tags/%E6%8A%80%E6%9C%AF%E6%94%AF%E6%8C%81/"/>
    
      <category term="平台搭建" scheme="http://yoursite.com/tags/%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot之路(四)--Swagger2（RESTful API统一文档）</title>
    <link href="http://yoursite.com/2018/03/24/springboot04/"/>
    <id>http://yoursite.com/2018/03/24/springboot04/</id>
    <published>2018-03-24T09:22:09.000Z</published>
    <updated>2018-03-25T16:26:02.200Z</updated>
    
    <content type="html"><![CDATA[<p>现如今的互联网开发，一款成熟的产品往往不只有Web作为前端，有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等等，现在的多终端时代，有可能我们需要开发所有市面的终端设备。</p><p>由于Spring Boot能够快速开发、便捷部署等特性，相信有很大一部分Spring Boot的用户会用来构建RESTful API。而我们构建RESTful API的目的通常都是由于多终端的原因，这些终端会共用很多底层业务逻辑，因此我们会抽象出这样一层来同时服务于多个移动端或者Web前端。</p><p>随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、先后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。<br>前端和后端的唯一联系，变成了API接口；API文档变成了前后端开发人员联系的纽带，变得越来越重要，swagger就是一款让你更好的书写API文档的框架。</p><p>这样一来，我们的RESTful API就有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等。为了减少与其他团队平时开发期间的频繁沟通成本，传统做法我们会创建一份RESTful API文档来记录所有接口细节，然而这样的做法有以下几个问题：</p><a id="more"></a><p>1.由于接口众多，并且细节复杂（需要考虑不同的HTTP请求类型、HTTP头部信息、HTTP请求内容等），高质量地创建这份文档本身就是件非常吃力的事，下游的抱怨声不绝于耳。</p><p>2.随着时间推移，不断修改接口实现的时候都必须同步修改接口文档，而文档与代码又处于两个不同的媒介，除非有严格的管理机制，不然很容易导致不一致现象。</p><p>如何在开发团队中实现一个RESTful API的接口统一文档？</p><h1 id="Swagger2"><a href="#Swagger2" class="headerlink" title="Swagger2"></a>Swagger2</h1><p>使用Swagger之前我们先需要构建一个RESTful API来做准备。</p><p>RESTful API具体设计如下：</p><p><img src="/2018/03/24/springboot04/p1.png" alt="logo"></p><p>User实体定义：</p><pre><code>public class User {     private Long id;     private String name;     private Integer age;     // 省略setter和getter }</code></pre><p>实现对User对象的操作接口：</p><pre><code>@RestController @RequestMapping(value=&quot;/users&quot;)     // 通过这里配置使下面的映射都在/users下 public class UserController {     // 创建线程安全的Map     //利用Collections工具类中的synchronizedMap方法来构建同步Map    //SynchronizedMap类是定义在Collections中的一个静态内部类。    //它实现了Map接口，并对其中的每一个方法实现，通过synchronized关键字进行了同步控制    //这样的好处在于Map不会产生混乱，当有并发请求时这个Map会进行同步锁。    static Map&lt;Long, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Long, User&gt;());     @RequestMapping(value=&quot;/&quot;, method=RequestMethod.GET)     public List&lt;User&gt; getUserList() {         // 处理&quot;/users/&quot;的GET请求，用来获取用户列表         // 还可以通过@RequestParam从页面中传递参数来进行查询条件或者翻页信息的传递        //users.Values()获取用户信息的所有值并传递给一个List集合，然后通过返回集合呈现过我们         List&lt;User&gt; r = new ArrayList&lt;User&gt;(users.values());         return r;     }     @RequestMapping(value=&quot;/&quot;, method=RequestMethod.POST)     public String postUser(@ModelAttribute User user) {         // 处理&quot;/users/&quot;的POST请求，用来创建User         // 除了@ModelAttribute绑定参数之外，还可以通过@RequestParam从页面中传递参数         users.put(user.getId(), user);         return &quot;success&quot;;     }     @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.GET)     public User getUser(@PathVariable Long id) {         // 处理&quot;/users/{id}&quot;的GET请求，用来获取url中id值的User信息         // url中的id可通过@PathVariable绑定到函数的参数中         return users.get(id);     }     @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.PUT)     public String putUser(@PathVariable Long id, @ModelAttribute User user) {         // 处理&quot;/users/{id}&quot;的PUT请求，用来更新User信息         User u = users.get(id);         u.setName(user.getName());         u.setAge(user.getAge());         users.put(id, u);         return &quot;success&quot;;     }     @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.DELETE)     public String deleteUser(@PathVariable Long id) {         // 处理&quot;/users/{id}&quot;的DELETE请求，用来删除User         users.remove(id);         return &quot;success&quot;;     } }</code></pre><p>下面针对该Controller编写测试用例验证正确性，具体如下。当然也可以通过浏览器插件等进行请求提交验证。</p><pre><code>@RunWith(SpringJUnit4ClassRunner.class) //@SpringApplicationConfiguration(classes = MockServletContext.class) @WebAppConfiguration public class ApplicationTests {     private MockMvc mvc;     @Before     public void setUp() throws Exception {         mvc = MockMvcBuilders.standaloneSetup(new UserController()).build();     }     @Test     public void testUserController() throws Exception {         // 测试UserController         RequestBuilder request = null;         // 1、get查一下user列表，应该为空         request = get(&quot;/users/&quot;);         mvc.perform(request)                 .andExpect(status().isOk())                 .andExpect(content().string(equalTo(&quot;[]&quot;)));         // 2、post提交一个user         request = post(&quot;/users/&quot;)                 .param(&quot;id&quot;, &quot;1&quot;)                 .param(&quot;name&quot;, &quot;测试大师&quot;)                 .param(&quot;age&quot;, &quot;20&quot;);         mvc.perform(request)                 .andExpect(content().string(equalTo(&quot;success&quot;)));         // 3、get获取user列表，应该有刚才插入的数据         request = get(&quot;/users/&quot;);         mvc.perform(request)                 .andExpect(status().isOk())                 .andExpect(content().string(equalTo(&quot;[{\&quot;id\&quot;:1,\&quot;name\&quot;:\&quot;测试大师\&quot;,\&quot;age\&quot;:20}]&quot;)));         // 4、put修改id为1的user         request = put(&quot;/users/1&quot;)                 .param(&quot;name&quot;, &quot;测试终极大师&quot;)                 .param(&quot;age&quot;, &quot;30&quot;);         mvc.perform(request)                 .andExpect(content().string(equalTo(&quot;success&quot;)));         // 5、get一个id为1的user         request = get(&quot;/users/1&quot;);         mvc.perform(request)                 .andExpect(content().string(equalTo(&quot;{\&quot;id\&quot;:1,\&quot;name\&quot;:\&quot;测试终极大师\&quot;,\&quot;age\&quot;:30}&quot;)));         // 6、del删除id为1的user         request = delete(&quot;/users/1&quot;);         mvc.perform(request)                 .andExpect(content().string(equalTo(&quot;success&quot;)));         // 7、get查一下user列表，应该为空         request = get(&quot;/users/&quot;);         mvc.perform(request)                 .andExpect(status().isOk())                 .andExpect(content().string(equalTo(&quot;[]&quot;)));     } }</code></pre><p>测试Console内容：</p><pre><code>2018-03-25 23:25:23.827  INFO 7832 --- [           main] com.didispace.ApplicationTests           : Starting ApplicationTests on DX-20170223SFUP with PID 7832 (F:\SpringBoot-Learning\Chapter3-1-1\target\test-classes started by Administrator in F:\SpringBoot-Learning\Chapter3-1-1)2018-03-25 23:25:23.829  INFO 7832 --- [           main] com.didispace.ApplicationTests           : No active profile set, falling back to default profiles: default2018-03-25 23:25:24.217  INFO 7832 --- [           main] o.s.w.c.s.GenericWebApplicationContext   : Refreshing org.springframework.web.context.support.GenericWebApplicationContext@6d2a209c: startup date [Sun Mar 25 23:25:24 CST 2018]; root of context hierarchy2018-03-25 23:25:25.640  INFO 7832 --- [           main] com.didispace.ApplicationTests           : Started ApplicationTests in 3.468 seconds (JVM running for 6.448)2018-03-25 23:25:26.400  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/hello]}&quot; onto public java.lang.String com.didispace.web.HelloController.index()2018-03-25 23:25:26.431  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/],methods=[GET]}&quot; onto public java.util.List&lt;com.didispace.domain.User&gt; com.didispace.web.UserController.getUserList()2018-03-25 23:25:26.432  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/],methods=[POST]}&quot; onto public java.lang.String com.didispace.web.UserController.postUser(com.didispace.domain.User)2018-03-25 23:25:26.432  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/{id}],methods=[GET]}&quot; onto public com.didispace.domain.User com.didispace.web.UserController.getUser(java.lang.Long)2018-03-25 23:25:26.432  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/{id}],methods=[PUT]}&quot; onto public java.lang.String com.didispace.web.UserController.putUser(java.lang.Long,com.didispace.domain.User)2018-03-25 23:25:26.433  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/{id}],methods=[DELETE]}&quot; onto public java.lang.String com.didispace.web.UserController.deleteUser(java.lang.Long)2018-03-25 23:25:27.204  INFO 7832 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.test.web.servlet.setup.StubWebApplicationContext@44a7bfbc2018-03-25 23:25:27.498  INFO 7832 --- [           main] o.s.mock.web.MockServletContext          : Initializing Spring FrameworkServlet &apos;&apos;2018-03-25 23:25:27.499  INFO 7832 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet &apos;&apos;: initialization started2018-03-25 23:25:27.500  INFO 7832 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet &apos;&apos;: initialization completed in 1 ms2018-03-25 23:25:27.890  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/hello]}&quot; onto public java.lang.String com.didispace.web.HelloController.index()2018-03-25 23:25:27.896  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/],methods=[GET]}&quot; onto public java.util.List&lt;com.didispace.domain.User&gt; com.didispace.web.UserController.getUserList()2018-03-25 23:25:27.896  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/],methods=[POST]}&quot; onto public java.lang.String com.didispace.web.UserController.postUser(com.didispace.domain.User)2018-03-25 23:25:27.897  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/{id}],methods=[GET]}&quot; onto public com.didispace.domain.User com.didispace.web.UserController.getUser(java.lang.Long)2018-03-25 23:25:27.897  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/{id}],methods=[PUT]}&quot; onto public java.lang.String com.didispace.web.UserController.putUser(java.lang.Long,com.didispace.domain.User)2018-03-25 23:25:27.897  INFO 7832 --- [           main] ilder$StaticRequestMappingHandlerMapping : Mapped &quot;{[/users/{id}],methods=[DELETE]}&quot; onto public java.lang.String com.didispace.web.UserController.deleteUser(java.lang.Long)2018-03-25 23:25:27.920  INFO 7832 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.test.web.servlet.setup.StubWebApplicationContext@61fe302018-03-25 23:25:27.927  INFO 7832 --- [           main] o.s.mock.web.MockServletContext          : Initializing Spring FrameworkServlet &apos;&apos;2018-03-25 23:25:27.927  INFO 7832 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet &apos;&apos;: initialization started2018-03-25 23:25:27.927  INFO 7832 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet &apos;&apos;: initialization completed in 0 ms2018-03-25 23:25:27.952  INFO 7832 --- [       Thread-1] o.s.w.c.s.GenericWebApplicationContext   : Closing org.springframework.web.context.support.GenericWebApplicationContext@6d2a209c: startup date [Sun Mar 25 23:25:24 CST 2018]; root of context hierarchy</code></pre><p>这个是用MockMVC来做数据分析，当然我们也可以直接用浏览器发送请求来实战测试，这就需要浏览器发送GET请求和POST请求<br>那么按照我们常规的方法是编写一个网站来发送POST请求（因为POST请求是不直接表达在URL上的）<br>所以这就需要借助浏览器的一些插件来实现发送POST请求</p><p>我们开发的工具是Google的Chrome浏览器，我们通过应用市场下载POSTMAN插件就可以实现浏览器发送POST请求<br>做WEB端开发的人员必须要下载这个插件作为调试页面访问请求的数据显示。</p><h2 id="Postman插件概述"><a href="#Postman插件概述" class="headerlink" title="Postman插件概述"></a>Postman插件概述</h2><p>Postman插件是什么？postman插件是一款chrome插件，是谷歌浏览器的网页调试插件，这款插件可以利用Chrome插件的形式把各种模拟用户HTTP请求的数据发送到服务器，以便开发人员能够及时地作出正确的响应，或者是对产品发布之前的错误信息提前处理，进而保证产品上线之后的稳定性和安全性。Postman是一种网页调试与发送网页http请求的chrome插件。我们可以用来很方便的模拟get或者post或者其他方式的请求来调试接口。</p><ul><li>Postman插件功能介绍</li></ul><p>当开发人员需要调试一个网页是否运行正常，并不是简简单单地调试网页的HTML、CSS、脚本等信息是否运行正常，更加重要的是网页能够正确是处理各种HTTP请求，毕竟网页的HTTP请求是网站与用户之间进行交互的非常重要的一种方式，在动态网站中，用户的大部分数据都需要通过HTTP请求来与服务器进行交互。可以利用Chrome插件的形式把各种模拟用户HTTP请求的数据发送到服务器，以便开发人员能够及时地作出正确的响应，或者是对产品发布之前的错误信息提前处理，进而保证产品上线之后的稳定性和安全性。</p><p>POSTman教程及安装：<a href="http://www.cnplugins.com/devtool/postman/" target="_blank" rel="noopener">http://www.cnplugins.com/devtool/postman/</a></p><p>它可以轻松的整合到Spring Boot中，并与Spring MVC程序配合组织出强大RESTful API文档。它既可以减少我们创建文档的工作量，同时说明内容又整合入实现代码中，让维护文档和修改代码整合为一体，可以让我们在修改代码逻辑的同时方便的修改文档说明。另外Swagger2也提供了强大的页面测试功能来调试每个RESTful API。具体效果如下图所示：</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现如今的互联网开发，一款成熟的产品往往不只有Web作为前端，有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等等，现在的多终端时代，有可能我们需要开发所有市面的终端设备。&lt;/p&gt;
&lt;p&gt;由于Spring Boot能够快速开发、便捷部署等特性，相信有很大一部分Spring Boot的用户会用来构建RESTful API。而我们构建RESTful API的目的通常都是由于多终端的原因，这些终端会共用很多底层业务逻辑，因此我们会抽象出这样一层来同时服务于多个移动端或者Web前端。&lt;/p&gt;
&lt;p&gt;随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、先后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。&lt;br&gt;前端和后端的唯一联系，变成了API接口；API文档变成了前后端开发人员联系的纽带，变得越来越重要，swagger就是一款让你更好的书写API文档的框架。&lt;/p&gt;
&lt;p&gt;这样一来，我们的RESTful API就有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等。为了减少与其他团队平时开发期间的频繁沟通成本，传统做法我们会创建一份RESTful API文档来记录所有接口细节，然而这样的做法有以下几个问题：&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot之路(三)--Thymeleaf模板引擎</title>
    <link href="http://yoursite.com/2018/03/24/springboot03/"/>
    <id>http://yoursite.com/2018/03/24/springboot03/</id>
    <published>2018-03-24T05:23:22.000Z</published>
    <updated>2018-03-24T18:35:30.820Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Thymeleaf"><a href="#Thymeleaf" class="headerlink" title="Thymeleaf"></a>Thymeleaf</h1><p>在实际的公司开发中，传统的JSP技术由于前段后端结合太过紧密，而且后端人员需要随时测试数据能不能渲染在界面上，这就需要前端与后端部门过于紧耦合，不利于实际开发，反而是模板引擎用的较多（当然也不排除一些老的公司需要维护公司以前的动态JSP网页）</p><p>thymeleaf最大的优势后缀为html,就是只需要浏览器就可以展现页面了,还有就是thymeleaf可以很好的和spring集成.</p><p>Thymeleaf是一个XML/XHTML/HTML5模板引擎，可用于Web与非Web环境中的应用开发。它是一个开源的Java库，基于Apache License 2.0许可，由Daniel Fernández创建，该作者还是Java加密库Jasypt的作者。</p><a id="more"></a><p>Thymeleaf提供了一个用于整合Spring MVC的可选模块，在应用开发中，你可以使用Thymeleaf来完全代替JSP或其他模板引擎，如Velocity、FreeMarker等。Thymeleaf的主要目标在于提供一种可被浏览器正确显示的、格式良好的模板创建方式，因此也可以用作静态建模。你可以使用它创建经过验证的XML与HTML模板。相对于编写逻辑或代码，开发者只需将标签属性添加到模板中即可。接下来，这些标签属性就会在DOM（文档对象模型）上执行预先制定好的逻辑。</p><h1 id="静态资源访问"><a href="#静态资源访问" class="headerlink" title="静态资源访问"></a>静态资源访问</h1><p>在我们开发Web应用的时候，需要引用大量的js、css、图片等静态资源。</p><h1 id="默认配置"><a href="#默认配置" class="headerlink" title="默认配置"></a>默认配置</h1><p>Spring Boot默认提供静态资源目录位置需置于classpath下，目录名需符合如下规则：</p><pre><code>/static/public/resources/META-INF/resources</code></pre><p>举例：我们可以在src/main/resources/目录下创建static，在该位置放置一个图片文件。启动程序后，尝试访问<a href="http://localhost:8088/D.jpg。如能显示图片，配置成功。" target="_blank" rel="noopener">http://localhost:8088/D.jpg。如能显示图片，配置成功。</a></p><p>在之前的示例中，我们都是通过@RestController来处理请求，所以返回的内容为json对象。那么如果需要渲染html页面的时候，要如何实现呢？</p><p>在动态HTML实现上Spring Boot依然可以完美胜任，并且提供了多种模板引擎的默认配置支持，所以在推荐的模板引擎下，我们可以很快的上手开发动态网站。</p><p>Spring Boot提供了默认配置的模板引擎（抛弃传统的JSP动态网页）主要有以下几种：</p><p>Thymeleaf<br>FreeMarker<br>Velocity<br>Groovy<br>Mustache</p><p>Spring Boot建议使用这些模板引擎，避免使用<strong>JSP</strong>，若一定要使用JSP将无法实现Spring Boot的多种特性，具体可见后文：支持JSP的配置</p><p>当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径，具体如何修改，可在后续各模板引擎的配置属性中查询并修改。</p><p>示例：</p><pre><code>&lt;table&gt;  &lt;thead&gt;    &lt;tr&gt;      &lt;th th:text=&quot;#{msgs.headers.name}&quot;&gt;Name&lt;/td&gt;      &lt;th th:text=&quot;#{msgs.headers.price}&quot;&gt;Price&lt;/td&gt;    &lt;/tr&gt;  &lt;/thead&gt;  &lt;tbody&gt;    &lt;tr th:each=&quot;prod : ${allProducts}&quot;&gt;      &lt;td th:text=&quot;${prod.name}&quot;&gt;Oranges&lt;/td&gt;      &lt;td th:text=&quot;${#numbers.formatDecimal(prod.price,1,2)}&quot;&gt;0.99&lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;</code></pre><p>可以看到Thymeleaf主要以<strong>属性</strong>的方式加入到html标签中，浏览器在解析html时，当检查到没有的属性时候会忽略，所以Thymeleaf的模板可以通过浏览器直接打开展现，这样非常有利于前后端的分离。</p><p>在Spring Boot中使用Thymeleaf，只需要引入下面依赖，并在默认的模板路径src/main/resources/templates下编写模板文件即可完成。</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>在完成配置之后，举一个简单的例子，在快速入门工程的基础上，举一个简单的示例来通过Thymeleaf渲染一个页面。</p><pre><code>package com.example.springboot.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.ModelMap;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class IndexController {    @RequestMapping(&quot;/index&quot;)    public String index(ModelMap map){        map.addAttribute(&quot;hello&quot;, &quot;i love you@com&quot;);        return &quot;index&quot;;    }}</code></pre><p>相应的index.html界面代码为</p><pre><code>&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;/meta&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;  &lt;h1 th:text=&quot;${hello}&quot;&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p>启动程序后，页面输入<a href="http://localhost:8088/index，所出现的显示数据是：i" target="_blank" rel="noopener">http://localhost:8088/index，所出现的显示数据是：i</a> love you@com，并没有出现Hello World<br>展现的是IndexController中的hello的属性值，做到了不破坏HTML自身内容的数据逻辑分离。</p><p>注意：我们建立模板测试或者是实际开发中，我们都需要严格遵守thymeleaf的HTML5页面规范，不然会报错<br>包括我上面写的<meta>标签则需要双标签来自正常结束才可以，否则页面将出现错误，你可以使用严格的标签，也就是每个标签都有结束标签，这种可能比较麻烦。</p><p>那么如何在thymeleaf中声明使用非严格的html5规范呢？</p><p>maven添加依赖</p><pre><code>&lt;dependency&gt;        &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt;        &lt;artifactId&gt;nekohtml&lt;/artifactId&gt;        &lt;version&gt;1.9.22&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>application.properties属性文件中添加</p><p>spring.thymeleaf.mode = LEGACYHTML5</p><p>声明thymeleaf使用非严格的html即可。最后更新下maven仓库即可生效。</p><h1 id="关于Thymeleaf的默认参数配置"><a href="#关于Thymeleaf的默认参数配置" class="headerlink" title="关于Thymeleaf的默认参数配置"></a>关于Thymeleaf的默认参数配置</h1><p>如有需要修改默认配置的时候，只需复制下面要修改的属性到application.properties中，并修改成需要的值，如修改模板文件的扩展名，修改默认的模板路径等。</p><p>-Enable template caching.<br>spring.thymeleaf.cache=true<br>-Check that the templates location exists.<br>spring.thymeleaf.check-template-location=true<br>-Content-Type value.<br>spring.thymeleaf.content-type=text/html<br>-Enable MVC Thymeleaf view resolution.<br>spring.thymeleaf.enabled=true<br>-Template encoding.<br>spring.thymeleaf.encoding=UTF-8<br>-Comma-separated list of view names that should be excluded from resolution.<br>spring.thymeleaf.excluded-view-names=<br>-Template mode to be applied to templates. See also StandardTemplateModeHandlers.<br>spring.thymeleaf.mode=HTML5<br>-Prefix that gets prepended to view names when building a URL.<br>spring.thymeleaf.prefix=classpath:/templates/<br>-Suffix that gets appended to view names when building a URL.<br>spring.thymeleaf.suffix=.html  spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain. spring.thymeleaf.view-names= # Comma-separated list of view names that can be resolved.</p><h1 id="关于Thymeleaf语法"><a href="#关于Thymeleaf语法" class="headerlink" title="关于Thymeleaf语法"></a>关于Thymeleaf语法</h1><h2 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h2><p>对于Thymeleaf语法来说，很多资料中会写应用Thymeleaf语法需要先在<html>标签中引入<br>在html中引入此命名空间，可避免编辑器出现html验证错误，虽然加不加命名空间对Thymeleaf的功能没有任何影响。</html></p><pre><code>&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;</code></pre><p>才可以使用Thymeleaf语法，但是我在上面的案例中并没有声明html标签的属性也可以用，也让我很费解。（不过为了一些不必要的麻烦还是把这个声明加上）</p><h2 id="输出内容"><a href="#输出内容" class="headerlink" title="输出内容"></a>输出内容</h2><p>例如:</p><pre><code>Controller:    map.addAttribute(&quot;hello&quot;, &quot;i love you@com&quot;);HTML:    &lt;h1 th:text=&quot;${hello}&quot;&gt;Hello World&lt;/h1&gt;1. th:text  用来将内容输出到所在标签的body中。2. ${hello} 用来引用hello属性值3. 可以用th:utext 用来显示“unescaped ” 的html内容。(unescaped即非转义字符)</code></pre><p>例如：</p><pre><code>&lt;p th:text=&quot;#{home.welcome}&quot;&gt;Welcome to our grocery store!&lt;/p&gt;`#{home.welcome} 用来引入数据home对象中的 welcome属性。`</code></pre><h2 id="标准表达式语法"><a href="#标准表达式语法" class="headerlink" title="标准表达式语法"></a>标准表达式语法</h2><p>它们分为四类：</p><p>1.变量表达式<br>2.选择或星号表达式<br>3.文字国际化表达式<br>4.URL表达式</p><h3 id="变量表达式"><a href="#变量表达式" class="headerlink" title="变量表达式"></a>变量表达式</h3><p>变量表达式即OGNL表达式或Spring EL表达式(在Spring术语中也叫model attributes)。如下所示：</p><p>${session.user.name}<br>${hello}</p><p>它们将以HTML标签的一个属性来表示：</p><pre><code>&lt;span th:text=&quot;${book.author.name}&quot;&gt;  &lt;li th:each=&quot;book : ${books}&quot;&gt;  </code></pre><h3 id="选择-星号-表达式"><a href="#选择-星号-表达式" class="headerlink" title="选择(星号)表达式"></a>选择(星号)表达式</h3><p>选择表达式很像变量表达式，不过它们用一个预先选择的对象来代替上下文变量容器(map)来执行，如下：</p><p>*{customer.name}</p><p>被指定的object由th:object属性定义：</p><pre><code>&lt;div th:object=&quot;${book}&quot;&gt;    ...    &lt;span th:text=&quot;*{title}&quot;&gt;...&lt;/span&gt;    ...  &lt;/div&gt;  </code></pre><h3 id="文字国际化表达式"><a href="#文字国际化表达式" class="headerlink" title="文字国际化表达式"></a>文字国际化表达式</h3><p>文字国际化表达式允许我们从一个外部文件获取区域文字信息(.properties)，用Key索引Value，还可以提供一组参数(可选).</p><pre><code>`#{main.title} ``#{message.entrycreated(${entryId})} `</code></pre><p>可以在模板文件中找到这样的表达式代码：</p><pre><code>&lt;table&gt;    ...    &lt;th th:text=&quot;#{header.address.city}&quot;&gt;...&lt;/th&gt;    &lt;th th:text=&quot;#{header.address.country}&quot;&gt;...&lt;/th&gt;    ...  &lt;/table&gt; </code></pre><h3 id="URL表达式"><a href="#URL表达式" class="headerlink" title="URL表达式"></a>URL表达式</h3><p>URL表达式指的是把一个有用的上下文或回话信息添加到URL，这个过程经常被叫做URL重写。<br>@{/order/list}</p><p>URL还可以设置参数：<br>@{/order/details(id=${orderId})}</p><p>相对路径：<br>@{../documents/report}</p><p>让我们看这些表达式：</p><pre><code>&lt;form th:action=&quot;@{/createOrder}&quot;&gt;  &lt;a href=&quot;main.html&quot; th:href=&quot;@{/main}&quot;&gt;</code></pre><p>变量表达式和星号表达有什么区别吗？</p><p>如果不考虑上下文的情况下，两者没有区别；星号语法评估在选定对象上表达，而不是整个上下文<br>什么是选定对象？就是父标签的值，如下：（相当于星号表达式会去全局中找这个属性，如果找不到则默认不显示）</p><pre><code>&lt;div th:object=&quot;${session.user}&quot;&gt;   &lt;p&gt;Name: &lt;span th:text=&quot;*{firstName}&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt;   &lt;p&gt;Surname: &lt;span th:text=&quot;*{lastName}&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt;   &lt;p&gt;Nationality: &lt;span th:text=&quot;*{nationality}&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt;&lt;/div&gt;</code></pre><p>完全等价于</p><pre><code>&lt;div th:object=&quot;${session.user}&quot;&gt;     &lt;p&gt;Name: &lt;span th:text=&quot;${session.user.firstName}&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt;     &lt;p&gt;Surname: &lt;span th:text=&quot;${session.user.lastName}&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt;     &lt;p&gt;Nationality: &lt;span th:text=&quot;${session.user.nationality}&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt;&lt;/div&gt;</code></pre><p>当然，美元符号和星号语法可以混合使用：</p><pre><code>&lt;div th:object=&quot;${session.user}&quot;&gt;      &lt;p&gt;Name: &lt;span th:text=&quot;*{firstName}&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt;      &lt;p&gt;Surname: &lt;span th:text=&quot;${session.user.lastName}&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt;      &lt;p&gt;Nationality: &lt;span th:text=&quot;*{nationality}&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt;&lt;/div&gt;</code></pre><h2 id="表达式支持的语法"><a href="#表达式支持的语法" class="headerlink" title="表达式支持的语法"></a>表达式支持的语法</h2><ul><li>字面（Literals）</li></ul><p>文本文字（Text literals）: ‘one text’, ‘Another one!’,…<br>数字文本（Number literals）: 0, 34, 3.0, 12.3,…<br>布尔文本（Boolean literals）: true, false<br>空（Null literal）: null<br>文字标记（Literal tokens）: one, sometext, main,…</p><ul><li>文本操作（Text operations）</li></ul><p>字符串连接(String concatenation): +<br>文本替换（Literal substitutions）: |The name is ${name}|</p><ul><li>算术运算（Arithmetic operations）</li></ul><p>二元运算符（Binary operators）: +, -, *, /, %<br>减号（单目运算符）Minus sign (unary operator): -</p><ul><li>布尔操作（Boolean operations）</li></ul><p>二元运算符（Binary operators）:and, or<br>布尔否定（一元运算符）Boolean negation (unary operator):!, not</p><ul><li>比较和等价(Comparisons and equality)</li></ul><p>比较（Comparators）: &gt;, &lt;, &gt;=, &lt;= (gt, lt, ge, le)<br>等值运算符（Equality operators）:==, != (eq, ne)</p><ul><li>条件运算符（Conditional operators）</li></ul><p>If-then: (if) ? (then)<br>If-then-else: (if) ? (then) : (else)<br>Default: (value) ?: (defaultvalue)</p><p>所有这些特征可以被组合并嵌套：</p><pre><code>&apos;User is of type &apos; + (${user.isAdmin()} ? &apos;Administrator&apos; : (${user.type} ?: &apos;Unknown&apos;))</code></pre><h2 id="常用th标签都有那些？"><a href="#常用th标签都有那些？" class="headerlink" title="常用th标签都有那些？"></a>常用th标签都有那些？</h2><p><img src="/2018/03/24/springboot03/p1.png" alt="logo"><br><img src="/2018/03/24/springboot03/p2.png" alt="logo"><br><img src="/2018/03/24/springboot03/p3.png" alt="logo"></p><h2 id="几种常用的使用方法"><a href="#几种常用的使用方法" class="headerlink" title="几种常用的使用方法"></a>几种常用的使用方法</h2><p>几种Thymeleaf在实际开发中的应用（需要掌握的）</p><ul><li><p>赋值、字符串拼接</p><p>  </p><p th:text="${collect.description}">description</p><br>  <span th:text="'Welcome to our application, ' + ${user.name} + '!'"><p></p></span></li></ul><p>注意：th:text=””,双引号里面才是正确输出的内容，拼接的字符串要用‘’单引号，<br>也有更加简易的拼接字符串的方法，用||符号</p><pre><code>&lt;h1 th:text=&quot;|hello,*{hello}|&quot;&gt;Hello World&lt;/h1&gt;</code></pre><ul><li>条件判断 If/Unless</li></ul><p>Thymeleaf中使用th:if和th:unless属性进行条件判断，下面的例子中，<a>标签只有在th:if中条件成立时才显示：</a></p><pre><code>&lt;a th:if=&quot;${myself==&apos;yes&apos;}&quot; &gt;&lt;/a&gt;&lt;a th:unless=${session.user != null} th:href=&quot;@{/login}&quot; &gt;Login&lt;/a&gt;</code></pre><p>th:unless于th:if恰好相反，只有表达式中的条件不成立，才会显示其内容。</p><p>也可以使用 (if) ? (then) : (else) 这种语法来判断显示的内容</p><ul><li><p>for 循环</p><pre><code>&lt;tr  th:each=&quot;collect,iterStat : ${collects}&quot;&gt;    &lt;th scope=&quot;row&quot; th:text=&quot;${collect.id}&quot;&gt;1&lt;/th&gt;   &lt;td &gt;      &lt;img th:src=&quot;${collect.webLogo}&quot;/&gt;   &lt;/td&gt;   &lt;td th:text=&quot;${collect.url}&quot;&gt;Mark&lt;/td&gt;   &lt;td th:text=&quot;${collect.title}&quot;&gt;Otto&lt;/td&gt;   &lt;td th:text=&quot;${collect.description}&quot;&gt;@mdo&lt;/td&gt;   &lt;td th:text=&quot;${terStat.index}&quot;&gt;index&lt;/td&gt;&lt;/tr&gt;</code></pre></li></ul><p>iterStat称作状态变量，属性有：</p><p>index:当前迭代对象的index（从0开始计算）<br>count: 当前迭代对象的index(从1开始计算)<br>size:被迭代对象的大小<br>current:当前迭代变量<br>even/odd:布尔值，当前循环是否是偶数/奇数（从0开始计算）<br>first:布尔值，当前循环是否是第一个<br>last:布尔值，当前循环是否是最后一个</p><ul><li>URL</li></ul><p>URL在Web应用模板中占据着十分重要的地位，需要特别注意的是Thymeleaf对于URL的处理是通过语法@{…}来处理的。<br>如果需要Thymeleaf对URL进行渲染，那么务必使用th:href，th:src等属性，下面是一个例子</p><pre><code>&lt;!-- Will produce &apos;http://localhost:8080/standard/unread&apos; (plus rewriting) --&gt; &lt;a  th:href=&quot;@{/standard/{type}(type=${type})}&quot;&gt;view&lt;/a&gt;&lt;!-- Will produce &apos;/gtvg/order/3/details&apos; (plus rewriting) --&gt;&lt;a href=&quot;details.html&quot; th:href=&quot;@{/order/{orderId}/details(orderId=${o.id})}&quot;&gt;view&lt;/a&gt;</code></pre><p>设置背景</p><pre><code>&lt;div th:style=&quot;&apos;background:url(&apos; + @{/&lt;path-to-image&gt;} + &apos;);&apos;&quot;&gt;&lt;/div&gt;</code></pre><p>根据属性值改变背景</p><pre><code>&lt;div class=&quot;media-object resource-card-image&quot;  th:style=&quot;&apos;background:url(&apos; + @{(${collect.webLogo}==&apos;&apos; ? &apos;img/favicon.png&apos; : ${collect.webLogo})} + &apos;)&apos;&quot; &gt;&lt;/div&gt;</code></pre><p>几点说明：</p><p>上例中URL最后的(orderId=${o.id}) 表示将括号内的内容作为URL参数处理，该语法避免使用字符串拼接，大大提高了可读性<br>@{…}表达式中可以通过{orderId}访问Context中的orderId变量<br>@{/order}是Context相关的相对路径，在渲染时会自动添加上当前Web应用的Context名字，假设context名字为app，那么结果应该是/app/order</p><ul><li>内联js</li></ul><p>内联文本：[[…]]内联文本的表示方式，使用时，必须先用th:inline=”text/javascript/none”激活，th:inline可以在父级标签内使用，甚至作为body的标签。内联文本尽管比th:text的代码少，不利于原型显示。</p><pre><code>&lt;script th:inline=&quot;javascript&quot;&gt;/*&lt;![CDATA[*/...var username = /*[[${sesion.user.name}]]*/ &apos;Sebastian&apos;;var size = /*[[${size}]]*/ 0;.../*]]&gt;*/&lt;/script&gt;</code></pre><p>js附加代码：</p><pre><code>/*[+var msg = &apos;This is a working application&apos;; +]*/</code></pre><p>js移除代码：</p><pre><code>/*[- */var msg = &apos;This is a non-working template&apos;;/* -]*/</code></pre><ul><li>内嵌变量</li></ul><p>为了模板更加易用，Thymeleaf还提供了一系列Utility对象（内置于Context中），可以通过#直接访问：</p><p>dates ： java.util.Date的功能方法类。<br>calendars : 类似#dates，面向java.util.Calendar<br>numbers : 格式化数字的功能方法类<br>strings : 字符串对象的功能类，contains,startWiths,prepending/appending等等。<br>objects: 对objects的功能类操作。<br>bools: 对布尔值求值的功能方法。<br>arrays：对数组的功能类方法。<br>lists: 对lists功能类方法<br>sets<br>maps<br>…<br>下面用一段代码来举例一些常用的方法：</p><p>1.dates</p><pre><code>/* * Format date with the specified pattern * Also works with arrays, lists or sets */${#dates.format(date, &apos;dd/MMM/yyyy HH:mm&apos;)}${#dates.arrayFormat(datesArray, &apos;dd/MMM/yyyy HH:mm&apos;)}${#dates.listFormat(datesList, &apos;dd/MMM/yyyy HH:mm&apos;)}${#dates.setFormat(datesSet, &apos;dd/MMM/yyyy HH:mm&apos;)}/* * Create a date (java.util.Date) object for the current date and time */${#dates.createNow()}/* * Create a date (java.util.Date) object for the current date (time set to 00:00) */${#dates.createToday()}</code></pre><p>2.strings</p><pre><code>/* * Check whether a String is empty (or null). Performs a trim() operation before check * Also works with arrays, lists or sets */${#strings.isEmpty(name)}${#strings.arrayIsEmpty(nameArr)}${#strings.listIsEmpty(nameList)}${#strings.setIsEmpty(nameSet)}/* * Check whether a String starts or ends with a fragment * Also works with arrays, lists or sets */${#strings.startsWith(name,&apos;Don&apos;)}                  // also array*, list* and set*${#strings.endsWith(name,endingFragment)}           // also array*, list* and set*/* * Compute length * Also works with arrays, lists or sets */${#strings.length(str)}/* * Null-safe comparison and concatenation */${#strings.equals(str)}${#strings.equalsIgnoreCase(str)}${#strings.concat(str)}${#strings.concatReplaceNulls(str)}/* * Random */${#strings.randomAlphanumeric(count)}</code></pre><ul><li>使用thymeleaf布局</li></ul><p>使用thymeleaf布局非常的方便</p><p>定义代码片段</p><pre><code>&lt;footer th:fragment=&quot;copy&quot;&gt; &amp;copy; 2016&lt;/footer&gt;</code></pre><p>在页面任何地方引入：</p><pre><code>&lt;body&gt;   &lt;div th:include=&quot;footer :: copy&quot;&gt;&lt;/div&gt;  &lt;div th:replace=&quot;footer :: copy&quot;&gt;&lt;/div&gt; &lt;/body&gt;‘</code></pre><p>th:include 和 th:replace区别，include只是加载，replace是替换</p><p>返回的HTML如下：</p><pre><code>&lt;body&gt;    &lt;div&gt; &amp;copy; 2016 &lt;/div&gt;   &lt;footer&gt;&amp;copy; 2016 &lt;/footer&gt; &lt;/body&gt;</code></pre><p>下面是一个常用的后台页面布局，将整个页面分为头部，尾部、菜单栏、隐藏栏，点击菜单只改变content区域的页面</p><pre><code>&lt;body class=&quot;layout-fixed&quot;&gt;  &lt;div th:fragment=&quot;navbar&quot;  class=&quot;wrapper&quot;  role=&quot;navigation&quot;&gt;    &lt;div th:replace=&quot;fragments/header :: header&quot;&gt;Header&lt;/div&gt;    &lt;div th:replace=&quot;fragments/left :: left&quot;&gt;left&lt;/div&gt;    &lt;div th:replace=&quot;fragments/sidebar :: sidebar&quot;&gt;sidebar&lt;/div&gt;    &lt;div layout:fragment=&quot;content&quot; id=&quot;content&quot; &gt;&lt;/div&gt;    &lt;div th:replace=&quot;fragments/footer :: footer&quot;&gt;footer&lt;/div&gt;  &lt;/div&gt;&lt;/body&gt;</code></pre><p>任何页面想使用这样的布局值只需要替换中见的 content模块即可</p><pre><code>&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot; layout:decorator=&quot;layout&quot;&gt;  &lt;body&gt;     &lt;section layout:fragment=&quot;content&quot;&gt;   ...</code></pre><p>也可以在引用模版的时候传参</p><pre><code>&lt;head th:include=&quot;layout :: htmlhead&quot; th:with=&quot;title=&apos;Hello&apos;&quot;&gt;&lt;/head&gt;</code></pre><p>layout 是文件地址，如果有文件夹可以这样写 fileName/layout:htmlhead<br>htmlhead 是指定义的代码片段 如 th:fragment=”copy”</p><p>开源云收藏项目的github源码：<a href="https://github.com/cloudfavorites/favorites-web" target="_blank" rel="noopener">https://github.com/cloudfavorites/favorites-web</a><br>里面用的技术包括springboot集成了tomcat和thymeleaf，源码测试里都是详细的项目功能介绍。</p><p>还有就是Springboot虽然不建议使用JSP技术，但是若有相应的要求也可以使用。具体自查。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Thymeleaf&quot;&gt;&lt;a href=&quot;#Thymeleaf&quot; class=&quot;headerlink&quot; title=&quot;Thymeleaf&quot;&gt;&lt;/a&gt;Thymeleaf&lt;/h1&gt;&lt;p&gt;在实际的公司开发中，传统的JSP技术由于前段后端结合太过紧密，而且后端人员需要随时测试数据能不能渲染在界面上，这就需要前端与后端部门过于紧耦合，不利于实际开发，反而是模板引擎用的较多（当然也不排除一些老的公司需要维护公司以前的动态JSP网页）&lt;/p&gt;
&lt;p&gt;thymeleaf最大的优势后缀为html,就是只需要浏览器就可以展现页面了,还有就是thymeleaf可以很好的和spring集成.&lt;/p&gt;
&lt;p&gt;Thymeleaf是一个XML/XHTML/HTML5模板引擎，可用于Web与非Web环境中的应用开发。它是一个开源的Java库，基于Apache License 2.0许可，由Daniel Fernández创建，该作者还是Java加密库Jasypt的作者。&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot之路(二)--Nosql支持</title>
    <link href="http://yoursite.com/2018/03/23/springboot02/"/>
    <id>http://yoursite.com/2018/03/23/springboot02/</id>
    <published>2018-03-23T08:49:42.000Z</published>
    <updated>2018-03-23T18:25:07.681Z</updated>
    
    <content type="html"><![CDATA[<p>在SpringBoot中对常用的数据库支持外，对nosql 数据库也进行了封装自动化。</p><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。<br>Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。<br>它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。</p><a id="more"></a><p>Redis学习手册：<a href="http://www.runoob.com/redis/redis-tutorial.html" target="_blank" rel="noopener">http://www.runoob.com/redis/redis-tutorial.html</a></p><p>Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。<br>Redis 与其他 key - value 缓存产品有以下三个特点：</p><p>1.Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。<br>2.Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。<br>3.Redis支持数据的备份，即master-slave模式的数据备份。</p><p>性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。<br>丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。<br>原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。<br>丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。</p><p>Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。<br>Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。</p><h2 id="什么是BSD协议？"><a href="#什么是BSD协议？" class="headerlink" title="什么是BSD协议？"></a>什么是BSD协议？</h2><p>BSD开源协议是一个给于使用者很大自由的协议。可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。当你发布使用了BSD协议的代码，或者以BSD协议代码为基础做二次开发自己的产品时，需要满足三个条件：<br>如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的BSD协议。<br>如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。<br>不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。<br>BSD代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销 售，因此是对商业集成很友好的协议。<br>很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者 二次开发。</p><h2 id="安装及使用"><a href="#安装及使用" class="headerlink" title="安装及使用"></a>安装及使用</h2><p>Windows下的安装教程：</p><p>下载地址（已在Github上开源）：<a href="https://github.com/MSOpenTech/redis/releases" target="_blank" rel="noopener">https://github.com/MSOpenTech/redis/releases</a></p><p>Redis 支持 32 位和 64 位。这个需要根据你系统平台的实际情况选择，这里我们下载 Redis-x64-xxx.zip压缩包到 F 盘，解压后，将文件夹重新命名为 redis。</p><p>打开一个 cmd 窗口 使用cd命令切换目录到 C:\redis 运行 redis-server.exe redis.windows.conf 。<br>如果想方便的话，可以把 redis 的路径加到系统的环境变量里，这样就省得再输路径了，后面的那个 redis.windows.conf 可以省略，如果省略，会启用默认的。输入之后，会显示如下界面：</p><p><img src="/2018/03/23/springboot02/redis-install1.png" alt="logo"></p><p>这时候另启一个cmd窗口，原来的不要关闭，不然就无法访问服务端了。<br>切换到redis目录下运行 redis-cli.exe -h 127.0.0.1 -p 6379 。<br>设置键值对 set myKey abc<br>取出键值对 get myKey</p><p><img src="/2018/03/23/springboot02/redis-install2.png" alt="logo"></p><p>Redis是目前业界使用最广泛的内存数据存储。相比memcached，Redis支持更丰富的数据结构，例如hashes, lists, sets等，同时支持数据持久化。除此之外，Redis还提供一些类数据库的特性，比如事务，HA，主从库。可以说Redis兼具了缓存系统和数据库的一些特性，因此有着丰富的应用场景。本文介绍Redis在Spring Boot中两个典型的应用场景。</p><h2 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h2><p>1、引入 spring-boot-starter-redis</p><pre><code>&lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;  &lt;/dependency&gt;</code></pre><p>2、添加配置文件</p><p>编辑配置<br>你可以通过修改 redis.conf 文件或使用 CONFIG set 命令来修改配置。</p><p>CONFIG SET 命令基本语法：<br>redis 127.0.0.1:6379&gt; CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE</p><p>通过修改application.properties中配置Redis连接信息文件修改如下：</p><ul><li>REDIS (RedisProperties)</li><li>Redis数据库索引（默认为0）<br>spring.redis.database=0  </li><li>Redis服务器地址<br>spring.redis.host=192.168.0.58</li><li>Redis服务器连接端口<br>spring.redis.port=6379  </li><li>Redis服务器连接密码（默认为空）<br>spring.redis.password=  </li><li>连接池最大连接数（使用负值表示没有限制）<br>spring.redis.pool.max-active=8  </li><li>连接池最大阻塞等待时间（使用负值表示没有限制）<br>spring.redis.pool.max-wait=-1  </li><li>连接池中的最大空闲连接<br>spring.redis.pool.max-idle=8  </li><li>连接池中的最小空闲连接<br>spring.redis.pool.min-idle=0  </li><li>连接超时时间（毫秒）<br>spring.redis.timeout=0  </li></ul><p>3、修改项目启动类</p><p>增加注解@EnableCaching，开启缓存功能，如下：</p><pre><code>package springboot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cache.annotation.EnableCaching;import org.springframework.scheduling.annotation.EnableScheduling;@SpringBootApplication@EnableScheduling@EnableCachingpublic class SpringbootApplication{    public static void main(String[] args) {        SpringApplication.run(SpringbootApplication.class, args);    }}</code></pre><p>4、新建Redis缓存配置类RedisConfig，如下：</p><pre><code>package springboot.config;import org.springframework.beans.factory.annotation.Value;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.cache.annotation.EnableCaching;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;/** * Redis缓存配置类 * @author szekinwin * */@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport{    @Value(&quot;${spring.redis.host}&quot;)    private String host;    @Value(&quot;${spring.redis.port}&quot;)    private int port;    @Value(&quot;${spring.redis.timeout}&quot;)    private int timeout;    //自定义缓存key生成策略//    @Bean//    public KeyGenerator keyGenerator() {//        return new KeyGenerator(){//            @Override//            public Object generate(Object target, java.lang.reflect.Method method, Object... params) {//                StringBuffer sb = new StringBuffer();//                sb.append(target.getClass().getName());//                sb.append(method.getName());//                for(Object obj:params){//                    sb.append(obj.toString());//                }//                return sb.toString();//            }//        };//    }    //缓存管理器    @Bean     public CacheManager cacheManager(@SuppressWarnings(&quot;rawtypes&quot;) RedisTemplate redisTemplate) {        RedisCacheManager cacheManager = new RedisCacheManager(redisTemplate);        //设置缓存过期时间         cacheManager.setDefaultExpiration(10000);        return cacheManager;    }    @Bean    public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory){        StringRedisTemplate template = new StringRedisTemplate(factory);        setSerializer(template);//设置序列化工具        template.afterPropertiesSet();        return template;    }     private void setSerializer(StringRedisTemplate template){            @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })            Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);            ObjectMapper om = new ObjectMapper();            om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);            om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);            jackson2JsonRedisSerializer.setObjectMapper(om);            template.setValueSerializer(jackson2JsonRedisSerializer);     }}</code></pre><p>5、新建UserMapper</p><pre><code>package springboot.dao;import org.apache.ibatis.annotations.Delete;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;import org.apache.ibatis.annotations.Select;import org.apache.ibatis.annotations.Update;import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.CacheEvict;import org.springframework.cache.annotation.CachePut;import org.springframework.cache.annotation.Cacheable;import springboot.domain.User;@Mapper@CacheConfig(cacheNames = &quot;users&quot;)public interface UserMapper {    @Insert(&quot;insert into user(name,age) values(#{name},#{age})&quot;)    int addUser(@Param(&quot;name&quot;)String name,@Param(&quot;age&quot;)String age);    @Select(&quot;select * from user where id =#{id}&quot;)    @Cacheable(key =&quot;#p0&quot;)     User findById(@Param(&quot;id&quot;) String id);    @CachePut(key = &quot;#p0&quot;)    @Update(&quot;update user set name=#{name} where id=#{id}&quot;)    void updataById(@Param(&quot;id&quot;)String id,@Param(&quot;name&quot;)String name);    //如果指定为 true，则方法调用后将立即清空所有缓存    @CacheEvict(key =&quot;#p0&quot;,allEntries=true)    @Delete(&quot;delete from user where id=#{id}&quot;)    void deleteById(@Param(&quot;id&quot;)String id);}</code></pre><p>@Cacheable将查询结果缓存到redis中，（key=”#p0”）指定传入的第一个参数作为redis的key。</p><p>@CachePut，指定key，将更新的结果同步到redis中</p><p>@CacheEvict，指定key，删除缓存数据，allEntries=true,方法调用后将立即清除缓存</p><h2 id="共享Session-spring-session-data-redis"><a href="#共享Session-spring-session-data-redis" class="headerlink" title="共享Session-spring-session-data-redis"></a>共享Session-spring-session-data-redis</h2><p>分布式系统中，sessiong共享有很多的解决方案，其中托管到缓存中应该是最常用的方案之一，</p><p>多台分布式机器共享Session的解决方案</p><h3 id="如何使用-1"><a href="#如何使用-1" class="headerlink" title="如何使用"></a>如何使用</h3><ul><li><p>引入依赖</p>  <dependency><br>      <groupid>org.springframework.session</groupid><br>      <artifactid>spring-session-data-redis</artifactid><br>  </dependency>　</li><li><p>Session配置</p><p>  @Configuration<br>  @EnableRedisHttpSession(maxInactiveIntervalInSeconds = 86400*30)<br>  public class SessionConfig {<br>  }</p></li></ul><p>maxInactiveIntervalInSeconds: 设置Session失效时间，使用Redis Session之后，原Boot的server.session.timeout属性不再生效</p><ul><li>测试</li></ul><p>添加测试方法获取sessionid</p><pre><code>@RequestMapping(&quot;/uid&quot;)String uid(HttpSession session) {    UUID uid = (UUID) session.getAttribute(&quot;uid&quot;);    if (uid == null) {        uid = UUID.randomUUID();    }    session.setAttribute(&quot;uid&quot;, uid);    return session.getId();}</code></pre><p>登录redis 输入 keys ‘<em>sessions</em>‘ xml t&lt;spring:session:sessions:db031986-8ecc-48d6-b471-b137a3ed6bc4 t(spring:session:expirations:1472976480000  其中 1472976480000为失效时间，意思是这个时间后session失效，db031986-8ecc-48d6-b471-b137a3ed6bc4 为sessionId,登录<a href="http://localhost:8080/uid" target="_blank" rel="noopener">http://localhost:8080/uid</a> 发现会一致，就说明session 已经在redis里面进行有效的管理了。<br>这条session作为数据储存在Redis数据库中。</p><h3 id="如何在两台或者多台中共享session"><a href="#如何在两台或者多台中共享session" class="headerlink" title="如何在两台或者多台中共享session"></a>如何在两台或者多台中共享session</h3><p>其实就是按照上面的步骤在另一个项目中再次配置一次，启动后自动就进行了session共享。</p><p>多台机器可以共享这个Redis数据库，里面自然有Session数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在SpringBoot中对常用的数据库支持外，对nosql 数据库也进行了封装自动化。&lt;/p&gt;
&lt;h1 id=&quot;Redis&quot;&gt;&lt;a href=&quot;#Redis&quot; class=&quot;headerlink&quot; title=&quot;Redis&quot;&gt;&lt;/a&gt;Redis&lt;/h1&gt;&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。&lt;br&gt;Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。&lt;br&gt;它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。&lt;/p&gt;
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
</feed>
